{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Pawe≈Ç Chruszczewsju\n",
    "\n",
    "Objective: The primary goal of this code is to develop a machine learning model that can classify the labels properly and address dataset imbalance. The dataset has three classes (1, 2, and 3). There are three problems in the challenge. In each problem, there is some specific task that needs to be done. In the following subsections, I describe three techniques I used to overcome the data imbalance problem.\n",
    "\n",
    "Codes and libraries: This project requires Python  3. I have Used python 3.9. The following Python libraries are also required:\n",
    "\n",
    "<li> numpy\n",
    "<li> pandas\n",
    "<li> matplotlib\n",
    "<li> scikit-learn\n",
    "<li> xgboost\n",
    "<li> scipy\n",
    "<li> seaborn\n",
    "<li> itertools\n",
    "<li> math\n",
    "<li> mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "## Plotting libraries\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "## Sklearn Libraries\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc, \\\n",
    "            classification_report, recall_score, precision_recall_curve, roc_auc_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "## XGBoost Librarires\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Scipy Libraries\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2\n",
    "\n",
    "#itertools\n",
    "from itertools import combinations, permutations\n",
    "\n",
    "#mlxtend\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "#math\n",
    "import math\n",
    "\n",
    "# Define random state\n",
    "random_state = 2020\n",
    "np.random.seed(random_state)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state = random_state)\n",
    "\n",
    "pipe_lr = make_pipeline(PowerTransformer(method='yeo-johnson',standardize = True),\n",
    "                        RFECV(estimator = logreg, step = 1, cv=cv, scoring = 'roc_auc'),\n",
    "                        logreg)\n",
    "\n",
    "search = RandomizedSearchCV(estimator=pipe_lr, param_distributions = logreg_grid, cv = cv, n_jobs=-1, verbose=True, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=2020, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('powertransformer',\n",
       "                                              PowerTransformer()),\n",
       "                                             ('rfecv',\n",
       "                                              RFECV(cv=StratifiedKFold(n_splits=5, random_state=2020, shuffle=True),\n",
       "                                                    estimator=LogisticRegression(random_state=2020),\n",
       "                                                    scoring='roc_auc')),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(random_state=2020...\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        'logisticregression__class_weight': ['balanced',\n",
       "                                                                             None],\n",
       "                                        'logisticregression__penalty': ['l1',\n",
       "                                                                        'l2',\n",
       "                                                                        'elasticnet',\n",
       "                                                                        None],\n",
       "                                        'logisticregression__solver': ['newton-cg',\n",
       "                                                                       'liblinear',\n",
       "                                                                       'saga',\n",
       "                                                                       'lbfgs']},\n",
       "                   scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = search.predict_proba(xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305790057411274"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset & Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Fundamentals_test4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Unnamed: 0','gdp_change'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64399, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pd</th>\n",
       "      <th>y</th>\n",
       "      <th>atch</th>\n",
       "      <th>empch</th>\n",
       "      <th>salech</th>\n",
       "      <th>roech</th>\n",
       "      <th>ptbch</th>\n",
       "      <th>dlcpdlttdebit</th>\n",
       "      <th>nwcdta</th>\n",
       "      <th>redat</th>\n",
       "      <th>...</th>\n",
       "      <th>dtdat</th>\n",
       "      <th>actdlct</th>\n",
       "      <th>quickratio</th>\n",
       "      <th>bvdmv</th>\n",
       "      <th>nidseq</th>\n",
       "      <th>actdnat</th>\n",
       "      <th>ebitdxint</th>\n",
       "      <th>redsale</th>\n",
       "      <th>nidsale</th>\n",
       "      <th>ebitdsale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.585663e-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275937</td>\n",
       "      <td>0.189045</td>\n",
       "      <td>0.132754</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>1.190518</td>\n",
       "      <td>2.508597</td>\n",
       "      <td>0.356337</td>\n",
       "      <td>0.162688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286958</td>\n",
       "      <td>2.008176</td>\n",
       "      <td>0.855730</td>\n",
       "      <td>0.405124</td>\n",
       "      <td>0.120632</td>\n",
       "      <td>1.475566</td>\n",
       "      <td>0.141434</td>\n",
       "      <td>0.130070</td>\n",
       "      <td>0.046393</td>\n",
       "      <td>0.091455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.021916e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185610</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.202329</td>\n",
       "      <td>-0.006262</td>\n",
       "      <td>-0.634720</td>\n",
       "      <td>1.678391</td>\n",
       "      <td>0.372817</td>\n",
       "      <td>0.183627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205406</td>\n",
       "      <td>2.078004</td>\n",
       "      <td>0.862750</td>\n",
       "      <td>0.545357</td>\n",
       "      <td>0.114370</td>\n",
       "      <td>1.257911</td>\n",
       "      <td>0.121963</td>\n",
       "      <td>0.144769</td>\n",
       "      <td>0.051514</td>\n",
       "      <td>0.096485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.698752e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212075</td>\n",
       "      <td>0.099448</td>\n",
       "      <td>0.165826</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.143538</td>\n",
       "      <td>2.079429</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.205122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254955</td>\n",
       "      <td>2.029756</td>\n",
       "      <td>0.720055</td>\n",
       "      <td>0.505766</td>\n",
       "      <td>0.141086</td>\n",
       "      <td>1.384712</td>\n",
       "      <td>0.157226</td>\n",
       "      <td>0.168131</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.100498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.373830e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250723</td>\n",
       "      <td>0.276382</td>\n",
       "      <td>0.168910</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.332061</td>\n",
       "      <td>2.151250</td>\n",
       "      <td>0.361805</td>\n",
       "      <td>0.215033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269305</td>\n",
       "      <td>2.006557</td>\n",
       "      <td>0.778922</td>\n",
       "      <td>0.433039</td>\n",
       "      <td>0.144621</td>\n",
       "      <td>1.498123</td>\n",
       "      <td>0.175031</td>\n",
       "      <td>0.188591</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.109792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.429146e-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090154</td>\n",
       "      <td>-0.043307</td>\n",
       "      <td>0.094780</td>\n",
       "      <td>-0.009272</td>\n",
       "      <td>0.745122</td>\n",
       "      <td>2.265693</td>\n",
       "      <td>0.475990</td>\n",
       "      <td>0.240520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273216</td>\n",
       "      <td>3.040201</td>\n",
       "      <td>1.077016</td>\n",
       "      <td>0.327398</td>\n",
       "      <td>0.135348</td>\n",
       "      <td>1.453859</td>\n",
       "      <td>0.213208</td>\n",
       "      <td>0.210052</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>0.105313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pd    y      atch     empch    salech     roech     ptbch  \\\n",
       "0  2.585663e-20  0.0  0.275937  0.189045  0.132754  0.016827  1.190518   \n",
       "1  2.021916e-04  0.0  0.185610  0.016854  0.202329 -0.006262 -0.634720   \n",
       "2  1.698752e-03  0.0  0.212075  0.099448  0.165826  0.026716  0.143538   \n",
       "3  5.373830e-15  0.0  0.250723  0.276382  0.168910  0.003535  0.332061   \n",
       "4  5.429146e-23  0.0  0.090154 -0.043307  0.094780 -0.009272  0.745122   \n",
       "\n",
       "   dlcpdlttdebit    nwcdta     redat  ...     dtdat   actdlct  quickratio  \\\n",
       "0       2.508597  0.356337  0.162688  ...  0.286958  2.008176    0.855730   \n",
       "1       1.678391  0.372817  0.183627  ...  0.205406  2.078004    0.862750   \n",
       "2       2.079429  0.371033  0.205122  ...  0.254955  2.029756    0.720055   \n",
       "3       2.151250  0.361805  0.215033  ...  0.269305  2.006557    0.778922   \n",
       "4       2.265693  0.475990  0.240520  ...  0.273216  3.040201    1.077016   \n",
       "\n",
       "      bvdmv    nidseq   actdnat  ebitdxint   redsale   nidsale  ebitdsale  \n",
       "0  0.405124  0.120632  1.475566   0.141434  0.130070  0.046393   0.091455  \n",
       "1  0.545357  0.114370  1.257911   0.121963  0.144769  0.051514   0.096485  \n",
       "2  0.505766  0.141086  1.384712   0.157226  0.168131  0.061078   0.100498  \n",
       "3  0.433039  0.144621  1.498123   0.175031  0.188591  0.061064   0.109792  \n",
       "4  0.327398  0.135348  1.453859   0.213208  0.210052  0.057668   0.105313  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>1.345430e-307</td>\n",
       "      <td>1.493709e-24</td>\n",
       "      <td>1.618681e-09</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atch</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.995402e-01</td>\n",
       "      <td>-4.050683e-02</td>\n",
       "      <td>5.274254e-02</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empch</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-4.444444e-02</td>\n",
       "      <td>2.155172e-02</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salech</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.487889e+00</td>\n",
       "      <td>-3.418465e-02</td>\n",
       "      <td>7.043707e-02</td>\n",
       "      <td>0.215762</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roech</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-9.432236e-02</td>\n",
       "      <td>-4.729832e-03</td>\n",
       "      <td>0.057598</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptbch</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.686304e-01</td>\n",
       "      <td>-2.560469e-03</td>\n",
       "      <td>0.501810</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dlcpdlttdebit</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.224381e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.303295e+00</td>\n",
       "      <td>4.207701</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nwcdta</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>-0.415334</td>\n",
       "      <td>102.483575</td>\n",
       "      <td>-2.596852e+04</td>\n",
       "      <td>2.709664e-02</td>\n",
       "      <td>1.732806e-01</td>\n",
       "      <td>0.364668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redat</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>-3.792834</td>\n",
       "      <td>142.177284</td>\n",
       "      <td>-2.609760e+04</td>\n",
       "      <td>-3.597986e-01</td>\n",
       "      <td>1.084332e-01</td>\n",
       "      <td>0.331912</td>\n",
       "      <td>140.581479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdat</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>-0.154390</td>\n",
       "      <td>6.453680</td>\n",
       "      <td>-1.413000e+03</td>\n",
       "      <td>-1.220279e-02</td>\n",
       "      <td>6.336885e-02</td>\n",
       "      <td>0.112973</td>\n",
       "      <td>10.698373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mvaluedtd</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.106887e-02</td>\n",
       "      <td>2.182192e-01</td>\n",
       "      <td>0.624160</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saledat</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>1.060237</td>\n",
       "      <td>1.094041</td>\n",
       "      <td>-4.886996e-01</td>\n",
       "      <td>4.587633e-01</td>\n",
       "      <td>8.577118e-01</td>\n",
       "      <td>1.383578</td>\n",
       "      <td>63.504065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nidat</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>-0.669030</td>\n",
       "      <td>102.969052</td>\n",
       "      <td>-2.588481e+04</td>\n",
       "      <td>-4.538253e-02</td>\n",
       "      <td>3.160838e-02</td>\n",
       "      <td>0.072891</td>\n",
       "      <td>239.675881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtdat</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>0.355334</td>\n",
       "      <td>1.955896</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.965795e-02</td>\n",
       "      <td>2.289889e-01</td>\n",
       "      <td>0.381874</td>\n",
       "      <td>231.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actdlct</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.128093e+00</td>\n",
       "      <td>1.766545e+00</td>\n",
       "      <td>2.846916</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickratio</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.494382e-03</td>\n",
       "      <td>6.512199e-01</td>\n",
       "      <td>1.088521e+00</td>\n",
       "      <td>1.925727</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bvdmv</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.416078e-01</td>\n",
       "      <td>4.740706e-01</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>423.281078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nidseq</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-4.895553e-02</td>\n",
       "      <td>8.834238e-02</td>\n",
       "      <td>0.171501</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actdnat</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.887705e+03</td>\n",
       "      <td>4.561178e-01</td>\n",
       "      <td>8.619546e-01</td>\n",
       "      <td>1.279895</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdxint</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.727637e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.411147e-02</td>\n",
       "      <td>0.269790</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redsale</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.121251e-01</td>\n",
       "      <td>1.090070e-01</td>\n",
       "      <td>0.358866</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nidsale</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-5.888414e-02</td>\n",
       "      <td>3.169565e-02</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdsale</th>\n",
       "      <td>64399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.436884e-02</td>\n",
       "      <td>6.522260e-02</td>\n",
       "      <td>0.136054</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      mean         std            min           25%  \\\n",
       "pd             64399.0  0.060438    0.176708  1.345430e-307  1.493709e-24   \n",
       "y              64399.0  0.008277    0.090599   0.000000e+00  0.000000e+00   \n",
       "atch           64399.0       inf         NaN  -9.995402e-01 -4.050683e-02   \n",
       "empch          64399.0       inf         NaN  -1.000000e+00 -4.444444e-02   \n",
       "salech         64399.0       inf         NaN  -6.487889e+00 -3.418465e-02   \n",
       "roech          64399.0       NaN         NaN           -inf -9.432236e-02   \n",
       "ptbch          64399.0       NaN         NaN           -inf -5.686304e-01   \n",
       "dlcpdlttdebit  64399.0       inf         NaN  -1.224381e+04  0.000000e+00   \n",
       "nwcdta         64399.0 -0.415334  102.483575  -2.596852e+04  2.709664e-02   \n",
       "redat          64399.0 -3.792834  142.177284  -2.609760e+04 -3.597986e-01   \n",
       "ebitdat        64399.0 -0.154390    6.453680  -1.413000e+03 -1.220279e-02   \n",
       "mvaluedtd      64399.0       inf         NaN   0.000000e+00  4.106887e-02   \n",
       "saledat        64399.0  1.060237    1.094041  -4.886996e-01  4.587633e-01   \n",
       "nidat          64399.0 -0.669030  102.969052  -2.588481e+04 -4.538253e-02   \n",
       "dtdat          64399.0  0.355334    1.955896   0.000000e+00  6.965795e-02   \n",
       "actdlct        64399.0       inf         NaN   0.000000e+00  1.128093e+00   \n",
       "quickratio     64399.0       inf         NaN  -4.494382e-03  6.512199e-01   \n",
       "bvdmv          64399.0      -inf         NaN           -inf  2.416078e-01   \n",
       "nidseq         64399.0       NaN         NaN           -inf -4.895553e-02   \n",
       "actdnat        64399.0       inf         NaN  -1.887705e+03  4.561178e-01   \n",
       "ebitdxint      64399.0       inf         NaN  -9.727637e+02  0.000000e+00   \n",
       "redsale        64399.0       NaN         NaN           -inf -5.121251e-01   \n",
       "nidsale        64399.0       NaN         NaN           -inf -5.888414e-02   \n",
       "ebitdsale      64399.0       NaN         NaN           -inf -1.436884e-02   \n",
       "\n",
       "                        50%       75%         max  \n",
       "pd             1.618681e-09  0.002570    1.000000  \n",
       "y              0.000000e+00  0.000000    1.000000  \n",
       "atch           5.274254e-02  0.184456         inf  \n",
       "empch          2.155172e-02  0.126582         inf  \n",
       "salech         7.043707e-02  0.215762         inf  \n",
       "roech         -4.729832e-03  0.057598         inf  \n",
       "ptbch         -2.560469e-03  0.501810         inf  \n",
       "dlcpdlttdebit  1.303295e+00  4.207701         inf  \n",
       "nwcdta         1.732806e-01  0.364668    1.000000  \n",
       "redat          1.084332e-01  0.331912  140.581479  \n",
       "ebitdat        6.336885e-02  0.112973   10.698373  \n",
       "mvaluedtd      2.182192e-01  0.624160         inf  \n",
       "saledat        8.577118e-01  1.383578   63.504065  \n",
       "nidat          3.160838e-02  0.072891  239.675881  \n",
       "dtdat          2.289889e-01  0.381874  231.444444  \n",
       "actdlct        1.766545e+00  2.846916         inf  \n",
       "quickratio     1.088521e+00  1.925727         inf  \n",
       "bvdmv          4.740706e-01  0.826816  423.281078  \n",
       "nidseq         8.834238e-02  0.171501         inf  \n",
       "actdnat        8.619546e-01  1.279895         inf  \n",
       "ebitdxint      7.411147e-02  0.269790         inf  \n",
       "redsale        1.090070e-01  0.358866         inf  \n",
       "nidsale        3.169565e-02  0.082609         inf  \n",
       "ebitdsale      6.522260e-02  0.136054         inf  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ebitdsale        64399\n",
       "nidsale          64399\n",
       "y                64399\n",
       "atch             64399\n",
       "empch            64399\n",
       "salech           64399\n",
       "roech            64399\n",
       "ptbch            64399\n",
       "dlcpdlttdebit    64399\n",
       "nwcdta           64399\n",
       "redat            64399\n",
       "ebitdat          64399\n",
       "mvaluedtd        64399\n",
       "saledat          64399\n",
       "nidat            64399\n",
       "dtdat            64399\n",
       "actdlct          64399\n",
       "quickratio       64399\n",
       "bvdmv            64399\n",
       "nidseq           64399\n",
       "actdnat          64399\n",
       "ebitdxint        64399\n",
       "redsale          64399\n",
       "pd               64399\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'y']\n",
    "y = data.loc[:, data.columns == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing extreme values(inf) to the 0.01 percentile and 0.99 percentile\n",
    "def winsorize_all(predictors):\n",
    "    for col in predictors.columns: \n",
    "         predictors[col] = winsorize(predictors[col], limits=0.01)\n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = winsorize_all(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pd               3.452901\n",
       "atch             3.684233\n",
       "empch            3.167673\n",
       "salech           8.485622\n",
       "roech            0.739635\n",
       "ptbch           -0.193292\n",
       "dlcpdlttdebit    0.758185\n",
       "nwcdta          -4.467631\n",
       "redat           -5.782641\n",
       "ebitdat         -4.703092\n",
       "mvaluedtd        4.949149\n",
       "saledat          1.550898\n",
       "nidat           -5.048107\n",
       "dtdat            3.238351\n",
       "actdlct          3.254847\n",
       "quickratio       3.619614\n",
       "bvdmv            1.067228\n",
       "nidseq          -0.544845\n",
       "actdnat          1.136374\n",
       "ebitdxint        0.595351\n",
       "redsale         -8.369578\n",
       "nidsale         -8.130412\n",
       "ebitdsale       -8.331175\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors distribution\n",
    "for i, col in enumerate(X.columns):\n",
    "    plt.figure(i)\n",
    "    sns.countplot(x=col, data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform first split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, \n",
    "                                                y, \n",
    "                                                test_size=0.3, \n",
    "                                                stratify = y,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. To handle data imbalance issue, I have used the following three techniques¬†:\n",
    "### A. Create ensemble class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
    "rf_n_estimators.append(1500)\n",
    "rf_n_estimators.append(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 55, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the default as a possible value\n",
    "rf_max_depth.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "rf_max_features = ['auto', 'sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_min_samples_leaf = [int(x) for x in np.linspace(1, 55, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion to split on\n",
    "rf_criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 40, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [float(x) for x in np.linspace(0, 0.3, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights associated with classes\n",
    "rf_class = ['balanced_subsample', 'balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = {'randomforestclassifier__n_estimators': rf_n_estimators,\n",
    "           'randomforestclassifier__max_depth': rf_max_depth,\n",
    "           'randomforestclassifier__max_features': rf_max_features,\n",
    "           'randomforestclassifier__criterion': rf_criterion,\n",
    "           'randomforestclassifier__min_samples_split': rf_min_samples_split,\n",
    "           'randomforestclassifier__min_impurity_decrease': rf_min_impurity_decrease,\n",
    "           'randomforestclassifier__min_samples_leaf':rf_min_samples_leaf,\n",
    "           'randomforestclassifier__bootstrap': rf_bootstrap,\n",
    "           'randomforestclassifier__class_weight': rf_class\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = RandomForestClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 81.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 108.3min finished\n"
     ]
    }
   ],
   "source": [
    "# base_models = [rdf]\n",
    "# n_splits = 5\n",
    "# grids = [rf_grid]\n",
    "# lgb_stack = Create_classifier(n_splits = n_splits, base_models = base_models, grids = grids)        \n",
    "# roc_auc_scores, feat_selected, feat_importance = lgb_stack.predict(xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the norm used in the penalization\n",
    "logreg_penalty = ['l1', 'l2', 'elasticnet', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse of regularization strength\n",
    "logreg_c = np.logspace(-4, 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to use in the optimization problem\n",
    "logreg_solver = ['newton-cg','liblinear', 'saga', 'lbfgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_weight = ['balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid = {'logisticregression__penalty' : logreg_penalty,\n",
    "               'logisticregression__C' : logreg_c,\n",
    "               'logisticregression__solver' : logreg_solver,\n",
    "               'logisticregression__class_weight': logreg_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to be used\n",
    "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "xgb_eta = [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum loss reduction required to make further partition\n",
    "xgb_gamma = [x for x in np.linspace(0, 0.5, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning objective used\n",
    "xgb_objective = ['binary:logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lambda = [10,20,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing of positive and negative weights\n",
    "xgb_weight = [119.85522788203754, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = {'xgbclassifier__n_estimators': xgb_n_estimators,\n",
    "            'xgbclassifier__max_depth': xgb_max_depth,\n",
    "            'xgbclassifier__min_child_weight': xgb_min_child_weight,\n",
    "            'xgbclassifier__tree_method': xgb_tree_method,\n",
    "            'xgbclassifier__learning_rate': xgb_eta,\n",
    "            'xgbclassifier__gamma': xgb_gamma,\n",
    "            'xgbclassifier__objective': xgb_objective,\n",
    "            'xgbclassifier__reg_lambda':xgb_lambda,\n",
    "            'xgbclassifier__scale_pos_weight': xgb_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  XGBClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 78.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 106.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 87.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 119.0min finished\n"
     ]
    }
   ],
   "source": [
    "chosen_set = ['ALL', 'PDE', 'PD']\n",
    "base_models = [logreg, rdf, xgb]\n",
    "n_splits = 5\n",
    "grids = [logreg_grid, rf_grid, xgb_grid]\n",
    "lgb_stack = Create_classifier(n_splits = n_splits, base_models = base_models, grids = grids)        \n",
    "roc_auc_scores, feat_selected, feat_importance, test_pred, models = lgb_stack.predict(xtrain, ytrain, xtest, ytest, chosen_set = chosen_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">ALL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "      <th>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=None, gamma=None,\\n              gpu_id=None, importance_type='gain', interaction_constraints=None,\\n              learning_rate=None, max_delta_step=None, max_depth=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\\n              random_state=2020, reg_alpha=None, reg_lambda=None,\\n              scale_pos_weight=None, subsample=None, tree_method=None,\\n              validate_parameters=None, verbosity=None)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.243919</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.041810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112291</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.350903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ALL  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                  0.000183   \n",
       "1                                  0.002008   \n",
       "2                                  0.000287   \n",
       "3                                  0.112291   \n",
       "4                                  0.000903   \n",
       "...                                     ...   \n",
       "19315                              0.000321   \n",
       "19316                              0.000044   \n",
       "19317                              0.000079   \n",
       "19318                              0.020542   \n",
       "19319                              0.000289   \n",
       "\n",
       "                                                 \\\n",
       "      RandomForestClassifier(random_state=2020)   \n",
       "0                                      0.015745   \n",
       "1                                      0.243919   \n",
       "2                                      0.041810   \n",
       "3                                      0.329563   \n",
       "4                                      0.000962   \n",
       "...                                         ...   \n",
       "19315                                  0.000000   \n",
       "19316                                  0.000000   \n",
       "19317                                  0.000383   \n",
       "19318                                  0.350903   \n",
       "19319                                  0.009197   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "      XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=None, gamma=None,\\n              gpu_id=None, importance_type='gain', interaction_constraints=None,\\n              learning_rate=None, max_delta_step=None, max_depth=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\\n              random_state=2020, reg_alpha=None, reg_lambda=None,\\n              scale_pos_weight=None, subsample=None, tree_method=None,\\n              validate_parameters=None, verbosity=None)  \n",
       "0                                                    0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "1                                                    0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "2                                                    0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "3                                                    0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "4                                                    0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "...                                                  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "19315                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "19316                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "19317                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "19318                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "19319                                                0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "[19320 rows x 3 columns]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.015745\n",
       "1        0.243919\n",
       "2        0.041810\n",
       "3        0.329563\n",
       "4        0.000962\n",
       "           ...   \n",
       "19315    0.000000\n",
       "19316    0.000000\n",
       "19317    0.000383\n",
       "19318    0.350903\n",
       "19319    0.009197\n",
       "Name: RandomForestClassifier(random_state=2020), Length: 19320, dtype: float64"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred['ALL']['RandomForestClassifier(random_state=2020)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "      <th>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=None, gamma=None,\\n              gpu_id=None, importance_type='gain', interaction_constraints=None,\\n              learning_rate=None, max_delta_step=None, max_depth=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\\n              random_state=2020, reg_alpha=None, reg_lambda=None,\\n              scale_pos_weight=None, subsample=None, tree_method=None,\\n              validate_parameters=None, verbosity=None)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.93039</td>\n",
       "      <td>0.951309</td>\n",
       "      <td>0.947079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LogisticRegression(random_state=2020)  \\\n",
       "0                               0.93039   \n",
       "\n",
       "  RandomForestClassifier(random_state=2020)  \\\n",
       "0                                  0.951309   \n",
       "\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\\n              colsample_bynode=None, colsample_bytree=None, gamma=None,\\n              gpu_id=None, importance_type='gain', interaction_constraints=None,\\n              learning_rate=None, max_delta_step=None, max_depth=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              n_estimators=100, n_jobs=None, num_parallel_tree=None,\\n              random_state=2020, reg_alpha=None, reg_lambda=None,\\n              scale_pos_weight=None, subsample=None, tree_method=None,\\n              validate_parameters=None, verbosity=None)  \n",
       "0                                           0.947079                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_score = Scoring(roc_auc = roc_auc_scores, predict_df = test_pred, base_models = base_models)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_classifier(object):\n",
    "    def __init__(self, n_splits, base_models, grids):\n",
    "        self.n_splits = n_splits\n",
    "        self.base_models = base_models\n",
    "        self.grids = grids\n",
    "\n",
    "    def predict(self, x_train, y_train, x_test, y_test, chosen_set = ''):\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state = random_state)\n",
    "                  \n",
    "        roc_auc_scores = pd.DataFrame(columns = [str(i) for i in self.base_models])\n",
    "        test_pred = pd.DataFrame(np.zeros((x_test.shape[0], len(self.base_models))), columns=[str(i) for i in self.base_models])\n",
    "        test_pred.columns = pd.MultiIndex.from_product([[chosen_set], test_pred.columns])\n",
    "        feat_selected = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "        feat_importance = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "        models = []         \n",
    "        \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            pipe_lr = make_pipeline(PowerTransformer(method='yeo-johnson',standardize = True),\n",
    "                                    RFECV(estimator = clf, step = 1, cv=cv, scoring = 'roc_auc'),\n",
    "                                    clf)\n",
    "                  \n",
    "            search = RandomizedSearchCV(estimator=pipe_lr, param_distributions = self.grids[i], cv = cv, n_jobs=-1, verbose=True, scoring = 'roc_auc')\n",
    "            search.fit(x_train, y_train)\n",
    "            \n",
    "            models.append([chosen_set, i, search.best_estimator_])\n",
    "            \n",
    "            predict_rdf = search.best_estimator_.predict_proba(x_test)[:,1]\n",
    "            test_pred[chosen_set][str(clf)] = predict_rdf\n",
    "                  \n",
    "            roc_auc_scores.loc[0,str(clf)] = roc_auc_score(y_test, predict_rdf)\n",
    "                  \n",
    "            for j in x_train.columns:\n",
    "                feat_est = dict(zip(x_train.columns, search.best_estimator_.named_steps[\"rfecv\"].ranking_))\n",
    "                feat_selected.loc[str(j), str(clf)] = feat_est[str(j)]\n",
    "                \n",
    "                try:\n",
    "                    importances = dict(zip(x_train.columns, search.best_estimator_.named_steps[str(clf).split('(')[0].lower()].feature_importances_))\n",
    "                    feat_importance.loc[str(j), str(clf)] = importances[str(j)]\n",
    "                except Exception:\n",
    "                    pass\n",
    "                \n",
    "        return roc_auc_scores, feat_selected, feat_importance, test_pred, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def compute_midrank_weight(x, sample_weight):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    cumulative_weight = np.cumsum(sample_weight[J])\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = cumulative_weight[i:j].mean()\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    T2[J] = T\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Oerating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    p_val = np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "    \n",
    "    p_val[p_val>1]=1\n",
    "    \n",
    "    return p_val\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth, sample_weight=None):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    if sample_weight is None:\n",
    "        ordered_sample_weight = None\n",
    "    else:\n",
    "        ordered_sample_weight = sample_weight[order]\n",
    "\n",
    "    return order, label_1_count, ordered_sample_weight\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "    order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(\n",
    "        ground_truth, sample_weight)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "    order, label_1_count, a = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    return math.exp(calc_pvalue(aucs, delongcov))\n",
    "\n",
    "def calc_auc_ci(y_true, y_pred, alpha=0.95):\n",
    "    auc, auc_cov = delong_roc_variance(y_true,y_pred)\n",
    "    auc_std = np.sqrt(auc_cov)\n",
    "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "    ci_delong = norm.ppf(\n",
    "        lower_upper_q,\n",
    "        loc=auc,\n",
    "        scale=auc_std)\n",
    "\n",
    "    ci_delong[ci_delong > 1] = 1\n",
    "    \n",
    "    return ci_delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "\n",
    "def score_ci(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    score_fun,\n",
    "    n_bootstraps=2000,\n",
    "    confidence_level=0.95,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute confidence interval for given score function based on labels and predictions using bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_pred: 1D list or array of predictions corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param confidence_level: Confidence level for computing confidence interval. (default: 0.95)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Score evaluated on labels and predictions, lower confidence interval, upper confidence interval, array of\n",
    "    bootstrapped scores.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(y_true) == len(y_pred)\n",
    "\n",
    "    score = score_fun(y_true, y_pred)\n",
    "    _, ci_lower, ci_upper, scores = score_stat_ci(\n",
    "        y_true=y_true,\n",
    "        y_preds=y_pred,\n",
    "        score_fun=score_fun,\n",
    "        n_bootstraps=n_bootstraps,\n",
    "        confidence_level=confidence_level,\n",
    "        seed=seed,\n",
    "        reject_one_class_samples=reject_one_class_samples,\n",
    "    )\n",
    "\n",
    "    return score, ci_lower, ci_upper, scores\n",
    "\n",
    "\n",
    "def score_stat_ci(\n",
    "    y_true,\n",
    "    y_preds,\n",
    "    score_fun,\n",
    "    stat_fun=np.mean,\n",
    "    n_bootstraps=2000,\n",
    "    confidence_level=0.95,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute confidence interval for given statistic of a score function based on labels and predictions using\n",
    "    bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_preds: A list of lists or 2D array of predictions corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param stat_fun: Statistic for which confidence interval is computed. (e.g. np.mean)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param confidence_level: Confidence level for computing confidence interval. (default: 0.95)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Mean score statistic evaluated on labels and predictions, lower confidence interval, upper confidence\n",
    "    interval, array of bootstrapped scores.\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_preds = np.atleast_2d(y_preds)\n",
    "    assert all(len(y_true) == len(y) for y in y_preds)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        readers = np.random.randint(0, len(y_preds), len(y_preds))\n",
    "        indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "        if reject_one_class_samples and len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        reader_scores = []\n",
    "        for r in readers:\n",
    "            reader_scores.append(score_fun(y_true[indices], y_preds[r][indices]))\n",
    "        scores.append(stat_fun(reader_scores))\n",
    "\n",
    "    mean_score = np.mean(scores)\n",
    "    sorted_scores = np.array(sorted(scores))\n",
    "    alpha = (1.0 - confidence_level) / 2.0\n",
    "    ci_lower = sorted_scores[int(round(alpha * len(sorted_scores)))]\n",
    "    ci_upper = sorted_scores[int(round((1.0 - alpha) * len(sorted_scores)))]\n",
    "    return mean_score, ci_lower, ci_upper, scores\n",
    "\n",
    "\n",
    "def pvalue(\n",
    "    y_true,\n",
    "    y_pred1,\n",
    "    y_pred2,\n",
    "    score_fun,\n",
    "    n_bootstraps=2000,\n",
    "    two_tailed=True,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute p-value for hypothesis that score function for model I predictions is higher than for model II predictions\n",
    "    using bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_pred1: 1D list or array of predictions for model I corresponding to elements in y_true.\n",
    "    :param y_pred2: 1D list or array of predictions for model II corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param two_tailed: Whether to use two-tailed test. (default: True)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Computed p-value, array of bootstrapped differences of scores.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(y_true) == len(y_pred1)\n",
    "    assert len(y_true) == len(y_pred2)\n",
    "\n",
    "    return pvalue_stat(\n",
    "        y_true=y_true,\n",
    "        y_preds1=y_pred1,\n",
    "        y_preds2=y_pred2,\n",
    "        score_fun=score_fun,\n",
    "        n_bootstraps=n_bootstraps,\n",
    "        two_tailed=two_tailed,\n",
    "        seed=seed,\n",
    "        reject_one_class_samples=reject_one_class_samples,\n",
    "    )\n",
    "\n",
    "\n",
    "def pvalue_stat(\n",
    "    y_true,\n",
    "    y_preds1,\n",
    "    y_preds2,\n",
    "    score_fun,\n",
    "    stat_fun=np.mean,\n",
    "    n_bootstraps=1000,\n",
    "    two_tailed=True,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute p-value for hypothesis that given statistic of score function for model I predictions is higher than for\n",
    "    model II predictions using bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_preds1: A list of lists or 2D array of predictions for model I corresponding to elements in y_true.\n",
    "    :param y_preds2: A list of lists or 2D array of predictions for model II corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param stat_fun: Statistic for which p-value is computed. (e.g. np.mean)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param two_tailed: Whether to use two-tailed test. (default: True)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Computed p-value, array of bootstrapped differences of scores.\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_preds1 = np.atleast_2d(y_preds1)\n",
    "    y_preds2 = np.atleast_2d(y_preds2)\n",
    "    assert all(len(y_true) == len(y) for y in y_preds1)\n",
    "    assert all(len(y_true) == len(y) for y in y_preds2)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    z = []\n",
    "    for i in range(n_bootstraps):\n",
    "        readers1 = np.random.randint(0, len(y_preds1), len(y_preds1))\n",
    "        readers2 = np.random.randint(0, len(y_preds2), len(y_preds2))\n",
    "        indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "        if reject_one_class_samples and len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        reader_scores = []\n",
    "        for r in readers1:\n",
    "            reader_scores.append(score_fun(y_true[indices], y_preds1[r][indices]))\n",
    "        score1 = stat_fun(reader_scores)\n",
    "        reader_scores = []\n",
    "        for r in readers2:\n",
    "            reader_scores.append(score_fun(y_true[indices], y_preds2[r][indices]))\n",
    "        score2 = stat_fun(reader_scores)\n",
    "        z.append(score1 - score2)\n",
    "\n",
    "    p = percentileofscore(z, 0.0, kind=\"weak\") / 100.0\n",
    "    if two_tailed:\n",
    "        p *= 2.0\n",
    "    return p, z\n",
    "\n",
    "def method(x,y):\n",
    "    roc_auc_score(x,y)\n",
    "\n",
    "def bootstrap_error_estimate(pred, truth, method, method_name=\"\", alpha=0.95, sample_frac=0.5, iterations=100):\n",
    "    \"\"\"\n",
    "    Generate a bootstrapped estimate of confidence intervals\n",
    "    :param pred: list of predicted values\n",
    "    :param truth: list of experimental values\n",
    "    :param method: method to evaluate performance, e.g. matthews_corrcoef\n",
    "    :param method_name: name of the method for the progress bar\n",
    "    :param alpha: confidence limit (e.g. 0.95 for 95% confidence interval)\n",
    "    :param sample_frac: fraction to resample for bootstrap confidence interval\n",
    "    :param iterations: number of iterations for resampling\n",
    "    :return: lower and upper bounds for confidence intervals\n",
    "    \"\"\"\n",
    "    index_list = range(0, len(pred))\n",
    "    num_samples = int(len(index_list) * sample_frac)\n",
    "    stats = []\n",
    "    for _ in range(0, iterations):\n",
    "        sample_idx = resample(index_list, n_samples=num_samples)\n",
    "        pred_sample = [pred[x] for x in sample_idx]\n",
    "        truth_sample = [truth[x] for x in sample_idx]\n",
    "        stats.append(method(truth_sample, pred_sample))\n",
    "    p = ((1.0 - alpha) / 2.0) * 100\n",
    "    lower = max(0.0, np.percentile(stats, p))\n",
    "    p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "    upper = min(1.0, np.percentile(stats, p))\n",
    "    \n",
    "    ci_boot = np.array([lower,upper])\n",
    "    \n",
    "    return ci_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scoring(object):\n",
    "    def __init__(self, roc_auc, predict_df, base_models):\n",
    "        self.roc_auc = roc_auc\n",
    "        self.predict_df = predict_df\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def joined_scores(self):\n",
    "        roc_auc_all = pd.concat(self.roc_auc)\n",
    "        predict_df_all = pd.concat(self.predict_df, axis = 1)\n",
    "        return roc_auc_all, predict_df_all\n",
    "\n",
    "    def delong_test(predict_df_all, labels):\n",
    "        \n",
    "        Test_df_sets = pd.DataFrame(np.zeros((2, len(base_models))), index=['ALL/PDE','ALL/PD'], columns=[str(i) for i in base_models])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['DeLong Test'], Test_df_sets.columns])\n",
    "        \n",
    "        Test_df_all = pd.DataFrame(list(combinations(Test_df['DeLong Test'].columns,2)),columns = ['1st Algorithm', '2nd Algorithm', 'score'])\n",
    "        Test_df_all['score'] = 0\n",
    "        Test_df_all.columns = pd.MultiIndex.from_product([['DeLong Test'], Test_df_all.columns])    \n",
    "            \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            Test_df['DeLong Test'].loc['ALL/PDE',str(clf)] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PDE'][str(clf)])\n",
    "            Test_df['DeLong Test'].loc['ALL/PD',str(clf)] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PD'][str(clf)])\n",
    "            \n",
    "        for j in len(range(Test_df_all.shape[0])):\n",
    "            Test_df_all['DeLong Test'].loc[i,'score'] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][Test_df_all['DeLong Test'].loc[i,'1st Algorithm']], predict_df_all['ALL'][Test_df_all['DeLong Test'].loc[i,'2nd Algorithm']])\n",
    "    \n",
    "        return Test_df_sets, Test_df_all\n",
    "    \n",
    "    def bootstrap_test(predict_df_all, labels):\n",
    "    \n",
    "        Test_df_sets = pd.DataFrame(np.zeros((2, len(base_models))), index=['ALL/PDE','ALL/PD'], columns=[str(i) for i in base_models])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['Bootstrap Test'], Test_df_sets.columns])\n",
    "        \n",
    "        Test_df_all = pd.DataFrame(list(combinations(Test_df['Bootstrap Test'].columns,2)),columns = ['1st Algorithm', '2nd Algorithm', 'score'])\n",
    "        Test_df_all['score'] = 0\n",
    "        Test_df_all.columns = pd.MultiIndex.from_product([['Bootstrap Test'], Test_df_all.columns])\n",
    "            \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            Test_df['Bootstrap Test'].loc['ALL/PDE',str(clf)] = pvalue(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PDE'][str(clf)], score_fun=roc_auc_score)\n",
    "            Test_df['Bootstrap Test'].loc['ALL/PD',str(clf)] = pvalue(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PD'][str(clf)], score_fun=roc_auc_score)\n",
    "            \n",
    "        for j in len(range(Test_df_all.shape[0])):\n",
    "            Test_df_all['Bootstrap Test'].loc[i,'score'] = pvalue(labels.values.ravel(), predict_df_all['ALL'][Test_df_all['Bootstrap Test'].loc[i,'1st Algorithm']], predict_df_all['ALL'][Test_df_all['Bootstrap Test'].loc[i,'2nd Algorithm']], score_fun=roc_auc_score)\n",
    "    \n",
    "        return Test_df_sets, Test_df_all\n",
    "    \n",
    "    def likelihood_RT(predict_df_all, labels):\n",
    "    \n",
    "        Test_df_sets = pd.DataFrame((np.zeros((2, 1))), index=['ALL/PDE','ALL/PD'], columns=['LogisticRegression()'])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['LRT'], Test_df_sets.columns])\n",
    "\n",
    "        alt_log_likelihood = -log_loss(labels,\n",
    "                                       predict_df_all['ALL']['LogisticRegression()'],\n",
    "                                       normalize=False)\n",
    "        null_log_likelihood = -log_loss(ytest,\n",
    "                                        predict_df_all['PDE']['LogisticRegression()'],\n",
    "                                        normalize=False)\n",
    "        G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "        p_log_l = chi2.sf(G, x_train.shape[1])\n",
    "        \n",
    "        alt_log_likelihood = -log_loss(labels,\n",
    "                                       predict_df_all['ALL']['LogisticRegression()'],\n",
    "                                       normalize=False)\n",
    "        null_log_likelihood = -log_loss(ytest,\n",
    "                                        predict_df_all['PD']['LogisticRegression()'],\n",
    "                                        normalize=False)\n",
    "        G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "        \n",
    "        p_log_2 = chi2.sf(G, x_train.shape[1])\n",
    "        \n",
    "        Test_df_sets['LRT'].loc['ALL/PDE','LogisticRegression()'] = p_log_l\n",
    "        Test_df_sets['LRT'].loc['ALL/PD','LogisticRegression()'] = p_log_2\n",
    "\n",
    "        return Test_df_sets\n",
    "    \n",
    "    def combined_ftest_5x2cv(estimator1, estimator2, x_train, y_train, scoring, random_seed):\n",
    "\n",
    "        if isinstance(scoring, str):\n",
    "            scorer = get_scorer(scoring)\n",
    "        else:\n",
    "            scorer = scoring\n",
    "\n",
    "        variances = []\n",
    "        differences = []\n",
    "\n",
    "        def score_diff(X_1, X_2, y_1, y_2):\n",
    "\n",
    "            estimator1.fit(X_1, y_1)\n",
    "            estimator2.fit(X_1, y_1)\n",
    "            est1_score = scorer(estimator1, X_2, y_2)\n",
    "            est2_score = scorer(estimator2, X_2, y_2)\n",
    "            score_diff = est1_score - est2_score\n",
    "            return score_diff\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            X_1, X_2, y_1, y_2 = train_test_split(x_train, y_train, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            score_diff_1 = score_diff(X_1, X_2, y_1, y_2)\n",
    "            score_diff_2 = score_diff(X_2, X_1, y_2, y_1)\n",
    "            score_mean = (score_diff_1 + score_diff_2) / 2.\n",
    "            score_var = ((score_diff_1 - score_mean)**2 + (score_diff_2 - score_mean)**2)\n",
    "\n",
    "            differences.extend([score_diff_1**2, score_diff_2**2])\n",
    "            variances.append(score_var)\n",
    "\n",
    "        numerator = sum(differences)\n",
    "        denominator = 2*(sum(variances))\n",
    "        f_stat = numerator / denominator\n",
    "\n",
    "        p_value = scipy.stats.f.sf(f_stat, 10, 5)\n",
    "\n",
    "        return float(f_stat), float(p_value)\n",
    "    \n",
    "    def f_test(estimators_list, x_train, y_train):\n",
    "    \n",
    "        estimators = []\n",
    "        for i in range(len(self.base_models)):\n",
    "            estimators.append(estimators_list[i][2])\n",
    "        estimators = list(combinations(estimators,2))\n",
    "        \n",
    "        p_values = []\n",
    "\n",
    "        for i in range(len(estimators)): \n",
    "\n",
    "            estimator1 = eval(estimators[i][0])\n",
    "            estimator2 = eval(estimators[i][1])\n",
    "            \n",
    "            f_stat, p_value = combined_ftest_5x2cv(estimator1, estimator2, x_train, y_train, roc_auc_score, random_state)\n",
    "            \n",
    "            p_values.append(p_value)\n",
    "            \n",
    "        f_p_values = pd.DataFrame(columns = ['algorithm1', 'algorithm2', 'score'])    \n",
    "            \n",
    "        for j in range(len(estimators)): \n",
    "            f_p_values.loc[j,'algorithm1'] = estimators[j][0]\n",
    "            f_p_values.loc[j,'algorithm2'] = estimators[j][1]\n",
    "            f_p_values.loc[j,'score'] = p_values[j]\n",
    "        \n",
    "        return(f_p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yeoj_graph(x_train, lbd_list, feature=''):\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    for i in range(len(lbd_list)):\n",
    "        n_lines = len(lbd_list)\n",
    "        c = np.arange(1, n_lines + 1)\n",
    "        norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "        cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Blues)\n",
    "        cmap.set_array([])\n",
    "        a = x_train[feature].values.ravel()\n",
    "        a = np.sort(a)\n",
    "        b = stats.yeojohnson(x_train[feature], lmbda=lbd_list[i])\n",
    "        b = np.sort(b)\n",
    "        plt.plot(a,b, c=cmap.to_rgba(i + 1), label='Œª = '+str(lbd_list[i]))\n",
    "    plt.legend(loc=0)\n",
    "    plt.ylabel(\"œà(Œª,x)\", fontsize=15)\n",
    "    plt.xlabel(\"x\", fontsize=15)\n",
    "    plt.savefig('yeo-johnson.png', dpi=1200)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Classification\n",
    "### A. Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
    "rf_n_estimators.append(1500)\n",
    "rf_n_estimators.append(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 55, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the default as a possible value\n",
    "rf_max_depth.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "rf_max_features = ['auto', 'sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_min_samples_leaf = [int(x) for x in np.linspace(1, 55, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion to split on\n",
    "rf_criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 40, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights associated with classes\n",
    "rf_class = ['balanced_subsample', 'balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'min_samples_leaf':rf_min_samples_leaf,\n",
    "               'bootstrap': rf_bootstrap,\n",
    "               'class_weight': rf_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state = random_state)\n",
    "\n",
    "rdf = RandomForestClassifier(random_state = random_state) \n",
    "scoring = {'Recall': make_scorer(recall_score),\n",
    "           'f1_score': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'min_samples_leaf':rf_min_samples_leaf,\n",
    "               'bootstrap': rf_bootstrap,\n",
    "               'class_weight': rf_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline dobrzez zrobiony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = {'randomforestclassifier__n_estimators': rf_n_estimators,\n",
    "           'randomforestclassifier__max_depth': rf_max_depth,\n",
    "           'randomforestclassifier__max_features': rf_max_features,\n",
    "           'randomforestclassifier__criterion': rf_criterion,\n",
    "           'randomforestclassifier__min_samples_split': rf_min_samples_split,\n",
    "           'randomforestclassifier__min_impurity_decrease': rf_min_impurity_decrease,\n",
    "           'randomforestclassifier__min_samples_leaf':rf_min_samples_leaf,\n",
    "           'randomforestclassifier__bootstrap': rf_bootstrap,\n",
    "           'randomforestclassifier__class_weight': rf_class\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(PowerTransformer(method='yeo-johnson',standardize = True),\n",
    "                        RFECV(estimator = RandomForestClassifier(random_state = random_state), step = 1, cv=cv, scoring = 'roc_auc'),\n",
    "                        RandomForestClassifier(random_state = random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(estimator=pipe_lr, param_distributions = rf_grid, cv = cv, n_jobs=-1, verbose=True, scoring = scoring, refit = 'roc_auc')\n",
    "search.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wywo≈Çanie z pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_.named_steps[\"rfecv\"].support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_._final_estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inne wywo≈Çanie z pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_.named_steps[\"rfecv\"].estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_.named_steps[\"rfecv\"].grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "predict_rdf = search.predict_proba(xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf = RandomizedSearchCV(estimator = rdf, param_distributions = rf_grid, cv = cv, n_jobs=-1, verbose=True, scoring = scoring, refit = 'roc_auc', n_iter = 150)\n",
    "grid_clf.fit(xtrain_pd, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_estimator_)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rdf = RandomForestClassifier(bootstrap=True, \n",
    "                             class_weight='balanced', \n",
    "                             criterion='gini',\n",
    "                             max_depth=35, \n",
    "                             max_features='log2', \n",
    "#                              max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.1, \n",
    "#                              min_impurity_split=None,\n",
    "                             min_samples_leaf=11, \n",
    "                             min_samples_split=12,\n",
    "#                              min_weight_fraction_leaf=0.0,\n",
    "                             n_estimators=1000, \n",
    "                             n_jobs=-1,\n",
    "#                              oob_score=False,\n",
    "                             random_state=random_state,\n",
    "                             verbose=0, \n",
    "#                              warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember about changing when changing models(ALL,NOPD,PD)!\n",
    "rdf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_rdf = rdf.predict(xtrain_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytrain,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytrain,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytrain,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytrain,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytrain,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "predict_rdf = rdf.predict(xtest_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytest,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytest,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytest,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytest,predict_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_rdf = search['randomforestclassifier'].feature_importances_\n",
    "\n",
    "#create a feature list from the original dataset (list of columns)\n",
    "# What are this numbers? Let's get back to the columns of the original dataset\n",
    "feature_list = list(xtrain.columns)\n",
    "\n",
    "#create a list of tuples\n",
    "feature_importance_rdf= sorted(zip(importances_rdf, feature_list), reverse=True)\n",
    "\n",
    "#create two lists from the previous list of tuples\n",
    "df_rdf = pd.DataFrame(feature_importance_rdf, columns=['importance', 'feature'])\n",
    "importance_rdf= list(df_rdf['importance'])\n",
    "feature= list(df_rdf['feature'])\n",
    "\n",
    "#see df\n",
    "print(df_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_list = list(xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_weights(pipe_lr['randomforestclassifier'], feature_names=numeric_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Predict All - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rdf = RandomForestClassifier(bootstrap=False, \n",
    "                             class_weight='balanced_subsample', \n",
    "                             criterion='entropy',\n",
    "                             max_depth=5, \n",
    "                             max_features='log2', \n",
    "#                              max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.0, \n",
    "#                              min_impurity_split=None,\n",
    "                             min_samples_leaf=33, \n",
    "                             min_samples_split=2,\n",
    "#                              min_weight_fraction_leaf=0.0,\n",
    "                             n_estimators=1000, \n",
    "                             n_jobs=-1,\n",
    "#                              oob_score=False,\n",
    "                             random_state=random_state,\n",
    "                             verbose=0, \n",
    "#                              warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember about changing when changing models(ALL,NOPD,PD)!\n",
    "rdf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_rdf_4 = rdf.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Predict No PD - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rdf = RandomForestClassifier(bootstrap=True, \n",
    "                             class_weight='balanced', \n",
    "                             criterion='gini',\n",
    "                             max_depth=None, \n",
    "                             max_features='sqrt', \n",
    "#                              max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.1, \n",
    "#                              min_impurity_split=None,\n",
    "                             min_samples_leaf=33, \n",
    "                             min_samples_split=28,\n",
    "#                              min_weight_fraction_leaf=0.0,\n",
    "                             n_estimators=1000, \n",
    "                             n_jobs=-1,\n",
    "#                              oob_score=False,\n",
    "                             random_state=random_state,\n",
    "                             verbose=0, \n",
    "#                              warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember about changing when changing models(ALL,NOPD,PD)!\n",
    "rdf.fit(xtrain_nopd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_rdf_5 = rdf.predict(xtest_nopd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Predict PD - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rdf = RandomForestClassifier(bootstrap=True, \n",
    "                             class_weight='balanced', \n",
    "                             criterion='gini',\n",
    "                             max_depth=35, \n",
    "                             max_features='log2', \n",
    "#                              max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.1, \n",
    "#                              min_impurity_split=None,\n",
    "                             min_samples_leaf=11, \n",
    "                             min_samples_split=12,\n",
    "#                              min_weight_fraction_leaf=0.0,\n",
    "                             n_estimators=1000, \n",
    "                             n_jobs=-1,\n",
    "#                              oob_score=False,\n",
    "                             random_state=random_state,\n",
    "                             verbose=0, \n",
    "#                              warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember about changing when changing models(ALL,NOPD,PD)!\n",
    "rdf.fit(xtrain_pd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_rdf_6 = rdf.predict(xtest_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [rdf]\n",
    "n_splits = 5\n",
    "lgb_stack = Create_ensemble(n_splits = n_splits, base_models = base_models)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred, recall_scores, f1_scores, roc_auc_scores = lgb_stack.predict(xtrain, ytrain, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(range(test_pred.shape[1])):  \n",
    "    print('1. The F-1 score of the model {}\\n'.format(f1_score(ytest, test_pred[:,i], average='macro')))\n",
    "    print('2. The roc_auc score of the model {}\\n'.format(roc_auc_score(ytest, test_pred[:,i], average='macro')))\n",
    "    print('3. Classification report \\n {} \\n'.format(classification_report(ytest, test_pred[:,i])))\n",
    "    print('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(ytest, test_pred[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpred_rf = pd.DataFrame(test_pred)\n",
    "final_tpred = tpred_rf.mode(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(final_tpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_tpred.to_csv('predicted_labels_1.csv', index=False, header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost Classification\n",
    "### A. Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to be used\n",
    "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "xgb_eta = [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum loss reduction required to make further partition\n",
    "xgb_gamma = [x for x in np.linspace(0, 0.5, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning objective used\n",
    "xgb_objective = ['binary:logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_lambda = [10,20,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing of positive and negative weights\n",
    "xgb_weight = [119.85522788203754, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "44706/373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(RFECV(estimator = xgb, step = 1, cv=cv, scoring = 'roc_auc'),\n",
    "                        RandomizedSearchCV(estimator = xgb, param_distributions = xgb_grid, cv = cv, n_jobs=-1, verbose=True, scoring = scoring, refit = 'roc_auc', n_iter = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pipe_lr['randomizedsearchcv'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredict = pipe_lr.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr['rfecv'].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest,ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the numerical values of feature importance from the grid search\n",
    "importances = pipe_lr['randomizedsearchcv'].feature_importances_\n",
    "\n",
    "#create a feature list from the original dataset (list of columns)\n",
    "# What are this numbers? Let's get back to the columns of the original dataset\n",
    "feature_list = list(xtrain.columns)\n",
    "\n",
    "#create a list of tuples\n",
    "feature_importance= sorted(zip(importances, feature_list), reverse=True)\n",
    "\n",
    "#create two lists from the previous list of tuples\n",
    "df = pd.DataFrame(feature_importance, columns=['importance', 'feature'])\n",
    "importance= list(df['importance'])\n",
    "feature= list(df['feature'])\n",
    "\n",
    "#see df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state = random_state)\n",
    "\n",
    "xgb = XGBClassifier(random_state = random_state) \n",
    "scoring = {'Recall': make_scorer(recall_score),\n",
    "           'f1_score': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "# Create the grid\n",
    "xgb_grid = {'n_estimators': xgb_n_estimators,\n",
    "            'max_depth': xgb_max_depth,\n",
    "            'min_child_weight': xgb_min_child_weight,\n",
    "            'tree_method': xgb_tree_method,\n",
    "            'learning_rate': xgb_eta,\n",
    "            'gamma': xgb_gamma,\n",
    "            'objective': xgb_objective,\n",
    "            'reg_lambda':xgb_lambda,\n",
    "            'scale_pos_weight': xgb_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf = RandomizedSearchCV(estimator = xgb, param_distributions = xgb_grid, cv = cv, n_jobs=-1, verbose=True, scoring = scoring, refit = 'roc_auc', n_iter = 100)\n",
    "grid_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_clf.best_estimator_)\n",
    "print(grid_clf.best_params_)\n",
    "print(grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb =  XGBClassifier(tree_method = 'exact',\n",
    "                     objective = 'binary:logistic',\n",
    "                     n_estimators = 1200,\n",
    "                     min_child_weight = 8,\n",
    "                     max_depth = 2,\n",
    "                     gamma = 0.3,\n",
    "                     reg_lambda = 90,\n",
    "                     learning_rate = 0.01,\n",
    "                     scale_pos_weight = 119.85522788203754,\n",
    "                     random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_xgb = xgb.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytrain,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytrain,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytrain,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytrain,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytrain,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "predict_xgb = xgb.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytest,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytest,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytest,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytest,predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the numerical values of feature importance from the grid search\n",
    "importances = xgb.feature_importances_\n",
    "\n",
    "#create a feature list from the original dataset (list of columns)\n",
    "# What are this numbers? Let's get back to the columns of the original dataset\n",
    "feature_list = list(xtrain.columns)\n",
    "\n",
    "#create a list of tuples\n",
    "feature_importance= sorted(zip(importances, feature_list), reverse=True)\n",
    "\n",
    "#create two lists from the previous list of tuples\n",
    "df = pd.DataFrame(feature_importance, columns=['importance', 'feature'])\n",
    "importance= list(df['importance'])\n",
    "feature= list(df['feature'])\n",
    "\n",
    "#see df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Predict All - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  XGBClassifier(tree_method = 'exact',\n",
    "                     objective = 'binary:logistic',\n",
    "                     n_estimators = 1200,\n",
    "                     min_child_weight = 8,\n",
    "                     max_depth = 2,\n",
    "                     gamma = 0.3,\n",
    "                     reg_lambda = 90,\n",
    "                     learning_rate = 0.01,\n",
    "                     scale_pos_weight = 119.85522788203754,\n",
    "                     random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_xgb_4 = xgb.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Predict No PD - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  XGBClassifier(tree_method = 'auto',\n",
    "                     objective = 'binary:logistic',\n",
    "                     n_estimators = 1000,\n",
    "                     min_child_weight = 4,\n",
    "                     max_depth = 2,\n",
    "                     gamma = 0.5,\n",
    "                     reg_lambda = 50,\n",
    "                     learning_rate = 0.01,\n",
    "                     scale_pos_weight = 119.85522788203754,\n",
    "                     random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(xtrain_nopd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_xgb_5 = xgb.predict(xtest_nopd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Predict PD - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  XGBClassifier(tree_method = 'hist',\n",
    "                     objective = 'binary:logistic',\n",
    "                     n_estimators = 200,\n",
    "                     min_child_weight = 3,\n",
    "                     max_depth = 2,\n",
    "                     gamma = 0.0,\n",
    "                     reg_lambda = 50,\n",
    "                     learning_rate = 0.01,\n",
    "                     scale_pos_weight = 119.85522788203754,\n",
    "                     random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(xtrain_pd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_xgb_6 = xgb.predict(xtest_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [xgb]\n",
    "n_splits = 5\n",
    "lgb_stack = Create_ensemble(n_splits = n_splits, base_models = base_models)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred, recall_scores, f1_scores, roc_auc_scores = lgb_stack.predict(xtrain, ytrain, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(range(test_pred.shape[1])):  \n",
    "    print('1. The F-1 score of the model {}\\n'.format(f1_score(ytest, test_pred[:,i], average='macro')))\n",
    "    print('2. The roc_auc score of the model {}\\n'.format(roc_auc_score(ytest, test_pred[:,i], average='macro')))\n",
    "    print('3. Classification report \\n {} \\n'.format(classification_report(ytest, test_pred[:,i])))\n",
    "    print('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(ytest, test_pred[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpred_xgb = pd.DataFrame(test_pred)\n",
    "final_tpred = tpred.mode(axis=1)LogisticRegression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(final_tpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logistic Regression Classificaton\n",
    "### A. Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the norm used in the penalization\n",
    "logreg_penalty = ['l1', 'l2', 'elasticnet', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse of regularization strength\n",
    "logreg_c = np.logspace(-4, 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to use in the optimization problem\n",
    "logreg_solver = ['newton-cg','liblinear', 'saga', 'lbfgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_weight = ['balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid = {'penalty' : logreg_penalty,\n",
    "                'C' : logreg_c,\n",
    "                'solver' : logreg_solver,\n",
    "                'class_weight': logreg_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state = random_state)\n",
    "\n",
    "logreg = LogisticRegression(random_state = random_state) \n",
    "scoring = {'Recall': make_scorer(recall_score),\n",
    "           'f1_score': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "# Create the grid\n",
    "logreg_grid = {'penalty' : logreg_penalty,\n",
    "                'C' : logreg_c,\n",
    "                'solver' : logreg_solver,\n",
    "                'class_weight': logreg_weight}\n",
    "\n",
    "grid_clf = RandomizedSearchCV(estimator = logreg, param_distributions = logreg_grid, cv = cv, n_jobs=-1, verbose=True, scoring = scoring, refit = 'roc_auc', n_iter = 10)\n",
    "grid_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_clf.best_estimator_)\n",
    "print(grid_clf.best_params_)\n",
    "print(grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log =  LogisticRegression(penalty = 'l2',\n",
    "                         solver = 'liblinear',\n",
    "                         class_weight = 'balanced',\n",
    "                         random_state = random_state,\n",
    "                         C = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(xtrain_pd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "pred_log = log.predict(xtrain_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytrain,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytrain,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytrain,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytrain,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytrain,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "pred_log = log.predict(xtest_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytest,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytest,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytest,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(ytest,pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method - solver\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(ytrain,xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = logit_model.fit(method = 'lbfgs',maxiter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Predict All - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log =  LogisticRegression(penalty = 'l2',\n",
    "                         solver = 'newton-cg',\n",
    "                         class_weight = 'balanced',\n",
    "                         random_state = random_state,\n",
    "                         C = 0.03359818286283781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_log_4 = log.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Predict No PD - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log =  LogisticRegression(penalty = 'l2',\n",
    "                         solver = 'newton-cg',\n",
    "                         class_weight = 'balanced',\n",
    "                         random_state = random_state,\n",
    "                         C = 0.012742749857031334)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(xtrain_nopd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_log_5 = log.predict(xtest_nopd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Predict PD - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log =  LogisticRegression(penalty = 'l2',\n",
    "                         solver = 'liblinear',\n",
    "                         class_weight = 'balanced',\n",
    "                         random_state = random_state,\n",
    "                         C = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(xtrain_pd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "predict_log_6 = log.predict(xtest_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [log]\n",
    "n_splits = 5\n",
    "lgb_stack = Create_ensemble(n_splits = n_splits, base_models = base_models)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred, recall_scores, f1_scores, roc_auc_scores = lgb_stack.predict(xtrain, ytrain, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(range(test_pred.shape[1])):  \n",
    "    print('1. The F-1 score of the model {}\\n'.format(f1_score(ytest, test_pred[:,i], average='macro')))\n",
    "    print('2. The roc_auc score of the model {}\\n'.format(roc_auc_score(ytest, test_pred[:,i], average='macro')))\n",
    "    print('3. Classification report \\n {} \\n'.format(classification_report(ytest, test_pred[:,i])))\n",
    "    print('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(ytest, test_pred[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpred_logreg = pd.DataFrame(test_pred)\n",
    "final_tpred = tpred.mode(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(final_tpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets used in problem-1 are highly unbalance. Therefore, all the evaluation metrics shows the expected random performance. Due to the unbalance data, the probabilities for minor classes (class-2 and 3) are inaccurate. But we can still get good predictions by choosing a more appropriate probability cutoff. In the problem-3 section, I will imporve the model performance by choosing a cutoff by ovserving the minor class probability distribution and ROC curve and by setting unequal importance of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modified Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem the labels have unequal importance, in the sense that we want to penalize the model most if it misclassified label 3, a little less for 2 and the least for label 1. Additionally, in case of a misclassification, it is preferable to over-predict a label than under-predict (i.e. misclassifying label 3 as 2 is worse than misclassifying label 2 as 3). To implement the above constraints I would rebuild problem-1 model in following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> <b>Step 1: </b>Predict probabilities instead of actual prediction.\n",
    "<li> <b>Step 2: </b>Set the class weight.\n",
    "<li> <b>Step 3: </b>Get probability distribution of minor class.\n",
    "<li> <b>Step 4: </b>From the ROC curve and probability distribution obtain probability thresholds for classes.\n",
    "<li> <b>Step 5: </b>Finally use the threshold to over-predict a label than under-predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_ensemble(object):\n",
    "    def __init__(self, n_splits, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def predict(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "#         T = np.array(T)\n",
    "        no_class = len(np.unique(y))\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, \n",
    "                                     random_state = random_state).split(X, y))\n",
    "\n",
    "        train_proba = np.zeros((X.shape[0], no_class))\n",
    "#         test_proba = np.zeros((T.shape[0], no_class))\n",
    "        \n",
    "        train_pred = np.zeros((X.shape[0], len(self.base_models)))\n",
    "#         test_pred = np.zeros((T.shape[0], len(self.base_models)* self.n_splits))\n",
    "        f1_scores = np.zeros((len(self.base_models), self.n_splits))\n",
    "        recall_scores = np.zeros((len(self.base_models), self.n_splits))\n",
    "        roc_auc_scores = np.zeros((len(self.base_models), self.n_splits))\n",
    "        \n",
    "        test_col = 0\n",
    "        \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            \n",
    "            for j, (train_idx, valid_idx) in enumerate(folds):\n",
    "                \n",
    "                X_train = X[train_idx]\n",
    "                Y_train = y[train_idx]\n",
    "                \n",
    "                clf.fit(X_train, Y_train)\n",
    "                \n",
    "                ## Probabilities\n",
    "                valid_proba = clf.predict_proba(X_train)\n",
    "                train_proba[train_idx, :] = valid_proba\n",
    "                \n",
    "#                 recall  = recall_score(Y_train, valid_proba, average='macro')\n",
    "#                 f1 = f1_score(Y_train, valid_proba, average='macro')\n",
    "                roc_auc = roc_auc_score(Y_train, valid_proba[:,1], average='macro')\n",
    "                \n",
    "#                 recall_scores[i][j] = recall\n",
    "#                 f1_scores[i][j] = f1\n",
    "                roc_auc_scores[i][j] = roc_auc\n",
    "                \n",
    "#                 train_pred[valid_idx, i] = valid_pred\n",
    "#                 test_pred[:, test_col] = clf.predict(T)\n",
    "#                 test_col += 1\n",
    "                \n",
    "#                 print( \"Model- {} and CV- {} recall: {}, f1_score: {}, roc_auc_score: {}\".format(i, j, recall, f1, roc_auc))\n",
    "                \n",
    "#             test_proba /= self.n_splits\n",
    "            \n",
    "        return train_proba, roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_class = len(np.unique(y))\n",
    "train_proba = np.zeros((X.shape[0], no_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rdf_1 = RandomForestClassifier(bootstrap=False, \n",
    "                             class_weight='balanced_subsample', \n",
    "                             criterion='gini',\n",
    "                             max_depth=5, \n",
    "                             max_features='log2', \n",
    "#                              max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.0, \n",
    "#                              min_impurity_split=None,\n",
    "#                              min_samples_leaf=8, \n",
    "                             min_samples_split=33,\n",
    "#                              min_weight_fraction_leaf=0.0,\n",
    "                             n_estimators=600, \n",
    "                             n_jobs=-1,\n",
    "#                              oob_score=False,\n",
    "                             random_state=random_state,\n",
    "                             verbose=0, \n",
    "#                              warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
       "                       max_depth=5, max_features='log2', min_samples_split=33,\n",
       "                       n_estimators=600, n_jobs=-1, random_state=2020)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rdf_1 = rdf_1.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rdf_1 = predict_rdf_1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9412822938413361"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest, predict_rdf_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. PD Omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rdf_2 = RandomForestClassifier(bootstrap=True, \n",
    "                             class_weight='balanced', \n",
    "                             criterion='entropy',\n",
    "                             max_depth=None, \n",
    "                             max_features='auto', \n",
    "#                              max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.05, \n",
    "#                              min_impurity_split=None,\n",
    "#                              min_samples_leaf=8, \n",
    "                             min_samples_split=11,\n",
    "#                              min_weight_fraction_leaf=0.0,\n",
    "                             n_estimators=2000, \n",
    "                             n_jobs=-1,\n",
    "#                              oob_score=False,\n",
    "                             random_state=random_state,\n",
    "                             verbose=0, \n",
    "#                              warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       min_impurity_decrease=0.05, min_samples_split=11,\n",
       "                       n_estimators=2000, n_jobs=-1, random_state=2020)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_2.fit(xtrain_nopd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rdf_2 = rdf_2.predict_proba(xtest_nopd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rdf_2 = predict_rdf_2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9267118997912317"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest,predict_rdf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rdf_3 = RandomForestClassifier(bootstrap=True, \n",
    "                             class_weight='balanced', \n",
    "                             criterion='gini',\n",
    "                             max_depth=25, \n",
    "                             max_features='sqrt', \n",
    "#                              max_leaf_nodes=None,\n",
    "                             min_impurity_decrease=0.05, \n",
    "#                              min_impurity_split=None,\n",
    "#                              min_samples_leaf=8, \n",
    "                             min_samples_split=38,\n",
    "#                              min_weight_fraction_leaf=0.0,\n",
    "                             n_estimators=1000, \n",
    "                             n_jobs=-1,\n",
    "#                              oob_score=False,\n",
    "                             random_state=random_state,\n",
    "                             verbose=0, \n",
    "#                              warm_start=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_3.fit(xtrain_pd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rdf_3 = rdf_3.predict_proba(xtest_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rdf_3 = predict_rdf_3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest, predict_rdf_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Bootstraping and DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_scores, feat_selected, feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame(np.zeros((xtest.shape[0], len(base_models))), columns=[str(i) for i in base_models])\n",
    "test_pred.columns = pd.MultiIndex.from_product([[chosen_set], test_pred.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred1 = pd.DataFrame(np.zeros((xtest.shape[0], len(base_models))), columns=[str(i) for i in base_models])\n",
    "test_pred1.columns = pd.MultiIndex.from_product([['NOPD'], test_pred1.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = [test_pred, test_pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df_all = pd.concat(predict_df,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all['ALL'].loc[0,'LogisticRegression()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = [logreg,rdf]\n",
    "predict_df = [logreg_grid]\n",
    "lgb_stack = Scoring(roc_auc = roc_auc, predict_df = predict_df)        \n",
    "roc_auc_scores, feat_selected, feat_importance = lgb_stack.predict(xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df = pd.DataFrame(np.zeros((2, len(base_models))), index=['ALL/PDE','PDE/PD'], columns=[str(i) for i in base_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df.columns = pd.MultiIndex.from_product([['DeLong Test'], Test_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ALL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">NOPD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ALL                                          NOPD  \\\n",
       "      LogisticRegression() RandomForestClassifier() LogisticRegression()   \n",
       "0                      0.0                      0.0                  0.0   \n",
       "1                      0.0                      0.0                  0.0   \n",
       "2                      0.0                      0.0                  0.0   \n",
       "3                      0.0                      0.0                  0.0   \n",
       "4                      0.0                      0.0                  0.0   \n",
       "...                    ...                      ...                  ...   \n",
       "19315                  0.0                      0.0                  0.0   \n",
       "19316                  0.0                      0.0                  0.0   \n",
       "19317                  0.0                      0.0                  0.0   \n",
       "19318                  0.0                      0.0                  0.0   \n",
       "19319                  0.0                      0.0                  0.0   \n",
       "\n",
       "                                \n",
       "      RandomForestClassifier()  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "...                        ...  \n",
       "19315                      0.0  \n",
       "19316                      0.0  \n",
       "19317                      0.0  \n",
       "19318                      0.0  \n",
       "19319                      0.0  \n",
       "\n",
       "[19320 rows x 4 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_df['DeLong Test'].loc['ALL/PDE','LogisticRegression()']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">DeLong Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL/PDE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDE/PD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DeLong Test                         \n",
       "        LogisticRegression() RandomForestClassifier()\n",
       "ALL/PDE                  0.0                      0.0\n",
       "PDE/PD                   0.0                      0.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LogisticRegression()  RandomForestClassifier()\n",
       "0                       0.0                       0.0\n",
       "1                       0.0                       0.0\n",
       "2                       0.0                       0.0\n",
       "3                       0.0                       0.0\n",
       "4                       0.0                       0.0\n",
       "...                     ...                       ...\n",
       "19315                   0.0                       0.0\n",
       "19316                   0.0                       0.0\n",
       "19317                   0.0                       0.0\n",
       "19318                   0.0                       0.0\n",
       "19319                   0.0                       0.0\n",
       "\n",
       "[19320 rows x 2 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all['ALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ALL', 'LogisticRegression()')\n",
      "('ALL', 'RandomForestClassifier()')\n",
      "('NOPD', 'LogisticRegression()')\n",
      "('NOPD', 'RandomForestClassifier()')\n"
     ]
    }
   ],
   "source": [
    "for i in predict_df_all:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [LogisticRegression(), RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df_all = pd.DataFrame(np.zeros((1, len(base_models))), index=['ALL'], columns=[str(i) for i in predict_df_all['ALL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LogisticRegression()  RandomForestClassifier()\n",
       "ALL                   0.0                       0.0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LogisticRegression()  RandomForestClassifier()\n",
       "0                       0.0                       0.0\n",
       "1                       0.0                       0.0\n",
       "2                       0.0                       0.0\n",
       "3                       0.0                       0.0\n",
       "4                       0.0                       0.0\n",
       "...                     ...                       ...\n",
       "19315                   0.0                       0.0\n",
       "19316                   0.0                       0.0\n",
       "19317                   0.0                       0.0\n",
       "19318                   0.0                       0.0\n",
       "19319                   0.0                       0.0\n",
       "\n",
       "[19320 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all['ALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scoring(object):\n",
    "    def __init__(self, roc_auc, predict_df, base_models, chosen_set):\n",
    "        self.roc_auc = roc_auc\n",
    "        self.predict_df = predict_df\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def joined_scores(self):\n",
    "        roc_auc_all = pd.concat(self.roc_auc)\n",
    "        predict_df_all = pd.concat(self.predict_df, axis = 1)\n",
    "        return roc_auc_all, predict_df_all\n",
    "\n",
    "    def delong_test(predict_df_all, labels):\n",
    "        \n",
    "        Test_df_sets = pd.DataFrame(np.zeros((2, len(base_models))), index=['ALL/PDE','ALL/PD'], columns=[str(i) for i in base_models])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['DeLong Test'], Test_df_sets.columns])\n",
    "        \n",
    "        Test_df_all = pd.DataFrame(list(combinations(Test_df['DeLong Test'].columns,2)),columns = ['1st Algorithm', '2nd Algorithm', 'score'])\n",
    "        Test_df_all['score'] = 0\n",
    "        Test_df_all.columns = pd.MultiIndex.from_product([['DeLong Test'], Test_df_all.columns])    \n",
    "            \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            Test_df['DeLong Test'].loc['ALL/PDE',str(clf)] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PDE'][str(clf)])\n",
    "            Test_df['DeLong Test'].loc['ALL/PD',str(clf)] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PD'][str(clf)])\n",
    "            \n",
    "        for j in len(range(Test_df_all.shape[0])):\n",
    "            Test_df_all['DeLong Test'].loc[i,'score'] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][Test_df_all['DeLong Test'].loc[i,'1st Algorithm']], predict_df_all['ALL'][Test_df_all['DeLong Test'].loc[i,'2nd Algorithm']])\n",
    "    \n",
    "        return Test_df_sets, Test_df_all\n",
    "    \n",
    "    def bootstrap_test(predict_df_all, labels):\n",
    "    \n",
    "        Test_df_sets = pd.DataFrame(np.zeros((2, len(base_models))), index=['ALL/PDE','ALL/PD'], columns=[str(i) for i in base_models])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['Bootstrap Test'], Test_df_sets.columns])\n",
    "        \n",
    "        Test_df_all = pd.DataFrame(list(combinations(Test_df['Bootstrap Test'].columns,2)),columns = ['1st Algorithm', '2nd Algorithm', 'score'])\n",
    "        Test_df_all['score'] = 0\n",
    "        Test_df_all.columns = pd.MultiIndex.from_product([['Bootstrap Test'], Test_df_all.columns])\n",
    "            \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            Test_df['Bootstrap Test'].loc['ALL/PDE',str(clf)] = pvalue(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PDE'][str(clf)], score_fun=roc_auc_score)\n",
    "            Test_df['Bootstrap Test'].loc['ALL/PD',str(clf)] = pvalue(labels.values.ravel(), predict_df_all['ALL'][str(clf)], predict_df_all['PD'][str(clf)], score_fun=roc_auc_score)\n",
    "            \n",
    "        for j in len(range(Test_df_all.shape[0])):\n",
    "            Test_df_all['Bootstrap Test'].loc[i,'score'] = pvalue(labels.values.ravel(), predict_df_all['ALL'][Test_df_all['Bootstrap Test'].loc[i,'1st Algorithm']], predict_df_all['ALL'][Test_df_all['Bootstrap Test'].loc[i,'2nd Algorithm']], score_fun=roc_auc_score)\n",
    "    \n",
    "        return Test_df_sets, Test_df_all\n",
    "    \n",
    "    def likelihood_RT(predict_df_all, labels):\n",
    "    \n",
    "        Test_df_sets = pd.DataFrame((np.zeros((2, 1))), index=['ALL/PDE','ALL/PD'], columns=['LogisticRegression()'])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['LRT'], Test_df_sets.columns])\n",
    "\n",
    "        alt_log_likelihood = -log_loss(labels,\n",
    "                                       predict_df_all['ALL']['LogisticRegression()'],\n",
    "                                       normalize=False)\n",
    "        null_log_likelihood = -log_loss(ytest,\n",
    "                                        predict_df_all['PDE']['LogisticRegression()'],\n",
    "                                        normalize=False)\n",
    "        G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "        p_log_l = chi2.sf(G, x_train.shape[1])\n",
    "        \n",
    "        alt_log_likelihood = -log_loss(labels,\n",
    "                                       predict_df_all['ALL']['LogisticRegression()'],\n",
    "                                       normalize=False)\n",
    "        null_log_likelihood = -log_loss(ytest,\n",
    "                                        predict_df_all['PD']['LogisticRegression()'],\n",
    "                                        normalize=False)\n",
    "        G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "        \n",
    "        p_log_2 = chi2.sf(G, x_train.shape[1])\n",
    "        \n",
    "        Test_df_sets['LRT'].loc['ALL/PDE','LogisticRegression()'] = p_log_l\n",
    "        Test_df_sets['LRT'].loc['ALL/PD','LogisticRegression()'] = p_log_2\n",
    "\n",
    "        return Test_df_sets\n",
    "    \n",
    "    def combined_ftest_5x2cv(estimator1, estimator2, x_train, y_train, scoring, random_seed):\n",
    "\n",
    "        if isinstance(scoring, str):\n",
    "            scorer = get_scorer(scoring)\n",
    "        else:\n",
    "            scorer = scoring\n",
    "\n",
    "        variances = []\n",
    "        differences = []\n",
    "\n",
    "        def score_diff(X_1, X_2, y_1, y_2):\n",
    "\n",
    "            estimator1.fit(X_1, y_1)\n",
    "            estimator2.fit(X_1, y_1)\n",
    "            est1_score = scorer(estimator1, X_2, y_2)\n",
    "            est2_score = scorer(estimator2, X_2, y_2)\n",
    "            score_diff = est1_score - est2_score\n",
    "            return score_diff\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            X_1, X_2, y_1, y_2 = train_test_split(x_train, y_train, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            score_diff_1 = score_diff(X_1, X_2, y_1, y_2)\n",
    "            score_diff_2 = score_diff(X_2, X_1, y_2, y_1)\n",
    "            score_mean = (score_diff_1 + score_diff_2) / 2.\n",
    "            score_var = ((score_diff_1 - score_mean)**2 + (score_diff_2 - score_mean)**2)\n",
    "\n",
    "            differences.extend([score_diff_1**2, score_diff_2**2])\n",
    "            variances.append(score_var)\n",
    "\n",
    "        numerator = sum(differences)\n",
    "        denominator = 2*(sum(variances))\n",
    "        f_stat = numerator / denominator\n",
    "\n",
    "        p_value = scipy.stats.f.sf(f_stat, 10, 5)\n",
    "\n",
    "        return float(f_stat), float(p_value)\n",
    "    \n",
    "    def f_test(estimators_list, x_train, y_train):\n",
    "    \n",
    "        estimators = []\n",
    "        for i in range(len(self.base_models)):\n",
    "            estimators.append(estimators_list[i][2])\n",
    "        estimators = list(combinations(estimators,2))\n",
    "        \n",
    "        p_values = []\n",
    "\n",
    "        for i in range(len(estimators)): \n",
    "\n",
    "            estimator1 = eval(estimators[i][0])\n",
    "            estimator2 = eval(estimators[i][1])\n",
    "            \n",
    "            f_stat, p_value = combined_ftest_5x2cv(estimator1, estimator2, x_train, y_train, roc_auc_score, random_state)\n",
    "            \n",
    "            p_values.append(p_value)\n",
    "            \n",
    "        f_p_values = pd.DataFrame(columns = ['algorithm1', 'algorithm2', 'score'])    \n",
    "            \n",
    "        for j in range(len(estimators)): \n",
    "            a.loc[j,'algorithm1'] = estimators[j][0]\n",
    "            a.loc[j,'algorithm2'] = estimators[j][1]\n",
    "            a.loc[j,'score'] = p_values[j]\n",
    "        \n",
    "        return(f_p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yeoj_graph(x_train, lbd_list, feature=''):\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    for i in range(len(lbd_list)):\n",
    "        n_lines = len(lbd_list)\n",
    "        c = np.arange(1, n_lines + 1)\n",
    "        norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "        cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Blues)\n",
    "        cmap.set_array([])\n",
    "        a = x_train[feature].values.ravel()\n",
    "        a = np.sort(a)\n",
    "        b = stats.yeojohnson(x_train[feature], lmbda=lbd_list[i])\n",
    "        b = np.sort(b)\n",
    "        plt.plot(a,b, c=cmap.to_rgba(i + 1), label='Œª = '+str(lbd_list[i]))\n",
    "    plt.legend(loc=0)\n",
    "    plt.ylabel(\"œà(Œª,x)\", fontsize=15)\n",
    "    plt.xlabel(\"x\", fontsize=15)\n",
    "    plt.savefig('yeo-johnson.png', dpi=1200)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All vs without PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rdf_1 = delong_roc_test(ytest.values.ravel(), predict_rdf_1, predict_rdf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_rdf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping - it is possible that not probabilities but {0,1} has to be passed; then code needs to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rdf_2, z = pvalue(ytest.values.ravel(), predict_rdf_1, predict_rdf_2, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rdf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All vs only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rdf_3 = delong_roc_test(ytest.values.ravel(), predict_rdf_1, predict_rdf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rdf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_rdf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rdf_4, z = pvalue(ytest.values.ravel(), predict_rdf_1, predict_rdf_3, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rdf_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model CV\n",
    "scores = cross_val_score(rdf_1, xtest.values, ytest.values.ravel(), scoring='roc_auc')\n",
    "roc_auc = np.mean(scores)\n",
    "print('ROC AUC: %.2f%%' % (100*roc_auc))\n",
    "\n",
    "# Confidence interval\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. XGBoost Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_1 =  XGBClassifier(tree_method = 'exact',\n",
    "                     objective = 'binary:logistic',\n",
    "                     n_estimators = 1200,\n",
    "                     min_child_weight = 8,\n",
    "                     max_depth = 2,\n",
    "                     gamma = 0.3,\n",
    "                     reg_lambda = 90,\n",
    "                     learning_rate = 0.01,\n",
    "                     scale_pos_weight = 119.85522788203754,\n",
    "                     random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgb_1 = xgb_1.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgb_1 = predict_xgb_1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest, predict_xgb_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. PD Ommitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_2 = XGBClassifier(tree_method = 'auto',\n",
    "                     objective = 'binary:logistic',\n",
    "                     n_estimators = 1000,\n",
    "                     min_child_weight = 4,\n",
    "                     max_depth = 2,\n",
    "                     gamma = 0.5,\n",
    "                     reg_lambda = 50,\n",
    "                     learning_rate = 0.01,\n",
    "                     scale_pos_weight = 119.85522788203754,\n",
    "                     random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_2.fit(xtrain_nopd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgb_2 = xgb_2.predict_proba(xtest_nopd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgb_2 = predict_xgb_2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest, predict_xgb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_3 =  XGBClassifier(tree_method = 'hist',\n",
    "                     objective = 'binary:logistic',\n",
    "                     n_estimators = 200,\n",
    "                     min_child_weight = 3,\n",
    "                     max_depth = 2,\n",
    "                     gamma = 0.0,\n",
    "                     reg_lambda = 50,\n",
    "                     learning_rate = 0.01,\n",
    "                     scale_pos_weight = 119.85522788203754,\n",
    "                     random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_3.fit(xtrain_pd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgb_3 = xgb_3.predict_proba(xtest_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xgb_3 = predict_xgb_3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest, predict_xgb_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Bootstraping and DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All vs without PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_1 = delong_roc_test(ytest.values.ravel(), predict_xgb_1, predict_xgb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_xgb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_2, z = pvalue(ytest.values.ravel(), predict_xgb_1, predict_xgb_2, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All vs only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_3 = delong_roc_test(ytest.values.ravel(), predict_xgb_1, predict_xgb_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_xgb_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_4, z = pvalue(ytest.values.ravel(), predict_xgb_1, predict_xgb_3, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_1 =  LogisticRegression(penalty = 'l2',\n",
    "                         solver = 'lbfgs',\n",
    "                         class_weight = 'balanced',\n",
    "                         random_state = random_state,\n",
    "                         C = 0.03359818286283781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.03359818286283781, class_weight='balanced',\n",
       "                   random_state=2020)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_1 = log_1.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_1 = predict_log_1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9225326200417537"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest, predict_log_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. PD Ommitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_2 =  LogisticRegression(penalty = 'l2',\n",
    "                         solver = 'newton-cg',\n",
    "                         class_weight = 'balanced',\n",
    "                         random_state = random_state,\n",
    "                         C = 0.03359818286283781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_nopd = xtrain.loc[:,xtrain.columns != 'pd']\n",
    "xtest_nopd = xtest.loc[:,xtest.columns != 'pd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.03359818286283781, class_weight='balanced',\n",
       "                   random_state=2020, solver='newton-cg')"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_2.fit(xtrain_nopd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_2 = log_2.predict_proba(xtest_nopd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_2 = predict_log_2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135914665970772"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest, predict_log_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atch</th>\n",
       "      <th>empch</th>\n",
       "      <th>salech</th>\n",
       "      <th>roech</th>\n",
       "      <th>ptbch</th>\n",
       "      <th>dlcpdlttdebit</th>\n",
       "      <th>nwcdta</th>\n",
       "      <th>redat</th>\n",
       "      <th>ebitdat</th>\n",
       "      <th>mvaluedtd</th>\n",
       "      <th>...</th>\n",
       "      <th>dtdat</th>\n",
       "      <th>actdlct</th>\n",
       "      <th>quickratio</th>\n",
       "      <th>bvdmv</th>\n",
       "      <th>nidseq</th>\n",
       "      <th>actdnat</th>\n",
       "      <th>ebitdxint</th>\n",
       "      <th>redsale</th>\n",
       "      <th>nidsale</th>\n",
       "      <th>ebitdsale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34821</th>\n",
       "      <td>0.074614</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>-0.090583</td>\n",
       "      <td>1.198695</td>\n",
       "      <td>3.837877</td>\n",
       "      <td>0.786032</td>\n",
       "      <td>0.219158</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.027980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047381</td>\n",
       "      <td>5.279364</td>\n",
       "      <td>0.672710</td>\n",
       "      <td>0.467244</td>\n",
       "      <td>0.011865</td>\n",
       "      <td>1.225588</td>\n",
       "      <td>0.226686</td>\n",
       "      <td>0.281262</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.015844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43997</th>\n",
       "      <td>0.066593</td>\n",
       "      <td>0.523044</td>\n",
       "      <td>0.653347</td>\n",
       "      <td>4.288486</td>\n",
       "      <td>21.293688</td>\n",
       "      <td>-5.435913</td>\n",
       "      <td>-0.005221</td>\n",
       "      <td>-0.318094</td>\n",
       "      <td>-0.133187</td>\n",
       "      <td>0.353727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723993</td>\n",
       "      <td>0.950281</td>\n",
       "      <td>0.753601</td>\n",
       "      <td>0.042694</td>\n",
       "      <td>-2.321567</td>\n",
       "      <td>1.142058</td>\n",
       "      <td>-0.515496</td>\n",
       "      <td>-0.931641</td>\n",
       "      <td>-0.572588</td>\n",
       "      <td>-0.390082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37849</th>\n",
       "      <td>0.151686</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.113960</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-1.813216</td>\n",
       "      <td>1.146984</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.384759</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>0.103472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113766</td>\n",
       "      <td>1.040633</td>\n",
       "      <td>0.287743</td>\n",
       "      <td>0.455054</td>\n",
       "      <td>0.122928</td>\n",
       "      <td>0.796451</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>0.115344</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>0.029735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61278</th>\n",
       "      <td>0.233387</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.244911</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>-0.380435</td>\n",
       "      <td>11.589041</td>\n",
       "      <td>0.524310</td>\n",
       "      <td>-1.226347</td>\n",
       "      <td>0.023982</td>\n",
       "      <td>1.947670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277924</td>\n",
       "      <td>2.198198</td>\n",
       "      <td>0.792042</td>\n",
       "      <td>3.469431</td>\n",
       "      <td>-0.257465</td>\n",
       "      <td>1.942933</td>\n",
       "      <td>4.577400</td>\n",
       "      <td>-1.849851</td>\n",
       "      <td>-0.192270</td>\n",
       "      <td>0.036174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>0.079972</td>\n",
       "      <td>0.029520</td>\n",
       "      <td>0.138705</td>\n",
       "      <td>0.011085</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>4.711203</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>0.165614</td>\n",
       "      <td>0.062117</td>\n",
       "      <td>0.399008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292645</td>\n",
       "      <td>1.230389</td>\n",
       "      <td>0.951531</td>\n",
       "      <td>0.420929</td>\n",
       "      <td>0.089412</td>\n",
       "      <td>0.241834</td>\n",
       "      <td>0.318678</td>\n",
       "      <td>0.494824</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.185593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20751</th>\n",
       "      <td>0.113819</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.138292</td>\n",
       "      <td>-0.025657</td>\n",
       "      <td>0.581703</td>\n",
       "      <td>1.278457</td>\n",
       "      <td>0.394583</td>\n",
       "      <td>0.523434</td>\n",
       "      <td>0.148059</td>\n",
       "      <td>0.133484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>3.457386</td>\n",
       "      <td>2.257829</td>\n",
       "      <td>0.386293</td>\n",
       "      <td>0.173398</td>\n",
       "      <td>1.013454</td>\n",
       "      <td>0.083159</td>\n",
       "      <td>0.443786</td>\n",
       "      <td>0.077263</td>\n",
       "      <td>0.125529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32829</th>\n",
       "      <td>0.241142</td>\n",
       "      <td>0.134888</td>\n",
       "      <td>0.192826</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>1.480461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435059</td>\n",
       "      <td>0.396876</td>\n",
       "      <td>0.182044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.977005</td>\n",
       "      <td>1.808575</td>\n",
       "      <td>0.141071</td>\n",
       "      <td>0.245877</td>\n",
       "      <td>1.587080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355831</td>\n",
       "      <td>0.122283</td>\n",
       "      <td>0.163217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28330</th>\n",
       "      <td>0.030897</td>\n",
       "      <td>0.146051</td>\n",
       "      <td>0.143349</td>\n",
       "      <td>0.110031</td>\n",
       "      <td>-0.842300</td>\n",
       "      <td>1.157527</td>\n",
       "      <td>0.290178</td>\n",
       "      <td>0.328776</td>\n",
       "      <td>0.235045</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272071</td>\n",
       "      <td>1.860646</td>\n",
       "      <td>1.082056</td>\n",
       "      <td>0.181488</td>\n",
       "      <td>0.450480</td>\n",
       "      <td>1.633864</td>\n",
       "      <td>0.045712</td>\n",
       "      <td>0.303109</td>\n",
       "      <td>0.159116</td>\n",
       "      <td>0.216696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44680</th>\n",
       "      <td>0.129805</td>\n",
       "      <td>0.162963</td>\n",
       "      <td>0.094389</td>\n",
       "      <td>-0.059211</td>\n",
       "      <td>0.060807</td>\n",
       "      <td>18.607639</td>\n",
       "      <td>-0.226996</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.032461</td>\n",
       "      <td>3.800677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604019</td>\n",
       "      <td>0.382717</td>\n",
       "      <td>0.268883</td>\n",
       "      <td>1.494953</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.592372</td>\n",
       "      <td>0.864308</td>\n",
       "      <td>0.113165</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.079928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38200</th>\n",
       "      <td>0.102150</td>\n",
       "      <td>0.075953</td>\n",
       "      <td>0.386879</td>\n",
       "      <td>-0.023225</td>\n",
       "      <td>0.909583</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.233875</td>\n",
       "      <td>0.603745</td>\n",
       "      <td>0.180753</td>\n",
       "      <td>0.073117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125371</td>\n",
       "      <td>2.401157</td>\n",
       "      <td>0.955424</td>\n",
       "      <td>0.390236</td>\n",
       "      <td>0.171664</td>\n",
       "      <td>0.598980</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.270252</td>\n",
       "      <td>0.051058</td>\n",
       "      <td>0.080910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           atch     empch    salech     roech      ptbch  dlcpdlttdebit  \\\n",
       "34821  0.074614  0.395604  0.001913 -0.090583   1.198695       3.837877   \n",
       "43997  0.066593  0.523044  0.653347  4.288486  21.293688      -5.435913   \n",
       "37849  0.151686  0.069767  0.113960 -0.000376  -1.813216       1.146984   \n",
       "61278  0.233387  0.200000  0.244911  0.076141  -0.380435      11.589041   \n",
       "3616   0.079972  0.029520  0.138705  0.011085   0.504975       4.711203   \n",
       "...         ...       ...       ...       ...        ...            ...   \n",
       "20751  0.113819  0.112600  0.138292 -0.025657   0.581703       1.278457   \n",
       "32829  0.241142  0.134888  0.192826  0.024265   1.480461       0.000000   \n",
       "28330  0.030897  0.146051  0.143349  0.110031  -0.842300       1.157527   \n",
       "44680  0.129805  0.162963  0.094389 -0.059211   0.060807      18.607639   \n",
       "38200  0.102150  0.075953  0.386879 -0.023225   0.909583       0.693603   \n",
       "\n",
       "         nwcdta     redat   ebitdat  mvaluedtd  ...     dtdat   actdlct  \\\n",
       "34821  0.786032  0.219158  0.012346   0.027980  ...  0.047381  5.279364   \n",
       "43997 -0.005221 -0.318094 -0.133187   0.353727  ...  0.723993  0.950281   \n",
       "37849  0.015560  0.384759  0.099188   0.103472  ...  0.113766  1.040633   \n",
       "61278  0.524310 -1.226347  0.023982   1.947670  ...  0.277924  2.198198   \n",
       "3616   0.013980  0.165614  0.062117   0.399008  ...  0.292645  1.230389   \n",
       "...         ...       ...       ...        ...  ...       ...       ...   \n",
       "20751  0.394583  0.523434  0.148059   0.133484  ...  0.189286  3.457386   \n",
       "32829  0.435059  0.396876  0.182044   0.000000  ...  0.000000  1.977005   \n",
       "28330  0.290178  0.328776  0.235045   0.128600  ...  0.272071  1.860646   \n",
       "44680 -0.226996  0.045959  0.032461   3.800677  ...  0.604019  0.382717   \n",
       "38200  0.233875  0.603745  0.180753   0.073117  ...  0.125371  2.401157   \n",
       "\n",
       "       quickratio     bvdmv    nidseq   actdnat  ebitdxint   redsale  \\\n",
       "34821    0.672710  0.467244  0.011865  1.225588   0.226686  0.281262   \n",
       "43997    0.753601  0.042694 -2.321567  1.142058  -0.515496 -0.931641   \n",
       "37849    0.287743  0.455054  0.122928  0.796451   0.036940  0.115344   \n",
       "61278    0.792042  3.469431 -0.257465  1.942933   4.577400 -1.849851   \n",
       "3616     0.951531  0.420929  0.089412  0.241834   0.318678  0.494824   \n",
       "...           ...       ...       ...       ...        ...       ...   \n",
       "20751    2.257829  0.386293  0.173398  1.013454   0.083159  0.443786   \n",
       "32829    1.808575  0.141071  0.245877  1.587080   0.000000  0.355831   \n",
       "28330    1.082056  0.181488  0.450480  1.633864   0.045712  0.303109   \n",
       "44680    0.268883  1.494953  0.011704  0.592372   0.864308  0.113165   \n",
       "38200    0.955424  0.390236  0.171664  0.598980   0.049072  0.270252   \n",
       "\n",
       "        nidsale  ebitdsale  \n",
       "34821  0.012048   0.015844  \n",
       "43997 -0.572588  -0.390082  \n",
       "37849  0.018058   0.029735  \n",
       "61278 -0.192270   0.036174  \n",
       "3616   0.082474   0.185593  \n",
       "...         ...        ...  \n",
       "20751  0.077263   0.125529  \n",
       "32829  0.122283   0.163217  \n",
       "28330  0.159116   0.216696  \n",
       "44680  0.006491   0.079928  \n",
       "38200  0.051058   0.080910  \n",
       "\n",
       "[19320 rows x 22 columns]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_nopd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_3 =  LogisticRegression(penalty = 'l1',\n",
    "                         solver = 'liblinear',\n",
    "                         class_weight = 'balanced',\n",
    "                         random_state = random_state,\n",
    "                         C = 0.0006951927961775605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_3.fit(xtrain_pd,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_3 = log_3.predict_proba(xtest_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_3 = predict_log_3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(ytest, predict_log_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Bootstraping and DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All vs without PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_1 = delong_roc_test(ytest.values.ravel(), predict_log_1, predict_log_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_log_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_2, z = pvalue(ytest.values.ravel(), predict_log_1, predict_log_2, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All vs only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_3 = delong_roc_test(ytest.values.ravel(), predict_log_1, predict_log_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_log_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_4, z = pvalue(ytest.values.ravel(), predict_log_1, predict_log_3,score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macimum Likelihood Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All/without PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ALL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">NOPD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ALL                                          NOPD  \\\n",
       "      LogisticRegression() RandomForestClassifier() LogisticRegression()   \n",
       "0                      0.0                      0.0                  0.0   \n",
       "1                      0.0                      0.0                  0.0   \n",
       "2                      0.0                      0.0                  0.0   \n",
       "3                      0.0                      0.0                  0.0   \n",
       "4                      0.0                      0.0                  0.0   \n",
       "...                    ...                      ...                  ...   \n",
       "19315                  0.0                      0.0                  0.0   \n",
       "19316                  0.0                      0.0                  0.0   \n",
       "19317                  0.0                      0.0                  0.0   \n",
       "19318                  0.0                      0.0                  0.0   \n",
       "19319                  0.0                      0.0                  0.0   \n",
       "\n",
       "                                \n",
       "      RandomForestClassifier()  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "...                        ...  \n",
       "19315                      0.0  \n",
       "19316                      0.0  \n",
       "19317                      0.0  \n",
       "19318                      0.0  \n",
       "19319                      0.0  \n",
       "\n",
       "[19320 rows x 4 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_RT():\n",
    "    \n",
    "    Test_df_sets = pd.DataFrame(np.zeros((2, len('LogisticRegression()'))), index=['ALL/PDE','ALL/PD'], columns=['LogisticRegression()'])\n",
    "    Test_df_sets.columns = pd.MultiIndex.from_product([['LRT'], Test_df_sets.columns])\n",
    "    \n",
    "    alt_log_likelihood = -log_loss(labels,\n",
    "                                   predict_log_1,\n",
    "                                   normalize=False)\n",
    "    null_log_likelihood = -log_loss(ytest,\n",
    "                                    predict_log_2,\n",
    "                                    normalize=False)\n",
    "    G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "    p_log_l = chi2.sf(G, xtrain.shape[1])\n",
    "    \n",
    "    return Test_df_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_log_likelihood = -log_loss(ytest,\n",
    "                               predict_log_1,\n",
    "                               normalize=False)\n",
    "null_log_likelihood = -log_loss(ytest,\n",
    "                                predict_log_2,\n",
    "                                normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "p_log_l = chi2.sf(G, xtrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All/Only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_log_likelihood = -log_loss(ytest,\n",
    "                               predict_log_1,\n",
    "                               normalize=False)\n",
    "null_log_likelihood = -log_loss(ytest,\n",
    "                                predict_log_3,\n",
    "                                normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "p_log_2 = chi2.sf(G, xtrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Models ROC Curves Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF vs XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf_xgb = delong_roc_test(ytest.values.ravel(), predict_rdf_1, predict_xgb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_rf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf_xgb2, z = pvalue(ytest.values.ravel(), predict_xgb_1, predict_rdf_1, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf_xgb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF vs LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf_logreg = delong_roc_test(ytest.values.ravel(), predict_rdf_1, predict_log_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_rf_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf_logreg2, z = pvalue(ytest.values.ravel(), predict_rdf_1, predict_log_1, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf_logreg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost vs LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeLong Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_logreg = delong_roc_test(ytest.values.ravel(), predict_xgb_1, predict_log_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(p_xgb_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_logreg2, z = pvalue(ytest.values.ravel(), predict_xgb_1, predict_log_1, score_fun=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb_logreg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Bootstraping Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(clf, X_train, y_train, X_test, y_test): \n",
    "#     xtest_1 = np.array(X_test)\n",
    "#     ytest_1 = np.array(y_test)\n",
    "    \n",
    "#     folds = list(StratifiedKFold(n_splits=5, shuffle=True, \n",
    "#                              random_state = random_state).split(xtest_1, ytest_1))\n",
    "    \n",
    "#     x_list = np.zeros((len(folds[0][0]), len(folds)))\n",
    "#     y_list = np.zeros((len(folds[0][0]), len(folds)))\n",
    "\n",
    "#     for j, (train_idx, valid_idx) in enumerate(folds):\n",
    "\n",
    "#         X_valid = xtest_1[train_idx]\n",
    "#         Y_valid = ytest_1[train_idx]\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "\n",
    "#         valid_pred = clf.predict_proba(X_valid)[:,1]\n",
    "\n",
    "#         y_list[:,j] = Y_valid[:,0]\n",
    "#         x_list[:,j] = valid_pred\n",
    "\n",
    "#     return y_list, x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf_list_y, rdf_list_x = predict(rdf_1, xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapped_rdf_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,5): \n",
    "#     bootstrapped_rdf = bootstrap_error_estimate(rdf_list_x[:,i], rdf_list_y[:,i],method)\n",
    "#     lower = bootstrapped_rdf_1.append(bootstrapped_rdf[0])\n",
    "#     upper = bootstrapped_rdf_1.append(bootstrapped_rdf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_classifier(object):\n",
    "    def __init__(self, n_splits, base_models, grids):\n",
    "        self.n_splits = n_splits\n",
    "        self.base_models = base_models\n",
    "        self.grids = grids\n",
    "\n",
    "    def predict(self, x_train, y_train, x_test, y_test, chosen_set = ''):\n",
    "        \n",
    "#         x_train = x_train\n",
    "#         x_test =x_test\n",
    "        \n",
    "#         x_train_nopd = x_train.loc[:,x_train.columns != Merton_label]\n",
    "#         x_test_nopd = x_test.loc[:,x_test.columns != Merton_label]\n",
    "        \n",
    "#         x_train_pd = x_train.loc[:,x_train.columns == Merton_label]\n",
    "#         x_test_pd = x_test.loc[:,x_test.columns == Merton_label]\n",
    "        \n",
    "#         chosen_train_set = [x_train, x_train_nopd, x_train_pd]\n",
    "#         chosen_test_set = [x_test, x_test_nopd, x_test_pd]\n",
    "        \n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state = random_state)\n",
    "                  \n",
    "        roc_auc_scores = pd.DataFrame(columns = [str(i) for i in self.base_models])\n",
    "        test_pred = pd.DataFrame(np.zeros((x_test.shape[0], len(self.base_models))), columns=[str(i) for i in self.base_models])\n",
    "        test_pred.columns = pd.MultiIndex.from_product([[chosen_set], test_pred.columns])\n",
    "        feat_selected = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "        feat_importance = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "                  \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            for train_index, test_index in cv.split(x_train):\n",
    "        \n",
    "            pipe_lr = make_pipeline(PowerTransformer(method='yeo-johnson',standardize = True),\n",
    "                                    RFECV(estimator = clf, step = 1, cv=cv, scoring = 'roc_auc'),\n",
    "                                    clf)\n",
    "                  \n",
    "            search = RandomizedSearchCV(estimator=pipe_lr, param_distributions = self.grids[i], cv = cv, n_jobs=-1, verbose=True, scoring = 'roc_auc')\n",
    "            search.fit(x_train, y_train)        \n",
    "            \n",
    "            predict_rdf = search.predict_proba(x_test)[:,1]\n",
    "            test_pred[chosen_set][str(clf)] = predict_rdf\n",
    "                  \n",
    "            roc_auc_scores.loc[0,str(clf)] = roc_auc_score(y_test, predict_rdf)\n",
    "                  \n",
    "            for j in x_train.columns:\n",
    "                feat_est = dict(zip(x_train.columns, search.best_estimator_.named_steps[\"rfecv\"].ranking_))\n",
    "                feat_selected.loc[str(j), str(clf)] = feat_est[str(j)]\n",
    "                \n",
    "                try:\n",
    "                    importances = dict(zip(x_train.columns, search.best_estimator_.named_steps[str(clf).split('(')[0].lower()].feature_importances_))\n",
    "                    feat_importance.loc[str(j), str(clf)] = importances[str(j)]\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            estimator1.fit(X_train, y_train)\n",
    "            est1_score = scorer(estimator1, X_test, y_test)\n",
    "            score_diff.append(est1_score - est2_score)\n",
    "            \n",
    "            estimator2.fit(X_train, y_train)\n",
    "                \n",
    "        return roc_auc_scores, feat_selected, feat_importance, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(x,y):\n",
    "    return roc_auc_score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_error_estimate(pred, truth, method, method_name=\"\", alpha=0.95, sample_frac=0.5, iterations=2000):\n",
    "    \"\"\"\n",
    "    Generate a bootstrapped estimate of confidence intervals\n",
    "    :param pred: list of predicted values\n",
    "    :param truth: list of experimental values\n",
    "    :param method: method to evaluate performance, e.g. matthews_corrcoef\n",
    "    :param method_name: name of the method for the progress bar\n",
    "    :param alpha: confidence limit (e.g. 0.95 for 95% confidence interval)\n",
    "    :param sample_frac: fraction to resample for bootstrap confidence interval\n",
    "    :param iterations: number of iterations for resampling\n",
    "    :return: lower and upper bounds for confidence intervals\n",
    "    \"\"\"\n",
    "    index_list = range(0, len(pred))\n",
    "    num_samples = int(len(index_list) * sample_frac)\n",
    "    stats = []\n",
    "    for _ in range(0, iterations):\n",
    "        sample_idx = resample(index_list, n_samples=num_samples)\n",
    "        pred_sample = [pred[x] for x in sample_idx]\n",
    "        truth_sample = [truth[x] for x in sample_idx]\n",
    "        stats.append(method(truth_sample, pred_sample))\n",
    "    p = ((1.0 - alpha) / 2.0) * 100\n",
    "    lower = max(0.0, np.percentile(stats, p))\n",
    "    p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "    upper = min(1.0, np.percentile(stats, p))\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(self.base_models):\n",
    "    predict_df_all[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_graph(predict_df_all, ):\n",
    "\n",
    "    columns = []\n",
    "    delong = []\n",
    "    bootstrap = []\n",
    "\n",
    "    for i in predict_df_all.columns:\n",
    "        columns.append(i)\n",
    "        \n",
    "    for j in enumerate(columns):\n",
    "        delong.append(calc_auc_ci(ytest.values.ravel(), predict_df_all[columns[j]], alpha=0.95))\n",
    "        bootstrap.append(bootstrap_error_estimate(ytest.values.ravel(), predict_df_all[columns[j]], roc_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "delong = []\n",
    "bootstrap = []\n",
    "\n",
    "for i in predict_df_all.columns:\n",
    "    columns.append(i)\n",
    "    for j in enumerate(columns):\n",
    "        delong.append(calc_auc_ci(ytest.values.ravel(), predict_df_all[columns[j[0]]], alpha=0.95))\n",
    "#         bootstrap.append(bootstrap_error_estimate(ytest.values.ravel(), predict_df_all[columns[j]], roc_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-787b984a6e3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdelong\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'delong' is not defined"
     ]
    }
   ],
   "source": [
    "delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "19315    0.0\n",
       "19316    0.0\n",
       "19317    0.0\n",
       "19318    0.0\n",
       "19319    0.0\n",
       "Name: (ALL, LogisticRegression()), Length: 19320, dtype: float64"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all[columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-e22880d9057b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdelong\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'delong' is not defined"
     ]
    }
   ],
   "source": [
    "delong[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for i in predict_df_all.columns:\n",
    "    columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALL'"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong = []\n",
    "\n",
    "for j in enumerate(columns):\n",
    "    delong.append(calc_auc_ci(ytest.values.ravel(), predict_df_all[columns[j[0]]], alpha=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ALL', 'LogisticRegression()')\n",
      "('ALL', 'RandomForestClassifier()')\n",
      "('NOPD', 'LogisticRegression()')\n",
      "('NOPD', 'RandomForestClassifier()')\n"
     ]
    }
   ],
   "source": [
    "for j in enumerate(columns):\n",
    "    print(columns[j[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([nan, nan]), array([nan, nan]), array([nan, nan]), array([nan, nan])]"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "\n",
    "for i in predict_df_all.columns:\n",
    "    columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ALL', 'LogisticRegression()'),\n",
       " ('ALL', 'RandomForestClassifier()'),\n",
       " ('NOPD', 'LogisticRegression()'),\n",
       " ('NOPD', 'RandomForestClassifier()')]"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong = []\n",
    "for j,k in enumerate(columns):\n",
    "    delong.append(calc_auc_ci(ytest.values.ravel(), predict_df_all[columns[j]], alpha=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([nan, nan]), array([nan, nan]), array([nan, nan]), array([nan, nan])]"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "19315    0.0\n",
       "19316    0.0\n",
       "19317    0.0\n",
       "19318    0.0\n",
       "19319    0.0\n",
       "Name: (ALL, LogisticRegression()), Length: 19320, dtype: float64"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all[columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([( 'ALL',     'LogisticRegression()'),\n",
       "            ( 'ALL', 'RandomForestClassifier()'),\n",
       "            ('NOPD',     'LogisticRegression()'),\n",
       "            ('NOPD', 'RandomForestClassifier()')],\n",
       "           )"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "for i in base_models:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df_all.loc[:, predict_df_all.columns.get_level_values(1).isin([str(i) for i in self.base_models])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-564-346d4c838a5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdelong\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredict_df_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_df_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LogisticRegression()'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdelong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_auc_ci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_df_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "delong = []\n",
    "for j in predict_df_all.loc[:, predict_df_all.columns.get_level_values(1).isin(['LogisticRegression()'])]:\n",
    "    delong.append(calc_auc_ci(ytest.values.ravel(), predict_df_all[columns[j[1]]], alpha=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for j in list(range(3)):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong = []\n",
    "for i in base_models:\n",
    "    for j in list(range(3)):\n",
    "        delong.append(calc_auc_ci(ytest.values.ravel(), predict_df_all.loc[:, predict_df_all.columns.get_level_values(1).isin([str(i) for i in base_models])].values[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_rdf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_rdf_2 = bootstrap_error_estimate(a, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_rdf_3 = bootstrap_error_estimate(predict_rdf_3, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_rdf_1 = calc_auc_ci(ytest.values.ravel(), a.values.ravel(), alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_rdf_2 = calc_auc_ci(ytest.values.ravel(), predict_rdf_2.values, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_rdf_3 = calc_auc_ci(ytest.values.ravel(), predict_rdf_3, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_bootstraps = 2000\n",
    "# rng_seed = 42  # control reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rdf_1\n",
    "# bootstrapped_rdf_1 = []\n",
    "# indices = rng.randint(0, len(predict_rdf_1), len(predict_rdf_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rdf_2\n",
    "# bootstrapped_rdf_2 = []\n",
    "# indices = rng.randint(0, len(predict_rdf_2), len(predict_rdf_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rdf_3\n",
    "# bootstrapped_rdf_3 = []\n",
    "# indices = rng.randint(0, len(predict_rdf_3), len(predict_rdf_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.RandomState(rng_seed)\n",
    "# for i in range(n_bootstraps):\n",
    "#     # bootstrap by sampling with replacement on the prediction indices\n",
    "#     indices = rng.randint(0, len(predict_rdf_3), len(predict_rdf_3))\n",
    "#     if len(np.unique(ytest)) < 2:\n",
    "#         # We need at least one positive and one negative sample for ROC AUC\n",
    "#         # to be defined: reject the sample\n",
    "#         continue\n",
    "\n",
    "#     score = roc_auc_score(ytest.values.ravel()[indices], predict_rdf_3[indices])\n",
    "#     bootstrapped_rdf_3.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapped_rdf_1 = np.array(bootstrapped_rdf_1)\n",
    "# bootstrapped_rdf_1.sort()\n",
    "\n",
    "# # Computing the lower and upper bound of the 90% confidence interval\n",
    "# # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# # a 95% confidence interval instead.\n",
    "# confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "# confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "# print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "#     confidence_lower, confidence_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervals = []\n",
    "# sample_means = []\n",
    "\n",
    "# for sample in data_to_plot_rdf:\n",
    "#     sample_mean = np.mean(sample)\n",
    "#     sample_means.append(sample_mean)\n",
    "\n",
    "#     sorted_scores = np.array(sample)\n",
    "#     sorted_scores.sort()\n",
    "\n",
    "#     # Computing the lower and upper bound of the 90% confidence interval\n",
    "#     # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "#     # a 95% confidence interval instead.\n",
    "#     confidence_lower = sorted_scores[int(0.0025 * len(sorted_scores))]\n",
    "#     confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "\n",
    "#     confidence_interval = (confidence_lower,\n",
    "#                            confidence_upper)  \n",
    "    \n",
    "#     intervals.append(confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_rdf = [bootstrapped_rdf_1, bootstrapped_rdf_2, bootstrapped_rdf_3, delong_rdf_1, delong_rdf_2, delong_rdf_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_graph(predict_df_all, ):\n",
    "\n",
    "    columns = []\n",
    "    delong = []\n",
    "    bootstrap = []\n",
    "\n",
    "    for i in predict_df_all.columns:\n",
    "        columns.append(i)\n",
    "        \n",
    "    for j in enumerate(columns):\n",
    "        delong.append([columns[j], calc_auc_ci(ytest.values.ravel(), predict_df_all[columns[0]], alpha=0.95)])\n",
    "        bootstrap.append([columns[j], bootstrap_error_estimate(ytest.values.ravel(), predict_df_all[columns[0]], roc_auc_score)])\n",
    "    \n",
    "    delong_df = pd.DataFrame(columns = ['Set', 'Algorithm', 'Score'])\n",
    "    b = pd.DataFrame(columns = ['Set', 'Algorithm', 'Score'])\n",
    "    \n",
    "    for j in range(len(delong)): \n",
    "        a.loc[j,'set'] = delong[j][0]\n",
    "        a.loc[j,'algorithm'] = delong[j][1]\n",
    "        a.loc[j,'score'] = delong[j][0]\n",
    "        b.loc[j,'set'] = bootstrap[j][0]\n",
    "        b.loc[j,'algorithm'] = bootstrap[j][1]\n",
    "        b.loc[j,'score'] = bootstrap[j][0]\n",
    "        \n",
    "    a.groupby(['algorithm'])[['Set', 'Score']].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ALL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">NOPD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ALL  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "19315                                   0.0   \n",
       "19316                                   0.0   \n",
       "19317                                   0.0   \n",
       "19318                                   0.0   \n",
       "19319                                   0.0   \n",
       "\n",
       "                                                 \\\n",
       "      RandomForestClassifier(random_state=2020)   \n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "...                                         ...   \n",
       "19315                                       0.0   \n",
       "19316                                       0.0   \n",
       "19317                                       0.0   \n",
       "19318                                       0.0   \n",
       "19319                                       0.0   \n",
       "\n",
       "                                       NOPD  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "19315                                   0.0   \n",
       "19316                                   0.0   \n",
       "19317                                   0.0   \n",
       "19318                                   0.0   \n",
       "19319                                   0.0   \n",
       "\n",
       "                                                 \n",
       "      RandomForestClassifier(random_state=2020)  \n",
       "0                                           0.0  \n",
       "1                                           0.0  \n",
       "2                                           0.0  \n",
       "3                                           0.0  \n",
       "4                                           0.0  \n",
       "...                                         ...  \n",
       "19315                                       0.0  \n",
       "19316                                       0.0  \n",
       "19317                                       0.0  \n",
       "19318                                       0.0  \n",
       "19319                                       0.0  \n",
       "\n",
       "[19320 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df3 = pd.DataFrame(np.zeros((xtest.shape[0], len(base_models))), columns=[str(i) for i in base_models])\n",
    "pred_df3.columns = pd.MultiIndex.from_product([['PD'], pred_df3.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_all = [pred_df,pred_df2,pred_df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat(pred_df_all, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.iloc[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pred_df.values.shape[0]):\n",
    "    pred_df.iloc[i][0] = random()\n",
    "    pred_df.iloc[i][1] = random()\n",
    "    pred_df.iloc[i][2] = random()\n",
    "    pred_df.iloc[i][3] = random()\n",
    "    pred_df.iloc[i][4] = random()\n",
    "    pred_df.iloc[i][5] = random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pred_df.copy(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3241478056110484"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "delong = []\n",
    "bootstrap = []\n",
    "\n",
    "for i in predict_df.columns:\n",
    "    columns.append(i)\n",
    "\n",
    "for j in enumerate(columns):\n",
    "    delong.append([columns[j], calc_auc_ci(ytest.values.ravel(), predict_df[columns[0]], alpha=0.95)])\n",
    "    bootstrap.append([columns[j], bootstrap_error_estimate(ytest.values.ravel(), predict_df[columns[0]], roc_auc_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(random_state=2020),\n",
       " RandomForestClassifier(random_state=2020)]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ALL', 'LogisticRegression(random_state=2020)')"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong = []\n",
    "for i,j in enumerate(columns):\n",
    "    delong.append([columns[i], calc_auc_ci(ytest.values.ravel(), predict_df[columns[i]], alpha=0.95)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ALL', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.470688  , 0.56133249])],\n",
       " [('ALL', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.49467452, 0.58076716])],\n",
       " [('NOPD', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.46338199, 0.55223387])],\n",
       " [('NOPD', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.47753506, 0.5634207 ])],\n",
       " [('PD', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.4610133, 0.5505779])],\n",
       " [('PD', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.48170062, 0.57266068])]]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong = []\n",
    "delong.append([columns[0], calc_auc_ci(ytest.values.ravel(), predict_df[columns[0]], alpha=0.95)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ALL', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.470688  , 0.56133249])]]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15885549, 0.97321207, 0.04793046, ..., 0.53369612, 0.54307258,\n",
       "       0.78709885])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[columns[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap.append([columns[0], bootstrap_error_estimate(predict_df[columns[0]], ytest.values.ravel(), roc_auc_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-340-4f677fc87b6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdelong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalc_auc_ci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap_error_estimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-3a473bf85809>\u001b[0m in \u001b[0;36mbootstrap_error_estimate\u001b[1;34m(pred, truth, method, method_name, alpha, sample_frac, iterations)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mpred_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mtruth_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruth_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mlower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                      sample_weight=sample_weight)\n\u001b[0;32m    394\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         return _average_binary_score(partial(_binary_roc_auc_score,\n\u001b[0m\u001b[0;32m    396\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    397\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(columns):\n",
    "    delong.append([columns[i], calc_auc_ci(ytest.values.ravel(), predict_df[columns[i]], alpha=0.95)])\n",
    "    bootstrap.append([columns[i], bootstrap_error_estimate(ytest.values.ravel(), predict_df[columns[i]], roc_auc_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "delong = []\n",
    "bootstrap = []\n",
    "\n",
    "for i in predict_df.columns:\n",
    "    columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_ci(predict_df, base_models):\n",
    "    \n",
    "    columns = []\n",
    "    delong = []\n",
    "    bootstrap = []\n",
    "\n",
    "    for i in predict_df.columns:\n",
    "        columns.append(i)\n",
    "\n",
    "    for i,j in enumerate(columns):\n",
    "        delong.append([columns[i], calc_auc_ci(ytest.values.ravel(), predict_df[columns[i]], alpha=0.95)])\n",
    "        bootstrap.append([columns[i], bootstrap_error_estimate(predict_df[columns[i]], ytest.values.ravel(), roc_auc_score)])\n",
    "\n",
    "    delong_df = pd.DataFrame(delong).rename(columns = {0:'Set', 1:'Score'})\n",
    "    delong_df[['Set', 'Algorithm']] = pd.DataFrame(delong_df['Set'].tolist(), index=delong_df.index)\n",
    "    delong_df[['Lower', 'Upper']] = pd.DataFrame(delong_df['Score'].tolist(), index=delong_df.index)\n",
    "    bootstrap_df = pd.DataFrame(bootstrap).rename(columns = {0:'Set', 1:'Score'})\n",
    "    bootstrap_df[['Set', 'Algorithm']] = pd.DataFrame(bootstrap_df['Set'].tolist(), index=bootstrap_df.index)\n",
    "    bootstrap_df[['Lower', 'Upper']] = pd.DataFrame(bootstrap_df['Score'].tolist(), index=bootstrap_df.index)   \n",
    "\n",
    "    for i,j in enumerate(base_models):\n",
    "        delong_ci = delong_df.groupby(['Algorithm'])[['Set', 'Lower', 'Upper']].get_group(str(j)).reset_index()\n",
    "        bootstrap_ci = bootstrap_df.groupby(['Algorithm'])[['Set', 'Lower', 'Upper']].get_group(str(j)).reset_index()\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "\n",
    "        SMALL_SIZE = 10\n",
    "        MEDIUM_SIZE = 12\n",
    "        BIGGER_SIZE = 14\n",
    "\n",
    "        plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "        plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "        plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "        plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "        x_ticks = ('Wszystkie Zmienne', 'Bez PD', 'Tylko PD')\n",
    "        \n",
    "        for k in range(len(x_ticks)):\n",
    "\n",
    "            x_1 = k+1\n",
    "            x_2 = x_1 + 0.1\n",
    "\n",
    "            \n",
    "            eb_1 = plt.errorbar(x=x_1, \n",
    "                             y=(bootstrap_ci['Upper'][k]+bootstrap_ci['Lower'][k])/2, \n",
    "                             yerr=[(bootstrap_ci['Upper'][k]-bootstrap_ci['Lower'][k])/2],\n",
    "                             fmt='og',\n",
    "                             capsize = 10,\n",
    "                             ecolor = 'seagreen')\n",
    "\n",
    "            eb_2 = plt.errorbar(x=x_2, \n",
    "                             y=(delong_ci['Upper'][k]+delong_ci['Lower'][k])/2,\n",
    "                             yerr=[(delong_ci['Upper'][k]-delong_ci['Lower'][k])/2],\n",
    "                             fmt='og',\n",
    "                             capsize = 10,\n",
    "                             ecolor = 'seagreen')\n",
    "            eb_2[-1][0].set_linestyle('--')\n",
    "\n",
    "            plt.xticks([1.05,2.05,3.05], x_ticks, rotation=90)\n",
    "            plt.tight_layout()\n",
    "\n",
    "\n",
    "            plt.ylabel(\"ROC AUC Przedzia≈Ç Ufno≈õci\", fontsize=15)\n",
    "            plt.tight_layout()\n",
    "\n",
    "        plt.savefig('plot'+str(j)+'.png', dpi=1200)\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ALL', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.45306965, 0.57859698])]]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_ci = pd.DataFrame(bootstrap).rename(columns = {0:'Set', 1:'Score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Score</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>[0.4530696528522594, 0.5785969821163989]</td>\n",
       "      <td>LogisticRegression(random_state=2020)</td>\n",
       "      <td>0.45307</td>\n",
       "      <td>0.578597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set                                     Score  \\\n",
       "0  ALL  [0.4530696528522594, 0.5785969821163989]   \n",
       "\n",
       "                               Algorithm    Lower     Upper  \n",
       "0  LogisticRegression(random_state=2020)  0.45307  0.578597  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_ci[['Set', 'Algorithm']] = pd.DataFrame(bootstrap_ci['Set'].tolist(), index=bootstrap_ci.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_ci[['Lower', 'Upper']] = pd.DataFrame(bootstrap_ci['Score'].tolist(), index=bootstrap_ci.index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Score</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>[0.4530696528522594, 0.5785969821163989]</td>\n",
       "      <td>LogisticRegression(random_state=2020)</td>\n",
       "      <td>0.45307</td>\n",
       "      <td>0.578597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set                                     Score  \\\n",
       "0  ALL  [0.4530696528522594, 0.5785969821163989]   \n",
       "\n",
       "                               Algorithm    Lower     Upper  \n",
       "0  LogisticRegression(random_state=2020)  0.45307  0.578597  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=2020)\n",
      "RandomForestClassifier(random_state=2020)\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(base_models):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_ci = bootstrap_ci.groupby(['Algorithm'])[['Set', 'Lower', 'Upper']].get_group(str(j)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Set</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>0.45307</td>\n",
       "      <td>0.578597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Set    Lower     Upper\n",
       "0      0  ALL  0.45307  0.578597"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ci(predict_df, base_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49828526784465177"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(delong).rename(columns = {0:'Set', 1:'Score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['Set', 'Algorithm']] = pd.DataFrame(a['Set'].tolist(), index=a.index)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['Lower', 'Upper']] = pd.DataFrame(a['Score'].tolist(), index=a.index)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_df = pd.DataFrame(columns = ['Set', 'Algorithm', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.groupby(['Algorithm'])[['Algorithm','Set', 'Lower', 'Upper']].get_group('LogisticRegression(random_state=2020)').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Set</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression(random_state=2020)</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression(random_state=2020)</td>\n",
       "      <td>NOPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                              Algorithm   Set  Lower  Upper\n",
       "0      0  LogisticRegression(random_state=2020)   ALL    NaN    NaN\n",
       "1      2  LogisticRegression(random_state=2020)  NOPD    NaN    NaN"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['LogisticRegression(random_state=2020)']\""
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(b['Algorithm'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "x_ticks = ('Wszystkie Zmienne', 'Bez PD', 'Tylko PD')\n",
    "\n",
    "x_1 = i+1\n",
    "x_2 = x_1 + 0.1\n",
    "\n",
    "eb_1 = plt.errorbar(x=x_1, \n",
    "                 y=(bootstrap_ci['upper'][i]+bootstrap_ci['lower'][i])/2, \n",
    "                 yerr=[(bootstrap_ci['upper'][i]-bootstrap_ci['lower'][i])/2],\n",
    "                 fmt='og',\n",
    "                 capsize = 10,\n",
    "                 ecolor = 'seagreen')\n",
    "\n",
    "eb_2 = plt.errorbar(x=x_2, \n",
    "                 y=(delong_ci['upper'][i]+delong_ci['lower'][i])/2,\n",
    "                 yerr=[(delong_ci['upper'][i]-delong_ci['lower'][i])/2],\n",
    "                 fmt='og',\n",
    "                 capsize = 10,\n",
    "                 ecolor = 'seagreen')\n",
    "eb_2[-1][0].set_linestyle('--')\n",
    "\n",
    "plt.xticks([1,2,3], x_ticks, rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.ylabel(\"ROC AUC Przedzia≈Ç Ufno≈õci\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('INT_RDF.png', dpi=1200)\n",
    "\n",
    "plt.close('plot'+str(base_models[i])+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "for i in base_models:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_xgb_1 = bootstrap_error_estimate(predict_xgb_1, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_xgb_2 = bootstrap_error_estimate(predict_xgb_2, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_xgb_3 = bootstrap_error_estimate(predict_xgb_3, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_xgb_1 = calc_auc_ci(ytest.values.ravel(), predict_xgb_1, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_xgb_2 = calc_auc_ci(ytest.values.ravel(), predict_xgb_2, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_xgb_3 = calc_auc_ci(ytest.values.ravel(), predict_xgb_3, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_xgb = [bootstrapped_xgb_1, bootstrapped_xgb_2, bootstrapped_xgb_3, delong_xgb_1, delong_xgb_2, delong_xgb_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "x_ticks = ('All Features', 'PD Excluded', 'Only PD')\n",
    "\n",
    "x_1 = 1\n",
    "x_2 = 2\n",
    "x_3 = 3\n",
    "x_4 = x_1 + 0.1\n",
    "x_5 = x_2 + 0.1\n",
    "x_6 = x_3 + 0.1\n",
    "\n",
    "eb_1 = plt.errorbar(x=x_1, \n",
    "             y=(intervals_xgb[0][1]+intervals_xgb[0][0])/2, \n",
    "             yerr=[(intervals_xgb[0][1]-intervals_xgb[0][0])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'royalblue')\n",
    "\n",
    "eb_2 = plt.errorbar(x=x_2, \n",
    "             y=(intervals_xgb[1][1]+intervals_xgb[1][0])/2, \n",
    "             yerr=[(intervals_xgb[1][1]-intervals_xgb[1][0])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'lightsteelblue')\n",
    "\n",
    "eb_3 = plt.errorbar(x=x_3, \n",
    "             y=(intervals_xgb[2][1]+intervals_xgb[2][0])/2, \n",
    "             yerr=[(intervals_xgb[2][1]-intervals_xgb[2][0])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'lavender')\n",
    "\n",
    "eb_4 = plt.errorbar(x=x_4, \n",
    "             y=intervals_xgb[3][0], \n",
    "             yerr=[(intervals_xgb[3][1][0]-intervals_xgb[3][1][1])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'royalblue')\n",
    "eb_4[-1][0].set_linestyle('--')\n",
    "\n",
    "eb_5 = plt.errorbar(x=x_5, \n",
    "             y=intervals_xgb[4][0], \n",
    "             yerr=[(intervals_xgb[4][1][0]-intervals_xgb[4][1][1])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'lightsteelblue')\n",
    "eb_5[-1][0].set_linestyle('--')\n",
    "\n",
    "eb_6 = plt.errorbar(x=x_6, \n",
    "             y=intervals_xgb[5][0], \n",
    "             yerr=[(intervals_xgb[5][1][0]-intervals_xgb[5][1][1])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'lavender')\n",
    "eb_6[-1][0].set_linestyle('--')\n",
    "\n",
    "plt.xticks([x_1,x_2,x_3], x_ticks, rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.ylabel(\"ROC AUC Score Confidence Interval\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('INT_XGB.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_log_1 = bootstrap_error_estimate(predict_log_1, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_log_2 = bootstrap_error_estimate(predict_log_2, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_log_3 = bootstrap_error_estimate(predict_log_3, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_log_1 = calc_auc_ci(ytest.values.ravel(), predict_log_1, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_log_2 = calc_auc_ci(ytest.values.ravel(), predict_log_2, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_log_3 = calc_auc_ci(ytest.values.ravel(), predict_log_3, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_log = [bootstrapped_log_1, bootstrapped_log_2, bootstrapped_log_3, delong_log_1, delong_log_2, delong_log_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "x_ticks = ('All Features', 'PD Excluded', 'Only PD')\n",
    "\n",
    "x_1 = 1\n",
    "x_2 = 2\n",
    "x_3 = 3\n",
    "x_4 = x_1 + 0.1\n",
    "x_5 = x_2 + 0.1\n",
    "x_6 = x_3 + 0.1\n",
    "\n",
    "eb_1 = plt.errorbar(x=x_1, \n",
    "             y=(intervals_log[0][1]+intervals_log[0][0])/2, \n",
    "             yerr=[(intervals_log[0][1]-intervals_log[0][0])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'chocolate')\n",
    "\n",
    "eb_2 = plt.errorbar(x=x_2, \n",
    "             y=(intervals_log[1][1]+intervals_log[1][0])/2, \n",
    "             yerr=[(intervals_log[1][1]-intervals_log[1][0])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'burlywood')\n",
    "\n",
    "eb_3 = plt.errorbar(x=x_3, \n",
    "             y=(intervals_log[2][1]+intervals_log[2][0])/2, \n",
    "             yerr=[(intervals_log[2][1]-intervals_log[2][0])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'navajowhite')\n",
    "\n",
    "eb_4 = plt.errorbar(x=x_4, \n",
    "             y=intervals_log[3][0], \n",
    "             yerr=[(intervals_log[3][1][0]-intervals_log[3][1][1])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'chocolate')\n",
    "eb_4[-1][0].set_linestyle('--')\n",
    "\n",
    "eb_5 = plt.errorbar(x=x_5, \n",
    "             y=intervals_log[4][0], \n",
    "             yerr=[(intervals_log[4][1][0]-intervals_log[4][1][1])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'burlywood')\n",
    "eb_5[-1][0].set_linestyle('--')\n",
    "\n",
    "eb_6 = plt.errorbar(x=x_6, \n",
    "             y=intervals_log[5][0], \n",
    "             yerr=[(intervals_log[5][1][0]-intervals_log[5][1][1])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'navajowhite')\n",
    "eb_6[-1][0].set_linestyle('--')\n",
    "\n",
    "plt.xticks([x_1,x_2,x_3], x_ticks, rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.ylabel(\"ROC AUC Score Confidence Interval\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('INT_LOG.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_all_2 = bootstrap_error_estimate(predict_rdf_1, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_all_1 = bootstrap_error_estimate(predict_xgb_1, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_all_3 = bootstrap_error_estimate(predict_log_1, ytest.values.ravel(),method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_all_2 = calc_auc_ci(ytest.values.ravel(), predict_rdf_1, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_all_1 = calc_auc_ci(ytest.values.ravel(), predict_xgb_1, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delong_all_3 = calc_auc_ci(ytest.values.ravel(), predict_log_1, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_all = [bootstrapped_all_1, bootstrapped_all_2, bootstrapped_all_3, delong_all_1, delong_all_2, delong_all_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "x_ticks = ('XGBoost', 'Random Forest', 'Logistic Regression')\n",
    "\n",
    "x_1 = 1\n",
    "x_2 = 2\n",
    "x_3 = 3\n",
    "x_4 = x_1 + 0.1\n",
    "x_5 = x_2 + 0.1\n",
    "x_6 = x_3 + 0.1\n",
    "\n",
    "eb_1 = plt.errorbar(x=x_1, \n",
    "             y=(intervals_all[0][1]+intervals_all[0][0])/2, \n",
    "             yerr=[(intervals_all[0][1]-intervals_all[0][0])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'royalblue')\n",
    "\n",
    "eb_2 = plt.errorbar(x=x_2, \n",
    "             y=(intervals_all[1][1]+intervals_all[1][0])/2, \n",
    "             yerr=[(intervals_all[1][1]-intervals_all[1][0])/2],\n",
    "             fmt='og',\n",
    "             capsize = 10,\n",
    "             ecolor = 'seagreen')\n",
    "\n",
    "eb_3 = plt.errorbar(x=x_3, \n",
    "             y=(intervals_all[2][1]+intervals_all[2][0])/2, \n",
    "             yerr=[(intervals_all[2][1]-intervals_all[2][0])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'chocolate')\n",
    "\n",
    "eb_4 = plt.errorbar(x=x_4, \n",
    "             y=intervals_all[3][0], \n",
    "             yerr=[(intervals_all[3][1][0]-intervals_all[3][1][1])/2],\n",
    "             fmt='ob',\n",
    "             capsize = 10,\n",
    "             ecolor = 'royalblue')\n",
    "eb_4[-1][0].set_linestyle('--')\n",
    "\n",
    "eb_5 = plt.errorbar(x=x_5, \n",
    "             y=intervals_all[4][0], \n",
    "             yerr=[(intervals_all[4][1][0]-intervals_all[4][1][1])/2],\n",
    "             fmt='og',\n",
    "             capsize = 10,\n",
    "             ecolor = 'seagreen')\n",
    "eb_5[-1][0].set_linestyle('--')\n",
    "\n",
    "eb_6 = plt.errorbar(x=x_6, \n",
    "             y=intervals_all[5][0], \n",
    "             yerr=[(intervals_all[5][1][0]-intervals_all[5][1][1])/2],\n",
    "             fmt='or',\n",
    "             capsize = 10,\n",
    "             ecolor = 'chocolate')\n",
    "eb_6[-1][0].set_linestyle('--')\n",
    "\n",
    "plt.xticks([x_1,x_2,x_3], x_ticks, rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.ylabel(\"ROC AUC Score Confidence Interval\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('INT_ALL.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. K-Fold Ttest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDF/XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=rdf_1,\n",
    "                          estimator2=xgb_1,\n",
    "                          X=x_test, y=y_test,\n",
    "                          random_seed=1)\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDF/LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=rdf_1,\n",
    "                          estimator2=log_1,\n",
    "                          X=xtest, y=ytest,\n",
    "                          random_seed=1)\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost/LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=xgb_1,\n",
    "                          estimator2=log_1,\n",
    "                          X=xtest, y=ytest,\n",
    "                          random_seed=1)\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. McNemar Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All/PD Excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_rdf_1 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_rdf_4, \n",
    "                   y_model2=predict_rdf_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_rdf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_rdf_1, p_rdf_1 = mcnemar(ary=tb_rdf_1, corrected=True)\n",
    "print('chi-squared:', chi2_rdf_1)\n",
    "print('p-value:', p_rdf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All/Only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_rdf_2 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_rdf_4, \n",
    "                   y_model2=predict_rdf_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_rdf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_rdf_2, p_rdf_2 = mcnemar(ary=tb_rdf_2, corrected=True)\n",
    "print('chi-squared:', chi2_rdf_2)\n",
    "print('p-value:', p_rdf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All/PD Excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_xgb_1 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_xgb_4, \n",
    "                   y_model2=predict_xgb_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_xgb_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_xgb_1, p_xgb_1 = mcnemar(ary=tb_xgb_1, corrected=True)\n",
    "print('chi-squared:', chi2_xgb_1)\n",
    "print('p-value:', p_xgb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All/Only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_xgb_2 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_xgb_4, \n",
    "                   y_model2=predict_xgb_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_xgb_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_xgb_2, p_xgb_2 = mcnemar(ary=tb_xgb_2, corrected=True)\n",
    "print('chi-squared:', chi2_xgb_2)\n",
    "print('p-value:', p_xgb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All/PD Excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_log_1 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_log_4, \n",
    "                   y_model2=predict_log_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_log_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_log_1, p_log_1 = mcnemar(ary=tb_log_1, corrected=True)\n",
    "print('chi-squared:', chi2_log_1)\n",
    "print('p-value:', p_log_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All/Only PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_log_2 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_log_4, \n",
    "                   y_model2=predict_log_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_log_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_log_2, p_log_2 = mcnemar(ary=tb_log_2, corrected=True)\n",
    "print('chi-squared:', chi2_log_2)\n",
    "print('p-value:', p_log_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDF/XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_all_1 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_rdf_4, \n",
    "                   y_model2=predict_xgb_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_all_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_all_1, p_all_1 = mcnemar(ary=tb_all_1, corrected=True)\n",
    "print('chi-squared:', chi2_all_1)\n",
    "print('p-value:', p_all_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDF/LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_all_2 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_rdf_4, \n",
    "                   y_model2=predict_log_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_all_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_all_2, p_all_2 = mcnemar(ary=tb_all_2, corrected=True)\n",
    "print('chi-squared:', chi2_all_2)\n",
    "print('p-value:', p_all_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost/LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_all_3 = mcnemar_table(y_target=ytest.values.ravel(), \n",
    "                   y_model1=predict_log_4, \n",
    "                   y_model2=predict_xgb_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_all_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2_all_3, p_all_3 = mcnemar(ary=tb_all_3, corrected=True)\n",
    "print('chi-squared:', chi2_all_3)\n",
    "print('p-value:', p_all_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model CV\n",
    "scores = cross_val_score(rdf_1, xtest.values, ytest.values.ravel(), scoring='roc_auc')\n",
    "roc_auc = np.mean(scores)\n",
    "print('ROC AUC: %.2f%%' % (100*roc_auc))\n",
    "\n",
    "# Confidence interval\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. ROC Curve All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classfiers and make a list\n",
    "classifiers = [predict_xgb_1,\n",
    "               predict_rdf_1,  \n",
    "               predict_log_1]\n",
    "\n",
    "# Define a result table as a DataFrame\n",
    "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models and record the results\n",
    "for cls in classifiers:\n",
    "    yproba = cls\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(ytest.values.ravel(),  yproba)\n",
    "    auc = roc_auc_score(ytest.values.ravel(), yproba)\n",
    "    \n",
    "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc}, ignore_index=True)\n",
    "\n",
    "# Set name of the classifiers as index labels\n",
    "result_table.set_index('classifiers', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = ['XGBoost', 'Random Forest', 'Logistic Regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = ['All features', 'PD Excluded', 'Only PD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.index = new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ALL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">NOPD</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.158855</td>\n",
       "      <td>0.524334</td>\n",
       "      <td>0.963207</td>\n",
       "      <td>0.343301</td>\n",
       "      <td>0.990515</td>\n",
       "      <td>0.409867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973212</td>\n",
       "      <td>0.456156</td>\n",
       "      <td>0.436855</td>\n",
       "      <td>0.394809</td>\n",
       "      <td>0.210037</td>\n",
       "      <td>0.569305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047930</td>\n",
       "      <td>0.294047</td>\n",
       "      <td>0.726307</td>\n",
       "      <td>0.157301</td>\n",
       "      <td>0.860371</td>\n",
       "      <td>0.892455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.765273</td>\n",
       "      <td>0.372387</td>\n",
       "      <td>0.689347</td>\n",
       "      <td>0.296049</td>\n",
       "      <td>0.889302</td>\n",
       "      <td>0.396982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196238</td>\n",
       "      <td>0.072257</td>\n",
       "      <td>0.485313</td>\n",
       "      <td>0.781989</td>\n",
       "      <td>0.493927</td>\n",
       "      <td>0.630451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.082049</td>\n",
       "      <td>0.484743</td>\n",
       "      <td>0.279380</td>\n",
       "      <td>0.756635</td>\n",
       "      <td>0.651031</td>\n",
       "      <td>0.287432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.148862</td>\n",
       "      <td>0.677764</td>\n",
       "      <td>0.544325</td>\n",
       "      <td>0.385573</td>\n",
       "      <td>0.703964</td>\n",
       "      <td>0.779929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.533696</td>\n",
       "      <td>0.597796</td>\n",
       "      <td>0.248720</td>\n",
       "      <td>0.660196</td>\n",
       "      <td>0.656771</td>\n",
       "      <td>0.899105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.543073</td>\n",
       "      <td>0.938828</td>\n",
       "      <td>0.547139</td>\n",
       "      <td>0.035523</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.715117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.787099</td>\n",
       "      <td>0.997049</td>\n",
       "      <td>0.153597</td>\n",
       "      <td>0.516802</td>\n",
       "      <td>0.856041</td>\n",
       "      <td>0.247840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ALL  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                  0.158855   \n",
       "1                                  0.973212   \n",
       "2                                  0.047930   \n",
       "3                                  0.765273   \n",
       "4                                  0.196238   \n",
       "...                                     ...   \n",
       "19315                              0.082049   \n",
       "19316                              0.148862   \n",
       "19317                              0.533696   \n",
       "19318                              0.543073   \n",
       "19319                              0.787099   \n",
       "\n",
       "                                                 \\\n",
       "      RandomForestClassifier(random_state=2020)   \n",
       "0                                      0.524334   \n",
       "1                                      0.456156   \n",
       "2                                      0.294047   \n",
       "3                                      0.372387   \n",
       "4                                      0.072257   \n",
       "...                                         ...   \n",
       "19315                                  0.484743   \n",
       "19316                                  0.677764   \n",
       "19317                                  0.597796   \n",
       "19318                                  0.938828   \n",
       "19319                                  0.997049   \n",
       "\n",
       "                                       NOPD  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                  0.963207   \n",
       "1                                  0.436855   \n",
       "2                                  0.726307   \n",
       "3                                  0.689347   \n",
       "4                                  0.485313   \n",
       "...                                     ...   \n",
       "19315                              0.279380   \n",
       "19316                              0.544325   \n",
       "19317                              0.248720   \n",
       "19318                              0.547139   \n",
       "19319                              0.153597   \n",
       "\n",
       "                                                 \\\n",
       "      RandomForestClassifier(random_state=2020)   \n",
       "0                                      0.343301   \n",
       "1                                      0.394809   \n",
       "2                                      0.157301   \n",
       "3                                      0.296049   \n",
       "4                                      0.781989   \n",
       "...                                         ...   \n",
       "19315                                  0.756635   \n",
       "19316                                  0.385573   \n",
       "19317                                  0.660196   \n",
       "19318                                  0.035523   \n",
       "19319                                  0.516802   \n",
       "\n",
       "                                         PD  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                  0.990515   \n",
       "1                                  0.210037   \n",
       "2                                  0.860371   \n",
       "3                                  0.889302   \n",
       "4                                  0.493927   \n",
       "...                                     ...   \n",
       "19315                              0.651031   \n",
       "19316                              0.703964   \n",
       "19317                              0.656771   \n",
       "19318                              0.008473   \n",
       "19319                              0.856041   \n",
       "\n",
       "                                                 \n",
       "      RandomForestClassifier(random_state=2020)  \n",
       "0                                      0.409867  \n",
       "1                                      0.569305  \n",
       "2                                      0.892455  \n",
       "3                                      0.396982  \n",
       "4                                      0.630451  \n",
       "...                                         ...  \n",
       "19315                                  0.287432  \n",
       "19316                                  0.779929  \n",
       "19317                                  0.899105  \n",
       "19318                                  0.715117  \n",
       "19319                                  0.247840  \n",
       "\n",
       "[19320 rows x 6 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-457-604d346906c9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-457-604d346906c9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for i,(j, clf) in enumerate(predict_df):;\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i,(j, clf) in enumerate(predict_df):\n",
    "    print(predict_df[j][clf]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=2020)\n",
      "RandomForestClassifier(random_state=2020)\n"
     ]
    }
   ],
   "source": [
    "for i in base_models[:2]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ALL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">NOPD</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "      <th>LogisticRegression(random_state=2020)</th>\n",
       "      <th>RandomForestClassifier(random_state=2020)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.158855</td>\n",
       "      <td>0.524334</td>\n",
       "      <td>0.963207</td>\n",
       "      <td>0.343301</td>\n",
       "      <td>0.990515</td>\n",
       "      <td>0.409867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973212</td>\n",
       "      <td>0.456156</td>\n",
       "      <td>0.436855</td>\n",
       "      <td>0.394809</td>\n",
       "      <td>0.210037</td>\n",
       "      <td>0.569305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047930</td>\n",
       "      <td>0.294047</td>\n",
       "      <td>0.726307</td>\n",
       "      <td>0.157301</td>\n",
       "      <td>0.860371</td>\n",
       "      <td>0.892455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.765273</td>\n",
       "      <td>0.372387</td>\n",
       "      <td>0.689347</td>\n",
       "      <td>0.296049</td>\n",
       "      <td>0.889302</td>\n",
       "      <td>0.396982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196238</td>\n",
       "      <td>0.072257</td>\n",
       "      <td>0.485313</td>\n",
       "      <td>0.781989</td>\n",
       "      <td>0.493927</td>\n",
       "      <td>0.630451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.082049</td>\n",
       "      <td>0.484743</td>\n",
       "      <td>0.279380</td>\n",
       "      <td>0.756635</td>\n",
       "      <td>0.651031</td>\n",
       "      <td>0.287432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.148862</td>\n",
       "      <td>0.677764</td>\n",
       "      <td>0.544325</td>\n",
       "      <td>0.385573</td>\n",
       "      <td>0.703964</td>\n",
       "      <td>0.779929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.533696</td>\n",
       "      <td>0.597796</td>\n",
       "      <td>0.248720</td>\n",
       "      <td>0.660196</td>\n",
       "      <td>0.656771</td>\n",
       "      <td>0.899105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.543073</td>\n",
       "      <td>0.938828</td>\n",
       "      <td>0.547139</td>\n",
       "      <td>0.035523</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.715117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>0.787099</td>\n",
       "      <td>0.997049</td>\n",
       "      <td>0.153597</td>\n",
       "      <td>0.516802</td>\n",
       "      <td>0.856041</td>\n",
       "      <td>0.247840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ALL  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                  0.158855   \n",
       "1                                  0.973212   \n",
       "2                                  0.047930   \n",
       "3                                  0.765273   \n",
       "4                                  0.196238   \n",
       "...                                     ...   \n",
       "19315                              0.082049   \n",
       "19316                              0.148862   \n",
       "19317                              0.533696   \n",
       "19318                              0.543073   \n",
       "19319                              0.787099   \n",
       "\n",
       "                                                 \\\n",
       "      RandomForestClassifier(random_state=2020)   \n",
       "0                                      0.524334   \n",
       "1                                      0.456156   \n",
       "2                                      0.294047   \n",
       "3                                      0.372387   \n",
       "4                                      0.072257   \n",
       "...                                         ...   \n",
       "19315                                  0.484743   \n",
       "19316                                  0.677764   \n",
       "19317                                  0.597796   \n",
       "19318                                  0.938828   \n",
       "19319                                  0.997049   \n",
       "\n",
       "                                       NOPD  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                  0.963207   \n",
       "1                                  0.436855   \n",
       "2                                  0.726307   \n",
       "3                                  0.689347   \n",
       "4                                  0.485313   \n",
       "...                                     ...   \n",
       "19315                              0.279380   \n",
       "19316                              0.544325   \n",
       "19317                              0.248720   \n",
       "19318                              0.547139   \n",
       "19319                              0.153597   \n",
       "\n",
       "                                                 \\\n",
       "      RandomForestClassifier(random_state=2020)   \n",
       "0                                      0.343301   \n",
       "1                                      0.394809   \n",
       "2                                      0.157301   \n",
       "3                                      0.296049   \n",
       "4                                      0.781989   \n",
       "...                                         ...   \n",
       "19315                                  0.756635   \n",
       "19316                                  0.385573   \n",
       "19317                                  0.660196   \n",
       "19318                                  0.035523   \n",
       "19319                                  0.516802   \n",
       "\n",
       "                                         PD  \\\n",
       "      LogisticRegression(random_state=2020)   \n",
       "0                                  0.990515   \n",
       "1                                  0.210037   \n",
       "2                                  0.860371   \n",
       "3                                  0.889302   \n",
       "4                                  0.493927   \n",
       "...                                     ...   \n",
       "19315                              0.651031   \n",
       "19316                              0.703964   \n",
       "19317                              0.656771   \n",
       "19318                              0.008473   \n",
       "19319                              0.856041   \n",
       "\n",
       "                                                 \n",
       "      RandomForestClassifier(random_state=2020)  \n",
       "0                                      0.409867  \n",
       "1                                      0.569305  \n",
       "2                                      0.892455  \n",
       "3                                      0.396982  \n",
       "4                                      0.630451  \n",
       "...                                         ...  \n",
       "19315                                  0.287432  \n",
       "19316                                  0.779929  \n",
       "19317                                  0.899105  \n",
       "19318                                  0.715117  \n",
       "19319                                  0.247840  \n",
       "\n",
       "[19320 rows x 6 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expr must be a string to be evaluated, <class 'bool'> given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-497-3ae658563baa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpredict_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'ALL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   3226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"expr must be a string to be evaluated, {type(expr)} given\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3228\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"level\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"level\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expr must be a string to be evaluated, <class 'bool'> given"
     ]
    }
   ],
   "source": [
    "for i,(j,clf) in enumerate(predict_df):\n",
    "    predict_df.query(str(j)=='ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "for i, (j, clf) in enumerate(predict_df):\n",
    "    yproba = predict_df[j][clf]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(ytest.values.ravel(),  yproba)\n",
    "    auc = roc_auc_score(ytest.values.ravel(), yproba)\n",
    "    \n",
    "    result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc}, ignore_index=True)\n",
    "    \n",
    "    result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "\n",
    "    # Set name of the classifiers as index labels\n",
    "#     result_table.set_index('classifiers', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 5.2192066805845514e-05, 0.01064718162839...\n",
       "1    [0.0, 5.2192066805845514e-05, 0.00120041753653...\n",
       "Name: fpr, dtype: object"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.loc[result_table.set == 'ALL']['fpr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(clf).split('(')[0].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_models[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def roc_comparison_all(predict_df, y_test):\n",
    "    \n",
    "    # Plot the figure\n",
    "    # Train the models and record the results\n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "\n",
    "    for i, (j, clf) in enumerate(predict_df):\n",
    "        yproba = predict_df[j][clf]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test.values.ravel(),  yproba)\n",
    "        auc = roc_auc_score(y_test.values.ravel(), yproba)\n",
    "\n",
    "        result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                            'fpr':fpr, \n",
    "                                            'tpr':tpr, \n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "\n",
    "        result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    for k,m in enumerate(result_table.classifier.unique()):\n",
    "\n",
    "    #     n_lines = len(base_models[:2])\n",
    "    #     c = np.arange(1, n_lines + 1)\n",
    "    #     norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "    #     cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Blues)\n",
    "    #     cmap.set_array([])\n",
    "\n",
    "        plt.plot(result_table.loc[result_table.set == 'ALL']['fpr'][k], \n",
    "                 result_table.loc[result_table.set == 'ALL']['tpr'][k],\n",
    "    #              c=cmap.to_rgba(k + 2),\n",
    "                 label=\"{}, AUC={:.3f}\".format(str(m).split('(')[0].lower(), result_table.loc[result_table.set == 'ALL']['auc'][k]))\n",
    "\n",
    "    plt.plot([0,1], [0,1], color='gray', linestyle='--')\n",
    "\n",
    "    plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "    plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "    # plt.title('ROC Curve Logistic Regression Analysis', fontweight='bold', fontsize=15)\n",
    "    plt.legend(prop={'size':13}, loc='lower right')\n",
    "    plt.savefig('ALL.png',  dpi=1200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def roc_comparison_sets(predict_df, y_test):\n",
    "    \n",
    "    # Plot the figure\n",
    "    # Train the models and record the results\n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "    for i, (j, clf) in enumerate(predict_df):\n",
    "        yproba = predict_df[j][clf]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test.values.ravel(),  yproba)\n",
    "        auc = roc_auc_score(y_test.values.ravel(), yproba)\n",
    "\n",
    "        result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                            'fpr':fpr, \n",
    "                                            'tpr':tpr, \n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "\n",
    "        result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "        for k,m in enumerate(result_table.set.unique()):\n",
    "\n",
    "            plt.plot(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['fpr'].values[0], \n",
    "                     result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['tpr'].values[0],\n",
    "                     label=\"{}, AUC={:.3f}\".format(str(m), result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['auc'].values[0]))\n",
    "\n",
    "            plt.plot([0,1], [0,1], color='gray', linestyle='--')\n",
    "\n",
    "            plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "            plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "            plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "            plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "            plt.legend(prop={'size':13}, loc='lower right')\n",
    "            \n",
    "        plt.savefig(str(clf)+str(m)+'.png',  dpi=1200)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_ci(predict_df, base_models):\n",
    "    \n",
    "        \n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'delong','bootstrap'])\n",
    "    for i, (j, clf) in enumerate(predict_df):\n",
    "        yproba = predict_df[j][clf]\n",
    "\n",
    "        delong = calc_auc_ci(ytest.values.ravel(),  yproba, alpha=0.95) \n",
    "        bootstrap = bootstrap_error_estimate(yproba, ytest.values.ravel(), roc_auc_score)\n",
    "\n",
    "        result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                            'delong':delong, \n",
    "                                            'bootstrap':bootstrap}, ignore_index=True)\n",
    "\n",
    "        result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "        \n",
    "        plt.figure(figsize=(8,6))\n",
    "\n",
    "        for k,(m,n) in enumerate(result_table.classifiers):\n",
    "\n",
    "            SMALL_SIZE = 10\n",
    "            MEDIUM_SIZE = 12\n",
    "            BIGGER_SIZE = 14\n",
    "\n",
    "            plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "            plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "            plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "            plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "            plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "            x_ticks = ('Wszystkie Zmienne', 'Bez PD', 'Tylko PD')\n",
    "            \n",
    "            def m_value(x):\n",
    "                if x == 'ALL':\n",
    "                    x_1 = 1\n",
    "                    x_2 = x_1 + 0.1\n",
    "                elif x == 'NOPD':\n",
    "                    x_1 = 2\n",
    "                    x_2 = x_1 + 0.1\n",
    "                elif x == 'PD':\n",
    "                    x_1 = 3\n",
    "                    x_2 = x_1 + 0.1\n",
    "                return list([x_1,x_2])\n",
    "\n",
    "            eb_1 = plt.errorbar(x=m_value(str(m))[0], \n",
    "                             y=(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][1] + result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][0])/2, \n",
    "                             yerr=[(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][1] - result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][0])/2],\n",
    "                             fmt='o',\n",
    "                             capsize = 10)\n",
    "\n",
    "            eb_2 = plt.errorbar(x=m_value(str(m))[1], \n",
    "                             y=(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][1] + result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][0])/2, \n",
    "                             yerr=[(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][1] - result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][0])/2],\n",
    "                             fmt='o',\n",
    "                             capsize = 10)\n",
    "            eb_2[-1][0].set_linestyle('--')\n",
    "\n",
    "            plt.xticks([1.05,2.05,3.05], x_ticks, rotation=90)\n",
    "            plt.tight_layout()\n",
    "\n",
    "\n",
    "            plt.ylabel(\"ROC AUC Przedzia≈Ç Ufno≈õci\", fontsize=15)\n",
    "            plt.tight_layout()\n",
    "\n",
    "        plt.savefig('plot'+str(clf)+'ci.png', dpi=1200)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_value(x):\n",
    "    if x == 'ALL':\n",
    "        x_1 = 1\n",
    "        x_2 = x_1 + 0.1\n",
    "    elif x == 'NOPD':\n",
    "        x_1 = 2\n",
    "        x_2 = x_1 + 0.1\n",
    "    elif x == 'PD':\n",
    "        x_1 = 3\n",
    "        x_2 = x_1 + 0.1\n",
    "    return list([x_1,x_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ALL LogisticRegression(random_state=2020)\n",
      "1 ALL RandomForestClassifier(random_state=2020)\n",
      "2 NOPD LogisticRegression(random_state=2020)\n",
      "3 NOPD RandomForestClassifier(random_state=2020)\n",
      "4 PD LogisticRegression(random_state=2020)\n",
      "5 PD RandomForestClassifier(random_state=2020)\n"
     ]
    }
   ],
   "source": [
    "for k,(m,n) in enumerate(result_table.classifiers):\n",
    "    print(k,m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ci(predict_df,base_models[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = pd.DataFrame(columns=['classifiers', 'delong','bootstrap'])\n",
    "for i, (j, clf) in enumerate(predict_df):\n",
    "    yproba = predict_df[j][clf]\n",
    "\n",
    "    delong = calc_auc_ci(ytest.values.ravel(),  yproba, alpha=0.95) \n",
    "    bootstrap = bootstrap_error_estimate(yproba, ytest.values.ravel(), roc_auc_score)\n",
    "\n",
    "    result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                        'delong':delong, \n",
    "                                        'bootstrap':bootstrap}, ignore_index=True)\n",
    "    \n",
    "    result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "\n",
    "# result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifier'].tolist(), index=result_table.index)\n",
    "\n",
    "# for i,j in enumerate(result_table.classifier.unique()):\n",
    "    \n",
    "#     plt.plot(result_table.loc[(result_table.classifier == str(j)) & (result_table.set == str(m))]['fpr'].values[0], \n",
    "#                      result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['tpr'].values[0],\n",
    "#                      label=\"{}, AUC={:.3f}\".format(str(m), result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['auc'].values[0]))\n",
    "\n",
    "#             plt.plot([0,1], [0,1], color='gray', linestyle='--')\n",
    "\n",
    "#             plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "#             plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "#             plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "#             plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "#             plt.legend(prop={'size':13}, loc='lower right')\n",
    "            \n",
    "#         plt.savefig(str(clf)+str(m)+'.png',  dpi=1200)\n",
    "#         plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ALL LogisticRegression(random_state=2020)\n",
      "1 ALL RandomForestClassifier(random_state=2020)\n",
      "2 NOPD LogisticRegression(random_state=2020)\n",
      "3 NOPD RandomForestClassifier(random_state=2020)\n",
      "4 PD LogisticRegression(random_state=2020)\n",
      "5 PD RandomForestClassifier(random_state=2020)\n"
     ]
    }
   ],
   "source": [
    "for k,(m,n) in enumerate(result_table.classifiers):\n",
    "    print(k,m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4946745167682817"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.loc[(result_table.classifier == 'RandomForestClassifier(random_state=2020)') & (result_table.set == 'ALL')]['delong'].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: delong, dtype: object)"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ALL LogisticRegression(random_state=2020)\n",
      "1 ALL RandomForestClassifier(random_state=2020)\n",
      "2 NOPD LogisticRegression(random_state=2020)\n",
      "3 NOPD RandomForestClassifier(random_state=2020)\n",
      "4 PD LogisticRegression(random_state=2020)\n",
      "5 PD RandomForestClassifier(random_state=2020)\n"
     ]
    }
   ],
   "source": [
    "for k,(m,n) in enumerate(result_table.classifier):\n",
    "    print(k,m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def graph_ci(predict_df, base_models):\n",
    "    \n",
    "#     columns = []\n",
    "#     delong = []\n",
    "#     bootstrap = []\n",
    "\n",
    "#     for i in predict_df.columns:\n",
    "#         columns.append(i)\n",
    "\n",
    "#     for i,j in enumerate(columns):\n",
    "#         delong.append([columns[i], calc_auc_ci(ytest.values.ravel(), predict_df[columns[i]], alpha=0.95)])\n",
    "#         bootstrap.append([columns[i], bootstrap_error_estimate(predict_df[columns[i]], ytest.values.ravel(), roc_auc_score)])\n",
    "\n",
    "#     delong_df = pd.DataFrame(delong).rename(columns = {0:'Set', 1:'Score'})\n",
    "#     delong_df[['Set', 'Algorithm']] = pd.DataFrame(delong_df['Set'].tolist(), index=delong_df.index)\n",
    "#     delong_df[['Lower', 'Upper']] = pd.DataFrame(delong_df['Score'].tolist(), index=delong_df.index)\n",
    "#     bootstrap_df = pd.DataFrame(bootstrap).rename(columns = {0:'Set', 1:'Score'})\n",
    "#     bootstrap_df[['Set', 'Algorithm']] = pd.DataFrame(bootstrap_df['Set'].tolist(), index=bootstrap_df.index)\n",
    "#     bootstrap_df[['Lower', 'Upper']] = pd.DataFrame(bootstrap_df['Score'].tolist(), index=bootstrap_df.index)   \n",
    "\n",
    "#     for i,j in enumerate(base_models[:2]):\n",
    "#         delong_ci = delong_df.groupby(['Algorithm'])[['Set', 'Lower', 'Upper']].get_group(str(j)).reset_index()\n",
    "#         bootstrap_ci = bootstrap_df.groupby(['Algorithm'])[['Set', 'Lower', 'Upper']].get_group(str(j)).reset_index()\n",
    "\n",
    "#         plt.figure(figsize=(8,6))\n",
    "\n",
    "#         SMALL_SIZE = 10\n",
    "#         MEDIUM_SIZE = 12\n",
    "#         BIGGER_SIZE = 14\n",
    "\n",
    "#         plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "#         plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "#         plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "#         plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "#         plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "#         plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "#         plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "#         x_ticks = ('Wszystkie Zmienne', 'Bez PD', 'Tylko PD')\n",
    "        \n",
    "#         for k in range(len(x_ticks)):\n",
    "\n",
    "#             x_1 = k+1\n",
    "#             x_2 = x_1 + 0.1\n",
    "\n",
    "            \n",
    "#             eb_1 = plt.errorbar(x=x_1, \n",
    "#                              y=(bootstrap_ci['Upper'][k]+bootstrap_ci['Lower'][k])/2, \n",
    "#                              yerr=[(bootstrap_ci['Upper'][k]-bootstrap_ci['Lower'][k])/2],\n",
    "#                              fmt='og',\n",
    "#                              capsize = 10)\n",
    "\n",
    "#             eb_2 = plt.errorbar(x=x_2, \n",
    "#                              y=(delong_ci['Upper'][k]+delong_ci['Lower'][k])/2,\n",
    "#                              yerr=[(delong_ci['Upper'][k]-delong_ci['Lower'][k])/2],\n",
    "#                              fmt='og',\n",
    "#                              capsize = 10)\n",
    "#             eb_2[-1][0].set_linestyle('--')\n",
    "\n",
    "#             plt.xticks([1.05,2.05,3.05], x_ticks, rotation=90)\n",
    "#             plt.tight_layout()\n",
    "\n",
    "\n",
    "#             plt.ylabel(\"ROC AUC Przedzia≈Ç Ufno≈õci\", fontsize=15)\n",
    "#             plt.tight_layout()\n",
    "\n",
    "#         plt.savefig('plot'+str(j)+'.png', dpi=1200)\n",
    "\n",
    "#         plt.close()\n",
    "    \n",
    "#     return delong, bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>delong</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(random_state=2020)</td>\n",
       "      <td>[0.4706879995996858, 0.5613324857865355]</td>\n",
       "      <td>[0.45963064905739076, 0.5693807497078069]</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier(random_state=2020)</td>\n",
       "      <td>[0.4946745167682817, 0.5807671585970627]</td>\n",
       "      <td>[0.46985884961199, 0.5948487029918954]</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(random_state=2020)</td>\n",
       "      <td>[0.4633819916711999, 0.5522338747171092]</td>\n",
       "      <td>[0.461787920343777, 0.5783646269699532]</td>\n",
       "      <td>NOPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier(random_state=2020)</td>\n",
       "      <td>[0.4775350630235856, 0.5634207041997964]</td>\n",
       "      <td>[0.45206475083733855, 0.5732989906387373]</td>\n",
       "      <td>NOPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(random_state=2020)</td>\n",
       "      <td>[0.46101330408158914, 0.5505779015551542]</td>\n",
       "      <td>[0.4402038441820304, 0.5645910949661206]</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier(random_state=2020)</td>\n",
       "      <td>[0.4817006239345414, 0.572660675647922]</td>\n",
       "      <td>[0.44345131886259637, 0.5928249305764615]</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  classifier  \\\n",
       "0      LogisticRegression(random_state=2020)   \n",
       "1  RandomForestClassifier(random_state=2020)   \n",
       "2      LogisticRegression(random_state=2020)   \n",
       "3  RandomForestClassifier(random_state=2020)   \n",
       "4      LogisticRegression(random_state=2020)   \n",
       "5  RandomForestClassifier(random_state=2020)   \n",
       "\n",
       "                                      delong  \\\n",
       "0   [0.4706879995996858, 0.5613324857865355]   \n",
       "1   [0.4946745167682817, 0.5807671585970627]   \n",
       "2   [0.4633819916711999, 0.5522338747171092]   \n",
       "3   [0.4775350630235856, 0.5634207041997964]   \n",
       "4  [0.46101330408158914, 0.5505779015551542]   \n",
       "5    [0.4817006239345414, 0.572660675647922]   \n",
       "\n",
       "                                   bootstrap   set  \n",
       "0  [0.45963064905739076, 0.5693807497078069]   ALL  \n",
       "1     [0.46985884961199, 0.5948487029918954]   ALL  \n",
       "2    [0.461787920343777, 0.5783646269699532]  NOPD  \n",
       "3  [0.45206475083733855, 0.5732989906387373]  NOPD  \n",
       "4   [0.4402038441820304, 0.5645910949661206]    PD  \n",
       "5  [0.44345131886259637, 0.5928249305764615]    PD  "
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = graph_ci(predict_df, base_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ALL', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.470688  , 0.56133249])],\n",
       " [('ALL', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.49467452, 0.58076716])],\n",
       " [('NOPD', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.46338199, 0.55223387])],\n",
       " [('NOPD', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.47753506, 0.5634207 ])],\n",
       " [('PD', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.4610133, 0.5505779])],\n",
       " [('PD', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.48170062, 0.57266068])]]"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ALL', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.46412033, 0.58517592])],\n",
       " [('ALL', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.48594683, 0.5919749 ])],\n",
       " [('NOPD', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.45803984, 0.57427771])],\n",
       " [('NOPD', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.46958834, 0.57768336])],\n",
       " [('PD', 'LogisticRegression(random_state=2020)'),\n",
       "  array([0.44704029, 0.55731509])],\n",
       " [('PD', 'RandomForestClassifier(random_state=2020)'),\n",
       "  array([0.46083828, 0.58935916])]]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "delong = []\n",
    "bootstrap = []\n",
    "\n",
    "for i in predict_df.columns:\n",
    "    columns.append(i)\n",
    "\n",
    "for i,j in enumerate(columns):\n",
    "    delong.append([columns[i], calc_auc_ci(ytest.values.ravel(), predict_df[columns[i]], alpha=0.95)])\n",
    "    bootstrap.append([columns[i], bootstrap_error_estimate(predict_df[columns[i]], ytest.values.ravel(), roc_auc_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_comparison_sets(predict_df, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 5.21920668e-05, 1.06471816e-02, 1.06471816e-02,\n",
       "       1.10647182e-02, 1.10647182e-02, 1.45615866e-02, 1.45615866e-02,\n",
       "       1.96242171e-02, 1.96242171e-02, 2.22860125e-02, 2.22860125e-02,\n",
       "       2.73486430e-02, 2.73486430e-02, 3.27766180e-02, 3.27766180e-02,\n",
       "       3.47077244e-02, 3.47077244e-02, 3.93006263e-02, 3.93006263e-02,\n",
       "       5.29227557e-02, 5.29227557e-02, 5.43841336e-02, 5.43841336e-02,\n",
       "       5.46972860e-02, 5.46972860e-02, 6.28392484e-02, 6.28392484e-02,\n",
       "       6.90501044e-02, 6.90501044e-02, 6.98851775e-02, 6.98851775e-02,\n",
       "       7.11899791e-02, 7.11899791e-02, 7.44780793e-02, 7.44780793e-02,\n",
       "       7.57828810e-02, 7.57828810e-02, 9.53549061e-02, 9.53549061e-02,\n",
       "       9.93215031e-02, 9.93215031e-02, 1.03810021e-01, 1.03810021e-01,\n",
       "       1.14509395e-01, 1.14509395e-01, 1.17484342e-01, 1.17484342e-01,\n",
       "       1.24634656e-01, 1.24634656e-01, 1.25469729e-01, 1.25469729e-01,\n",
       "       1.31002088e-01, 1.31002088e-01, 1.32828810e-01, 1.32828810e-01,\n",
       "       1.34551148e-01, 1.34551148e-01, 1.37108559e-01, 1.37108559e-01,\n",
       "       1.59446764e-01, 1.59446764e-01, 1.62787056e-01, 1.62787056e-01,\n",
       "       1.63361169e-01, 1.63361169e-01, 1.68058455e-01, 1.68058455e-01,\n",
       "       1.73434238e-01, 1.73434238e-01, 1.77244259e-01, 1.77244259e-01,\n",
       "       1.80532359e-01, 1.80532359e-01, 1.89300626e-01, 1.89300626e-01,\n",
       "       1.97442589e-01, 1.97442589e-01, 2.09237996e-01, 2.09237996e-01,\n",
       "       2.11638831e-01, 2.11638831e-01, 2.48903967e-01, 2.48903967e-01,\n",
       "       2.52296451e-01, 2.52296451e-01, 2.53444676e-01, 2.53444676e-01,\n",
       "       2.60699374e-01, 2.60699374e-01, 2.73016701e-01, 2.73016701e-01,\n",
       "       2.76617954e-01, 2.76617954e-01, 2.81524008e-01, 2.81524008e-01,\n",
       "       2.85542797e-01, 2.85542797e-01, 3.09290188e-01, 3.09290188e-01,\n",
       "       3.19780793e-01, 3.19780793e-01, 3.38256785e-01, 3.38256785e-01,\n",
       "       3.53914405e-01, 3.53914405e-01, 3.55741127e-01, 3.55741127e-01,\n",
       "       3.63256785e-01, 3.63256785e-01, 3.63569937e-01, 3.63569937e-01,\n",
       "       3.65083507e-01, 3.65083507e-01, 3.66388309e-01, 3.66388309e-01,\n",
       "       3.67118998e-01, 3.67118998e-01, 3.68945720e-01, 3.68945720e-01,\n",
       "       3.93215031e-01, 3.93215031e-01, 3.98016701e-01, 3.98016701e-01,\n",
       "       4.02609603e-01, 4.02609603e-01, 4.07933194e-01, 4.07933194e-01,\n",
       "       4.09968685e-01, 4.09968685e-01, 4.10386221e-01, 4.10386221e-01,\n",
       "       4.15240084e-01, 4.15240084e-01, 4.16753653e-01, 4.16753653e-01,\n",
       "       4.21868476e-01, 4.21868476e-01, 4.23695198e-01, 4.23695198e-01,\n",
       "       4.39979123e-01, 4.39979123e-01, 4.44415449e-01, 4.44415449e-01,\n",
       "       4.55480167e-01, 4.55480167e-01, 4.57933194e-01, 4.57933194e-01,\n",
       "       4.60281837e-01, 4.60281837e-01, 4.62265136e-01, 4.62265136e-01,\n",
       "       4.65396660e-01, 4.65396660e-01, 4.67484342e-01, 4.67484342e-01,\n",
       "       4.69989562e-01, 4.69989562e-01, 4.72338205e-01, 4.72338205e-01,\n",
       "       4.72599165e-01, 4.72599165e-01, 4.85542797e-01, 4.85542797e-01,\n",
       "       4.89874739e-01, 4.89874739e-01, 4.95198330e-01, 4.95198330e-01,\n",
       "       4.97390397e-01, 4.97390397e-01, 5.01722338e-01, 5.01722338e-01,\n",
       "       5.06784969e-01, 5.06784969e-01, 5.10751566e-01, 5.10751566e-01,\n",
       "       5.14561587e-01, 5.14561587e-01, 5.18215031e-01, 5.18215031e-01,\n",
       "       5.19102296e-01, 5.19102296e-01, 5.20041754e-01, 5.20041754e-01,\n",
       "       5.34759916e-01, 5.34759916e-01, 5.59342380e-01, 5.59342380e-01,\n",
       "       5.65344468e-01, 5.65344468e-01, 5.93058455e-01, 5.93058455e-01,\n",
       "       5.94258873e-01, 5.94258873e-01, 5.97077244e-01, 5.97077244e-01,\n",
       "       6.01722338e-01, 6.01722338e-01, 6.02505219e-01, 6.02505219e-01,\n",
       "       6.06576200e-01, 6.06576200e-01, 6.11951983e-01, 6.11951983e-01,\n",
       "       6.13622129e-01, 6.13622129e-01, 6.16858038e-01, 6.16858038e-01,\n",
       "       6.34290188e-01, 6.34290188e-01, 6.35594990e-01, 6.35594990e-01,\n",
       "       6.38308977e-01, 6.38308977e-01, 6.52922756e-01, 6.52922756e-01,\n",
       "       6.60647182e-01, 6.60647182e-01, 6.66910230e-01, 6.66910230e-01,\n",
       "       6.69832985e-01, 6.69832985e-01, 6.87369520e-01, 6.87369520e-01,\n",
       "       6.91492693e-01, 6.91492693e-01, 6.94519833e-01, 6.94519833e-01,\n",
       "       6.99895616e-01, 6.99895616e-01, 7.00887265e-01, 7.00887265e-01,\n",
       "       7.02453027e-01, 7.02453027e-01, 7.25782881e-01, 7.25782881e-01,\n",
       "       7.46398747e-01, 7.46398747e-01, 7.51983299e-01, 7.51983299e-01,\n",
       "       7.59290188e-01, 7.59290188e-01, 7.65866388e-01, 7.65866388e-01,\n",
       "       7.67849687e-01, 7.67849687e-01, 7.72286013e-01, 7.72286013e-01,\n",
       "       7.75260960e-01, 7.75260960e-01, 7.81263048e-01, 7.81263048e-01,\n",
       "       7.90031315e-01, 7.90031315e-01, 7.91492693e-01, 7.91492693e-01,\n",
       "       7.93997912e-01, 7.93997912e-01, 7.97442589e-01, 7.97442589e-01,\n",
       "       7.97912317e-01, 7.97912317e-01, 8.01983299e-01, 8.01983299e-01,\n",
       "       8.05271399e-01, 8.05271399e-01, 8.22651357e-01, 8.22651357e-01,\n",
       "       8.23903967e-01, 8.23903967e-01, 8.28131524e-01, 8.28131524e-01,\n",
       "       8.29853862e-01, 8.29853862e-01, 8.43684760e-01, 8.43684760e-01,\n",
       "       8.46607516e-01, 8.46607516e-01, 8.52348643e-01, 8.52348643e-01,\n",
       "       8.63308977e-01, 8.63308977e-01, 8.70876827e-01, 8.70876827e-01,\n",
       "       8.71607516e-01, 8.71607516e-01, 8.92954071e-01, 8.92954071e-01,\n",
       "       9.05010438e-01, 9.05010438e-01, 9.17118998e-01, 9.17118998e-01,\n",
       "       9.19467641e-01, 9.19467641e-01, 9.21085595e-01, 9.21085595e-01,\n",
       "       9.34759916e-01, 9.34759916e-01, 9.43058455e-01, 9.43058455e-01,\n",
       "       9.46764092e-01, 9.46764092e-01, 9.48225470e-01, 9.48225470e-01,\n",
       "       9.51409186e-01, 9.51409186e-01, 9.57933194e-01, 9.57933194e-01,\n",
       "       9.59498956e-01, 9.59498956e-01, 9.60751566e-01, 9.60751566e-01,\n",
       "       9.66075157e-01, 9.66075157e-01, 9.78914405e-01, 9.78914405e-01,\n",
       "       9.91701461e-01, 9.91701461e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.loc[(result_table.classifier == 'LogisticRegression(random_state=2020)') & (result_table.set == 'ALL')]['fpr'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5160102426931106"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.loc[(result_table['classifier'] == 'LogisticRegression(random_state=2020)') & (result_table['set'] == 'ALL')]['auc'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5160102426931106"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.loc[result_table.set == 'ALL']['auc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 5.2192066805845514e-05, 0.01064718162839...\n",
       "Name: fpr, dtype: object"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.loc[(result_table.classifier == 'LogisticRegression(random_state=2020)') & (result_table.set == 'ALL')]['fpr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ALL\n",
      "1 NOPD\n",
      "2 PD\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(result_table.set.unique()):\n",
    "    print(k,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the figure\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in (self.base_models):\n",
    "\n",
    "    plt.plot(result_table.loc['XGBoost']['fpr'], \n",
    "             result_table.loc['XGBoost']['tpr'],\n",
    "             color = 'royalblue',\n",
    "             label=\"{}, AUC={:.3f}\".format('XGBoost', result_table.loc['XGBoost']['auc']))\n",
    "    plt.plot(result_table.loc['Random Forest']['fpr'], \n",
    "             result_table.loc['Random Forest']['tpr'],\n",
    "             color = 'seagreen',\n",
    "             label=\"{}, AUC={:.3f}\".format('Random Forest', result_table.loc['Random Forest']['auc']))\n",
    "    plt.plot(result_table.loc['Logistic Regression']['fpr'], \n",
    "             result_table.loc['Logistic Regression']['tpr'],\n",
    "             color = 'chocolate',\n",
    "             label=\"{}, AUC={:.3f}\".format('Logistic Regression', result_table.loc['Logistic Regression']['auc']))\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='gray', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "plt.savefig('ROC_ALL.png',  dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LogisticRegression(random_state=2020)\n",
      "1 RandomForestClassifier(random_state=2020)\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(result_table.classifier.unique()):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LogisticRegression(random_state=2020)'"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.classifier.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the figure\n",
    "# fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "# for i in result_table.index:\n",
    "#     plt.plot(result_table.loc[i]['fpr'], \n",
    "#              result_table.loc[i]['tpr'], \n",
    "#              label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    \n",
    "# plt.plot([0,1], [0,1], color='gray', linestyle='--')\n",
    "\n",
    "# plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "# plt.xlabel(\"Flase Positive Rate\", fontsize=15)\n",
    "\n",
    "# plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "# plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "# plt.title('ROC Curve Logistic Regression Analysis', fontweight='bold', fontsize=15)\n",
    "# plt.legend(prop={'size':13}, loc='lower right')\n",
    "# plt.savefig('ROC_LOG.png',  dpi=1200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Probability distribution for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of predicted probabilities\n",
    "plt.figure(figsize=(12, 4))\n",
    "nclasses = 2\n",
    "for i in range(nclasses):\n",
    "    \n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.hist(train_proba[:, i], bins=10, histtype='bar', rwidth=0.95)\n",
    "    plt.xlim(0,1)\n",
    "    plt.title('Predicted class-{} probabilities'.format(i+1))\n",
    "    plt.xlabel('Probability')\n",
    "    plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Over-Predict a Label than Under-Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_predict(data, threshods):\n",
    "\n",
    "    argmax = np.argmax(data)\n",
    "\n",
    "    ## If the argmax is 2 (class-3) then ovbiously return this highest label\n",
    "    if argmax == 2: \n",
    "        return (argmax +1)\n",
    "\n",
    "    # If argmax is 1 (class-2) there is a chnace that, label is class-2 if\n",
    "    # the probability of the class is greater than the threshold otherwise obviously\n",
    "    # return this highest label (class-3)\n",
    "    elif argmax == 1:\n",
    "        if data[argmax] >= threshods[argmax] : \n",
    "            return (argmax +1)\n",
    "        else:\n",
    "            return (argmax +2)\n",
    "\n",
    "    # If the argmax is 0 (class-1) then there are chances that label is class-1 if\n",
    "    # the probability of the class is greater than the threshold otherwise label can be\n",
    "    # either next two highest labels (class-2 or class-3). To determine the exact class\n",
    "    # class, we have to consider four cases.\n",
    "    # case A : if class_2_prob >= threshold and class_3_prob < threshold then pick class-2\n",
    "    # case B : if class_3_prob >= threshold and class_2_prob < threshold then pick class-3\n",
    "    # case C : if class_2_prob < threshold and class_3_prob < threshold then pick class-1\n",
    "    # case D : if class_2_prob > threshold and class_3_prob > threshold then pick class-3\n",
    "\n",
    "    elif argmax == 0:\n",
    "\n",
    "        if data[argmax] >= threshods[argmax] : \n",
    "            return (argmax +1)\n",
    "        else:\n",
    "            # case A : if class_2_prob >= threshold and class_3_prob < threshold then pick class-2\n",
    "            if data[argmax + 1] >= threshods[argmax + 1] and data[argmax + 2] < threshods[argmax + 2]:\n",
    "                return (argmax + 2)\n",
    "\n",
    "            # case B : if class_3_prob >= threshold and class_2_prob < threshold then pick class-3\n",
    "            if data[argmax + 2] >= threshods[argmax + 2] and data[argmax + 1] < threshods[argmax + 1]:\n",
    "                return (argmax + 3)\n",
    "\n",
    "            # case C : if class_2_prob < threshold and class_3_prob < threshold then pick class-1\n",
    "            if data[argmax + 1] < threshods[argmax + 1] and data[argmax + 2] < threshods[argmax + 2]:\n",
    "                return (argmax + 1)\n",
    "\n",
    "            # case D : if class_2_prob > threshold and class_3_prob > threshold then pick class-3\n",
    "            if data[argmax + 1] > threshods[argmax + 1] and data[argmax + 2] > threshods[argmax + 2]:\n",
    "                return (argmax + 3)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding threshold probability of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = label_binarize(ytrain, classes=[0, 1])\n",
    "th1 = roc_curve(ytrain['y'], train_proba[:, 0])\n",
    "th2 = roc_curve(ytrain['y'], train_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(th1))\n",
    "print(np.median(th2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(train_proba[1\n",
    "                      , :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [0.575, 0.425]\n",
    "new_pred = []\n",
    "for i in range(train_pred.shape[0]):\n",
    "    new_pred.append(re_predict(train_proba[i, :], threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1. The F-1 score of the model {}\\n'.format(f1_score(ytrain, new_pred, average='macro')))\n",
    "print('2. The recall score of the model {}\\n'.format(recall_score(ytrain, new_pred, average='macro')))\n",
    "print('3. The roc score of the model {}\\n'.format(roc_auc_score(ytrain, new_pred, average='macro')))\n",
    "print('4. Classification report \\n {} \\n'.format(classification_report(ytrain, new_pred)))\n",
    "print('5. Confusion matrix \\n {} \\n'.format(confusion_matrix(ytrain, new_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tpred_prob3 = []\n",
    "for i in range(test_proba.shape[0]):\n",
    "    final_tpred_prob3.append(re_predict(test_proba[i, :], threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'min_samples_split':rf_min_samples_leaf,\n",
    "               'bootstrap': rf_bootstrap,\n",
    "               'class_weight': rf_class}from xgboost import XGBClassifier\n",
    "tpred_prob3 = pd.DataFrame(final_tpred_prob3)\n",
    "tpred_prob3.to_csv('final.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
