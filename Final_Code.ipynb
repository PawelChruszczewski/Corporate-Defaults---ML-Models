{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Paweł Chruszczewsju\n",
    "\n",
    "Objective: The primary goal of this code is to develop a machine learning model that can classify the labels properly and address dataset imbalance. The dataset has three classes (1, 2, and 3). There are three problems in the challenge. In each problem, there is some specific task that needs to be done. In the following subsections, I describe three techniques I used to overcome the data imbalance problem.\n",
    "\n",
    "Codes and libraries: This project requires Python  3. I have Used python 3.9. The following Python libraries are also required:\n",
    "\n",
    "<li> numpy\n",
    "<li> pandas\n",
    "<li> matplotlib\n",
    "<li> scikit-learn\n",
    "<li> xgboost\n",
    "<li> scipy\n",
    "<li> seaborn\n",
    "<li> itertools\n",
    "<li> math\n",
    "<li> mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "## Plotting libraries\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "## Sklearn Libraries\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.gaussian_process.kernels import DotProduct\n",
    "# from sklearn.gaussian_process.kernels import Matern\n",
    "# from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "# from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc, \\\n",
    "            classification_report, recall_score, precision_recall_curve, roc_auc_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "## XGBoost Librarires\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# pickle library\n",
    "import pickle\n",
    "\n",
    "## Scipy Libraries\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import f\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import randint\n",
    "\n",
    "#statistics\n",
    "from statistics import stdev \n",
    "\n",
    "#itertools\n",
    "from itertools import combinations, permutations\n",
    "\n",
    "#mlxtend\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "#math\n",
    "import math\n",
    "\n",
    "# Define random state\n",
    "random_state = 2020\n",
    "np.random.seed(random_state)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset & Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['gdp_change'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-a7b6489eb19a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\pawel\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pawel\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1912\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1915\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pawel\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1780\u001b[0m         \u001b[1;31m# caller is responsible for ensuring non-None axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1782\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1783\u001b[0m         \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pawel\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2315\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2317\u001b[1;33m             raise IndexingError(\n\u001b[0m\u001b[0;32m   2318\u001b[0m                 \u001b[1;34m\"Unalignable boolean Series provided as \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m                 \u001b[1;34m\"indexer (index of the boolean Series and of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "y.loc[y.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pd</th>\n",
       "      <th>y</th>\n",
       "      <th>atch</th>\n",
       "      <th>empch</th>\n",
       "      <th>salech</th>\n",
       "      <th>roech</th>\n",
       "      <th>ptbch</th>\n",
       "      <th>nich</th>\n",
       "      <th>dlcpdlttdebit</th>\n",
       "      <th>...</th>\n",
       "      <th>quickratio</th>\n",
       "      <th>bvdmv</th>\n",
       "      <th>nidseq</th>\n",
       "      <th>actdnat</th>\n",
       "      <th>ebitdxint</th>\n",
       "      <th>redsale</th>\n",
       "      <th>nidsale</th>\n",
       "      <th>ebitdsale</th>\n",
       "      <th>ltdat</th>\n",
       "      <th>ffodlt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.585663e-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275937</td>\n",
       "      <td>0.189045</td>\n",
       "      <td>0.132754</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>1.190518</td>\n",
       "      <td>0.118336</td>\n",
       "      <td>2.508597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855730</td>\n",
       "      <td>0.405124</td>\n",
       "      <td>0.120632</td>\n",
       "      <td>1.475566</td>\n",
       "      <td>0.141434</td>\n",
       "      <td>0.130070</td>\n",
       "      <td>0.046393</td>\n",
       "      <td>0.091455</td>\n",
       "      <td>0.518975</td>\n",
       "      <td>0.233942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.021916e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185610</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.202329</td>\n",
       "      <td>-0.006262</td>\n",
       "      <td>-0.634720</td>\n",
       "      <td>0.143485</td>\n",
       "      <td>1.678391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862750</td>\n",
       "      <td>0.545357</td>\n",
       "      <td>0.114370</td>\n",
       "      <td>1.257911</td>\n",
       "      <td>0.121963</td>\n",
       "      <td>0.144769</td>\n",
       "      <td>0.051514</td>\n",
       "      <td>0.096485</td>\n",
       "      <td>0.428689</td>\n",
       "      <td>0.303986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.698752e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212075</td>\n",
       "      <td>0.099448</td>\n",
       "      <td>0.165826</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.143538</td>\n",
       "      <td>0.160463</td>\n",
       "      <td>2.079429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720055</td>\n",
       "      <td>0.505766</td>\n",
       "      <td>0.141086</td>\n",
       "      <td>1.384712</td>\n",
       "      <td>0.157226</td>\n",
       "      <td>0.168131</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.100498</td>\n",
       "      <td>0.471844</td>\n",
       "      <td>0.261582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.373830e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250723</td>\n",
       "      <td>0.276382</td>\n",
       "      <td>0.168910</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.332061</td>\n",
       "      <td>0.077768</td>\n",
       "      <td>2.151250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778922</td>\n",
       "      <td>0.433039</td>\n",
       "      <td>0.144621</td>\n",
       "      <td>1.498123</td>\n",
       "      <td>0.175031</td>\n",
       "      <td>0.188591</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.518562</td>\n",
       "      <td>0.233980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.429146e-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090154</td>\n",
       "      <td>-0.043307</td>\n",
       "      <td>0.094780</td>\n",
       "      <td>-0.009272</td>\n",
       "      <td>0.745122</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>2.265693</td>\n",
       "      <td>...</td>\n",
       "      <td>1.077016</td>\n",
       "      <td>0.327398</td>\n",
       "      <td>0.135348</td>\n",
       "      <td>1.453859</td>\n",
       "      <td>0.213208</td>\n",
       "      <td>0.210052</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>0.105313</td>\n",
       "      <td>0.512129</td>\n",
       "      <td>0.221352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            pd    y      atch     empch    salech     roech  \\\n",
       "0           1  2.585663e-20  0.0  0.275937  0.189045  0.132754  0.016827   \n",
       "1           2  2.021916e-04  0.0  0.185610  0.016854  0.202329 -0.006262   \n",
       "2           3  1.698752e-03  0.0  0.212075  0.099448  0.165826  0.026716   \n",
       "3           4  5.373830e-15  0.0  0.250723  0.276382  0.168910  0.003535   \n",
       "4           5  5.429146e-23  0.0  0.090154 -0.043307  0.094780 -0.009272   \n",
       "\n",
       "      ptbch      nich  dlcpdlttdebit  ...  quickratio     bvdmv    nidseq  \\\n",
       "0  1.190518  0.118336       2.508597  ...    0.855730  0.405124  0.120632   \n",
       "1 -0.634720  0.143485       1.678391  ...    0.862750  0.545357  0.114370   \n",
       "2  0.143538  0.160463       2.079429  ...    0.720055  0.505766  0.141086   \n",
       "3  0.332061  0.077768       2.151250  ...    0.778922  0.433039  0.144621   \n",
       "4  0.745122  0.016664       2.265693  ...    1.077016  0.327398  0.135348   \n",
       "\n",
       "    actdnat  ebitdxint   redsale   nidsale  ebitdsale     ltdat    ffodlt  \n",
       "0  1.475566   0.141434  0.130070  0.046393   0.091455  0.518975  0.233942  \n",
       "1  1.257911   0.121963  0.144769  0.051514   0.096485  0.428689  0.303986  \n",
       "2  1.384712   0.157226  0.168131  0.061078   0.100498  0.471844  0.261582  \n",
       "3  1.498123   0.175031  0.188591  0.061064   0.109792  0.518562  0.233980  \n",
       "4  1.453859   0.213208  0.210052  0.057668   0.105313  0.512129  0.221352  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>44645.409069</td>\n",
       "      <td>28120.658134</td>\n",
       "      <td>7.710000e+02</td>\n",
       "      <td>1.966800e+04</td>\n",
       "      <td>4.309700e+04</td>\n",
       "      <td>68352.000000</td>\n",
       "      <td>96264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.059888</td>\n",
       "      <td>0.174016</td>\n",
       "      <td>8.938556e-188</td>\n",
       "      <td>1.474051e-24</td>\n",
       "      <td>1.646004e-09</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.912808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atch</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.150981</td>\n",
       "      <td>0.493803</td>\n",
       "      <td>-6.153846e-01</td>\n",
       "      <td>-4.053647e-02</td>\n",
       "      <td>5.274254e-02</td>\n",
       "      <td>0.184562</td>\n",
       "      <td>3.185871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empch</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.085824</td>\n",
       "      <td>0.356288</td>\n",
       "      <td>-6.535496e-01</td>\n",
       "      <td>-4.444444e-02</td>\n",
       "      <td>2.155172e-02</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>2.206522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salech</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.491591</td>\n",
       "      <td>3.019083</td>\n",
       "      <td>-9.191919e-01</td>\n",
       "      <td>-3.418802e-02</td>\n",
       "      <td>7.044831e-02</td>\n",
       "      <td>0.215830</td>\n",
       "      <td>28.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roech</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-0.004649</td>\n",
       "      <td>2.057030</td>\n",
       "      <td>-1.073889e+01</td>\n",
       "      <td>-9.428077e-02</td>\n",
       "      <td>-4.720736e-03</td>\n",
       "      <td>0.057653</td>\n",
       "      <td>11.925383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptbch</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-0.094815</td>\n",
       "      <td>9.646932</td>\n",
       "      <td>-5.594627e+01</td>\n",
       "      <td>-5.690631e-01</td>\n",
       "      <td>-2.517948e-03</td>\n",
       "      <td>0.502332</td>\n",
       "      <td>54.324612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nich</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.535532</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-2.379024e-01</td>\n",
       "      <td>4.158620e-02</td>\n",
       "      <td>0.268966</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dlcpdlttdebit</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>2.417913</td>\n",
       "      <td>10.705792</td>\n",
       "      <td>-4.813566e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.299619e+00</td>\n",
       "      <td>4.197935</td>\n",
       "      <td>59.401297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nwcdta</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.153577</td>\n",
       "      <td>0.481716</td>\n",
       "      <td>-3.281553e+00</td>\n",
       "      <td>2.736148e-02</td>\n",
       "      <td>1.735873e-01</td>\n",
       "      <td>0.364889</td>\n",
       "      <td>0.852339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redat</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-1.535865</td>\n",
       "      <td>6.692772</td>\n",
       "      <td>-5.116779e+01</td>\n",
       "      <td>-3.595846e-01</td>\n",
       "      <td>1.086992e-01</td>\n",
       "      <td>0.332331</td>\n",
       "      <td>0.931502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdat</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.454485</td>\n",
       "      <td>-3.089931e+00</td>\n",
       "      <td>-1.226171e-02</td>\n",
       "      <td>6.348126e-02</td>\n",
       "      <td>0.113046</td>\n",
       "      <td>0.345728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mvaluedtd</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.714805</td>\n",
       "      <td>1.672636</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.089488e-02</td>\n",
       "      <td>2.179571e-01</td>\n",
       "      <td>0.623297</td>\n",
       "      <td>12.258328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saledat</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>1.032991</td>\n",
       "      <td>0.806825</td>\n",
       "      <td>2.444267e-03</td>\n",
       "      <td>4.601262e-01</td>\n",
       "      <td>8.584606e-01</td>\n",
       "      <td>1.384240</td>\n",
       "      <td>4.336329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nidat</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-0.108801</td>\n",
       "      <td>0.543288</td>\n",
       "      <td>-3.896328e+00</td>\n",
       "      <td>-4.542284e-02</td>\n",
       "      <td>3.163087e-02</td>\n",
       "      <td>0.072898</td>\n",
       "      <td>0.314877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtdat</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.281282</td>\n",
       "      <td>0.317082</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.939674e-02</td>\n",
       "      <td>2.286567e-01</td>\n",
       "      <td>0.381564</td>\n",
       "      <td>2.216553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lctdact</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.924867</td>\n",
       "      <td>1.663028</td>\n",
       "      <td>5.755510e-02</td>\n",
       "      <td>3.512607e-01</td>\n",
       "      <td>5.658064e-01</td>\n",
       "      <td>0.885882</td>\n",
       "      <td>13.741023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickratio</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>1.820242</td>\n",
       "      <td>2.384642</td>\n",
       "      <td>3.181737e-02</td>\n",
       "      <td>6.517354e-01</td>\n",
       "      <td>1.089051e+00</td>\n",
       "      <td>1.925814</td>\n",
       "      <td>15.852184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bvdmv</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.615904</td>\n",
       "      <td>0.905476</td>\n",
       "      <td>-3.135244e+00</td>\n",
       "      <td>2.414832e-01</td>\n",
       "      <td>4.737350e-01</td>\n",
       "      <td>0.826153</td>\n",
       "      <td>4.981070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nidseq</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>1.108054</td>\n",
       "      <td>-5.933333e+00</td>\n",
       "      <td>-4.902829e-02</td>\n",
       "      <td>8.836259e-02</td>\n",
       "      <td>0.171530</td>\n",
       "      <td>5.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actdnat</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>1.604300</td>\n",
       "      <td>-6.152082e+00</td>\n",
       "      <td>4.578332e-01</td>\n",
       "      <td>8.626532e-01</td>\n",
       "      <td>1.280143</td>\n",
       "      <td>9.641316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdxint</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.143061</td>\n",
       "      <td>0.831714</td>\n",
       "      <td>-3.884415e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.396928e-02</td>\n",
       "      <td>0.269256</td>\n",
       "      <td>4.565972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redsale</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-31.279108</td>\n",
       "      <td>214.019581</td>\n",
       "      <td>-1.978520e+03</td>\n",
       "      <td>-5.106448e-01</td>\n",
       "      <td>1.091831e-01</td>\n",
       "      <td>0.358525</td>\n",
       "      <td>1.863845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nidsale</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-3.180740</td>\n",
       "      <td>21.173906</td>\n",
       "      <td>-1.925900e+02</td>\n",
       "      <td>-5.887786e-02</td>\n",
       "      <td>3.168032e-02</td>\n",
       "      <td>0.082468</td>\n",
       "      <td>0.571137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebitdsale</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>-3.385290</td>\n",
       "      <td>23.515122</td>\n",
       "      <td>-2.161579e+02</td>\n",
       "      <td>-1.442195e-02</td>\n",
       "      <td>6.513195e-02</td>\n",
       "      <td>0.135884</td>\n",
       "      <td>0.483358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltdat</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.611288</td>\n",
       "      <td>0.602404</td>\n",
       "      <td>5.254669e-02</td>\n",
       "      <td>3.505720e-01</td>\n",
       "      <td>5.320081e-01</td>\n",
       "      <td>0.690797</td>\n",
       "      <td>5.063739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffodlt</th>\n",
       "      <td>64285.0</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.952351</td>\n",
       "      <td>-5.565646e+00</td>\n",
       "      <td>1.676985e-02</td>\n",
       "      <td>1.520899e-01</td>\n",
       "      <td>0.316370</td>\n",
       "      <td>2.249405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count          mean           std            min  \\\n",
       "Unnamed: 0     64285.0  44645.409069  28120.658134   7.710000e+02   \n",
       "pd             64285.0      0.059888      0.174016  8.938556e-188   \n",
       "atch           64285.0      0.150981      0.493803  -6.153846e-01   \n",
       "empch          64285.0      0.085824      0.356288  -6.535496e-01   \n",
       "salech         64285.0      0.491591      3.019083  -9.191919e-01   \n",
       "roech          64285.0     -0.004649      2.057030  -1.073889e+01   \n",
       "ptbch          64285.0     -0.094815      9.646932  -5.594627e+01   \n",
       "nich           64285.0      0.013895      0.535532  -1.000000e+00   \n",
       "dlcpdlttdebit  64285.0      2.417913     10.705792  -4.813566e+01   \n",
       "nwcdta         64285.0      0.153577      0.481716  -3.281553e+00   \n",
       "redat          64285.0     -1.535865      6.692772  -5.116779e+01   \n",
       "ebitdat        64285.0     -0.049643      0.454485  -3.089931e+00   \n",
       "mvaluedtd      64285.0      0.714805      1.672636   0.000000e+00   \n",
       "saledat        64285.0      1.032991      0.806825   2.444267e-03   \n",
       "nidat          64285.0     -0.108801      0.543288  -3.896328e+00   \n",
       "dtdat          64285.0      0.281282      0.317082   0.000000e+00   \n",
       "lctdact        64285.0      0.924867      1.663028   5.755510e-02   \n",
       "quickratio     64285.0      1.820242      2.384642   3.181737e-02   \n",
       "bvdmv          64285.0      0.615904      0.905476  -3.135244e+00   \n",
       "nidseq         64285.0     -0.000637      1.108054  -5.933333e+00   \n",
       "actdnat        64285.0      0.983954      1.604300  -6.152082e+00   \n",
       "ebitdxint      64285.0      0.143061      0.831714  -3.884415e+00   \n",
       "redsale        64285.0    -31.279108    214.019581  -1.978520e+03   \n",
       "nidsale        64285.0     -3.180740     21.173906  -1.925900e+02   \n",
       "ebitdsale      64285.0     -3.385290     23.515122  -2.161579e+02   \n",
       "ltdat          64285.0      0.611288      0.602404   5.254669e-02   \n",
       "ffodlt         64285.0      0.022839      0.952351  -5.565646e+00   \n",
       "\n",
       "                        25%           50%           75%           max  \n",
       "Unnamed: 0     1.966800e+04  4.309700e+04  68352.000000  96264.000000  \n",
       "pd             1.474051e-24  1.646004e-09      0.002571      0.912808  \n",
       "atch          -4.053647e-02  5.274254e-02      0.184562      3.185871  \n",
       "empch         -4.444444e-02  2.155172e-02      0.126582      2.206522  \n",
       "salech        -3.418802e-02  7.044831e-02      0.215830     28.411765  \n",
       "roech         -9.428077e-02 -4.720736e-03      0.057653     11.925383  \n",
       "ptbch         -5.690631e-01 -2.517948e-03      0.502332     54.324612  \n",
       "nich          -2.379024e-01  4.158620e-02      0.268966      1.000000  \n",
       "dlcpdlttdebit  0.000000e+00  1.299619e+00      4.197935     59.401297  \n",
       "nwcdta         2.736148e-02  1.735873e-01      0.364889      0.852339  \n",
       "redat         -3.595846e-01  1.086992e-01      0.332331      0.931502  \n",
       "ebitdat       -1.226171e-02  6.348126e-02      0.113046      0.345728  \n",
       "mvaluedtd      4.089488e-02  2.179571e-01      0.623297     12.258328  \n",
       "saledat        4.601262e-01  8.584606e-01      1.384240      4.336329  \n",
       "nidat         -4.542284e-02  3.163087e-02      0.072898      0.314877  \n",
       "dtdat          6.939674e-02  2.286567e-01      0.381564      2.216553  \n",
       "lctdact        3.512607e-01  5.658064e-01      0.885882     13.741023  \n",
       "quickratio     6.517354e-01  1.089051e+00      1.925814     15.852184  \n",
       "bvdmv          2.414832e-01  4.737350e-01      0.826153      4.981070  \n",
       "nidseq        -4.902829e-02  8.836259e-02      0.171530      5.583333  \n",
       "actdnat        4.578332e-01  8.626532e-01      1.280143      9.641316  \n",
       "ebitdxint      0.000000e+00  7.396928e-02      0.269256      4.565972  \n",
       "redsale       -5.106448e-01  1.091831e-01      0.358525      1.863845  \n",
       "nidsale       -5.887786e-02  3.168032e-02      0.082468      0.571137  \n",
       "ebitdsale     -1.442195e-02  6.513195e-02      0.135884      0.483358  \n",
       "ltdat          3.505720e-01  5.320081e-01      0.690797      5.063739  \n",
       "ffodlt         1.676985e-02  1.520899e-01      0.316370      2.249405  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ffodlt           64285\n",
       "ltdat            64285\n",
       "pd               64285\n",
       "y                64285\n",
       "atch             64285\n",
       "empch            64285\n",
       "salech           64285\n",
       "roech            64285\n",
       "ptbch            64285\n",
       "nich             64285\n",
       "dlcpdlttdebit    64285\n",
       "nwcdta           64285\n",
       "redat            64285\n",
       "ebitdat          64285\n",
       "mvaluedtd        64285\n",
       "saledat          64285\n",
       "nidat            64285\n",
       "dtdat            64285\n",
       "lctdact          64285\n",
       "quickratio       64285\n",
       "bvdmv            64285\n",
       "nidseq           64285\n",
       "actdnat          64285\n",
       "ebitdxint        64285\n",
       "redsale          64285\n",
       "nidsale          64285\n",
       "ebitdsale        64285\n",
       "Unnamed: 0       64285\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'y']\n",
    "y = data.loc[:, data.columns == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing extreme values(inf) to the 0.01 percentile and 0.99 percentile\n",
    "def winsorize_all(predictors):\n",
    "    for col in predictors.columns: \n",
    "         predictors[col] = winsorize(predictors[col], limits=0.01)\n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = winsorize_all(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0.176026\n",
       "pd               3.454312\n",
       "atch             3.674639\n",
       "empch            3.161556\n",
       "salech           8.503536\n",
       "roech            0.735914\n",
       "ptbch           -0.214624\n",
       "nich            -0.114128\n",
       "dlcpdlttdebit    0.748810\n",
       "nwcdta          -4.449948\n",
       "redat           -5.779699\n",
       "ebitdat         -4.685178\n",
       "mvaluedtd        4.953619\n",
       "saledat          1.550603\n",
       "nidat           -5.027924\n",
       "dtdat            3.217487\n",
       "lctdact          6.043565\n",
       "quickratio       3.619294\n",
       "bvdmv            1.082681\n",
       "nidseq          -0.549455\n",
       "actdnat          1.132375\n",
       "ebitdxint        0.564292\n",
       "redsale         -8.350867\n",
       "nidsale         -8.124911\n",
       "ebitdsale       -8.284005\n",
       "ltdat            5.227732\n",
       "ffodlt          -3.249561\n",
       "dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predictors distribution\n",
    "# for i, col in enumerate(X.columns):\n",
    "#     plt.figure(i)\n",
    "#     sns.countplot(x=col, data=X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform first split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, \n",
    "                                                y, \n",
    "                                                test_size=0.2, \n",
    "                                                stratify = y,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_pd = xtrain.loc[:,xtrain.columns == 'pd']\n",
    "xtest_pd = xtest.loc[:,xtest.columns == 'pd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_nopd = xtrain.loc[:,xtrain.columns != 'pd']\n",
    "xtest_nopd = xtest.loc[:,xtest.columns != 'pd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_smoothing = np.logspace(-1,1, num=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_grid = {'gaussiannb__var_smoothing': var_smoothing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_params = [x for x in np.linspace(0.0, 2.5, 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_grid = {'quadraticdiscriminantanalysis__reg_param': qda_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the norm used in the penalization\n",
    "logreg_penalty = ['l1', 'l2', 'elasticnet', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse of regularization strength\n",
    "logreg_c = [0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to use in the optimization problem\n",
    "logreg_solver = ['newton-cg','liblinear', 'saga', 'lbfgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_weight = ['balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid = {'logisticregression__penalty' : logreg_penalty,\n",
    "               'logisticregression__C' : logreg_c,\n",
    "               'logisticregression__solver' : logreg_solver,\n",
    "               'logisticregression__class_weight': logreg_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion to split on\n",
    "dt_criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The strategy used to choose the split at each node\n",
    "# dt_splitter = ['best', 'random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "dt_max_depth = [int(x) for x in np.linspace(1, 20, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the default as a possible value\n",
    "dt_max_depth.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The minimum number of samples required to split an internal node\n",
    "# dt_min_samples_split = [int(x) for x in np.linspace(2, 40, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_min_impurity_decrease = [float(x) for x in np.linspace(0, 0.3, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The minimum number of samples required to be at a leaf node\n",
    "dt_min_samples_leaf = [int(x) for x in np.linspace(1, 5, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "dt_max_features = ['auto', 'sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights associated with classes\n",
    "dt_class = ['balanced_subsample', 'balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid = {'decisiontreeclassifier__criterion': dt_criterion,\n",
    "#            'decisiontreeclassifier__splitter': dt_splitter,\n",
    "           'decisiontreeclassifier__max_depth': dt_max_depth,\n",
    "#            'decisiontreeclassifier__min_samples_split': dt_min_samples_split,\n",
    "#            'decisiontreeclassifier__min_impurity_decrease': dt_min_impurity_decrease,\n",
    "           'decisiontreeclassifier__min_samples_leaf':dt_min_samples_leaf,\n",
    "           'decisiontreeclassifier__max_features':dt_max_features,\n",
    "           'decisiontreeclassifier__class_weight': dt_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(100, 300, 3)]\n",
    "rf_n_estimators.append(10)\n",
    "rf_n_estimators.append(50)\n",
    "rf_n_estimators.append(1000)\n",
    "rf_n_estimators.append(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_max_depth = [int(x) for x in np.linspace(1, 20, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_max_depth.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_max_features = ['auto', 'sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_min_samples_leaf = [int(x) for x in np.linspace(1, 5, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_min_samples_split = [int(x) for x in np.linspace(2, 40, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_min_impurity_decrease = [float(x) for x in np.linspace(0, 0.3, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method of selecting samples for training each tree\n",
    "# rf_bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_class = ['balanced_subsample', 'balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = {'randomforestclassifier__n_estimators': rf_n_estimators,\n",
    "           'randomforestclassifier__max_depth': rf_max_depth,\n",
    "           'randomforestclassifier__max_features': rf_max_features,\n",
    "           'randomforestclassifier__criterion': rf_criterion,\n",
    "#            'randomforestclassifier__min_samples_split': rf_min_samples_split,\n",
    "#            'randomforestclassifier__min_impurity_decrease': rf_min_impurity_decrease,\n",
    "           'randomforestclassifier__min_samples_leaf':rf_min_samples_leaf,\n",
    "#            'randomforestclassifier__bootstrap': rf_bootstrap,\n",
    "           'randomforestclassifier__class_weight': rf_class\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# base_models = [rdf]\n",
    "# n_splits = 5\n",
    "# grids = [rf_grid]\n",
    "# lgb_stack = Create_classifier(n_splits = n_splits, base_models = base_models, grids = grids)        \n",
    "# roc_auc_scores, feat_selected, feat_importance = lgb_stack.predict(xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in c:\\users\\pawel\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (5.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\pawel\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "adab_max_depth = [1,2,5,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to be used\n",
    "adab_n_estimators = [20,50,100,200,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "adab_eta = [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "adab_algorithm = ['SAMME', 'SAMME.R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "adab_grid = {'adaboostclassifier__base_estimator__max_depth': adab_max_depth,\n",
    "             'adaboostclassifier__n_estimators': adab_n_estimators,\n",
    "             'adaboostclassifier__learning_rate': adab_eta,\n",
    "             'adaboostclassifier__algorithm': adab_algorithm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "adab = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(random_state=random_state), random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to be used\n",
    "xgb_n_estimators = [20,50,100,200,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [1,2,5,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "xgb_eta = [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum loss reduction required to make further partition\n",
    "# xgb_gamma = [x for x in np.linspace(0, 0.5, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning objective used\n",
    "# xgb_objective = ['binary:logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_lambda = [10,20,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing of positive and negative weights\n",
    "xgb_weight = [119.85522788203754, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_colsample_bytree = [x for x in np.linspace(0.1, 1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_bytree = [x for x in np.linspace(0.1, 1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = {'xgbclassifier__n_estimators': xgb_n_estimators,\n",
    "            'xgbclassifier__max_depth': xgb_max_depth,\n",
    "            'xgbclassifier__min_child_weight': xgb_min_child_weight,\n",
    "            'xgbclassifier__tree_method': xgb_tree_method,\n",
    "            'xgbclassifier__learning_rate': xgb_eta,\n",
    "#             'xgbclassifier__gamma': xgb_gamma,\n",
    "#             'xgbclassifier__objective': xgb_objective,\n",
    "#             'xgbclassifier__reg_lambda':xgb_lambda,\n",
    "            'xgbclassifier__colsample_bytree':xgb_colsample_bytree,\n",
    "            'xgbclassifier__subsample_bytree':subsample_bytree,\n",
    "            'xgbclassifier__scale_pos_weight': xgb_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =  XGBClassifier(random_state = random_state, objective = 'binary:logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_leaf_size = [int(x) for x in np.linspace(1, 55, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_weights = ['uniform','distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_n_neighbors = [int(x) for x in np.linspace(1, 30, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_p= [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_metric = ['minkowski', 'euclidean', 'manhattan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = {'kneighborsclassifier__leaf_size':knn_leaf_size,\n",
    "            'kneighborsclassifier__weights':knn_weights,\n",
    "            'kneighborsclassifier__n_neighbors':knn_n_neighbors,\n",
    "            'kneighborsclassifier__p': knn_p,\n",
    "            'kneighborsclassifier__metric': knn_metric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity I choose 3 layers with the same number of neurons as there are features in my data set\n",
    "mlp_hidden_layer_sizes = [(26,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_activation = ['tanh', 'relu', 'logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_solver = ['lbfgs', 'sgd', 'adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_alpha = np.linspace(0.0001,0.1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_eta = ['constant','invscaling','adaptive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid = {'mlpclassifier__hidden_layer_sizes': mlp_hidden_layer_sizes,\n",
    "            'mlpclassifier__activation': mlp_activation,\n",
    "            'mlpclassifier__solver': mlp_solver,\n",
    "            'mlpclassifier__alpha': mlp_alpha,\n",
    "            'mlpclassifier__learning_rate': mlp_eta\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse of regularization strength\n",
    "svc_c = [0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel selects the type of hyperplane used to separate the data; \n",
    "# ‘linear’ will use a linear hyperplane (a line in the case of 2D data). ‘rbf’ and ‘poly’ uses a non linear hyper-plane;\n",
    "svc_kernel = ['linear', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when kernel set to ‘poly’, the degree of the polynomial used to find the hyperplane to split the data\n",
    "# svc_degree = [int(x) for x in np.linspace(0, 10, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter for non linear hyperplanes\n",
    "svc_gamma = [0.1, 1, 10, 100, 1000]\n",
    "svc_gamma.append('scale')\n",
    "svc_gamma.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_weight = ['balanced', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid = {'svc__C' : svc_c,\n",
    "            'svc__kernel':svc_kernel,\n",
    "#             'svc__degree':svc_degree,\n",
    "            'svc__gamma':svc_gamma,\n",
    "            'svc__class_weight':svc_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state = random_state, probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True, random_state=2020)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chosen_set = ['ALL', 'PDE', 'PD']\n",
    "base_models = [gnb, qda, logreg, dt, rf, adab, xgb, knn, svc, mlp]\n",
    "n_splits = 4\n",
    "grids = [gnb_grid, qda_grid, logreg_grid dt_grid, rf_grid, adab_grid, xgb_grid, knn_grid, svc_grid, mlp_grid]\n",
    "lgb_stack = Create_classifier(n_splits = n_splits, base_models = base_models, grids = grids)        \n",
    "roc_auc_scores, feat_selected, test_pred, estimators = lgb_stack.predict(xtrain, ytrain, xtest, ytest, chosen_set = chosen_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-307-720252682c46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgrids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgnb_grid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlgb_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCreate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mroc_auc_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchosen_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchosen_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-306-5b5e97f16fae>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x_train, y_train, x_test, y_test, chosen_set)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchosen_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_saved.sav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchosen_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "chosen_set = ['ALL', 'PDE', 'PD']\n",
    "base_models = [gnb]\n",
    "n_splits = 3\n",
    "grids = [gnb_grid]\n",
    "lgb_stack = Create_classifier(n_splits = n_splits, base_models = base_models, grids = grids)        \n",
    "roc_auc_scores, feat_selected, test_pred, estimators = lgb_stack.predict(xtrain, ytrain, xtest, ytest, chosen_set = chosen_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions of all sets\n",
    "predict_df = [test_pred, test_pred2, test_pred3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_stack = Create_classifier(n_splits = n_splits, base_models = base_models, grids = grids)        \n",
    "predict_df_all = lgb_stack.joined_scores(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_classifier(object):\n",
    "    def __init__(self, n_splits, base_models, grids):\n",
    "        self.n_splits = n_splits\n",
    "        self.base_models = base_models\n",
    "        self.grids = grids\n",
    "\n",
    "    def predict(self, x_train, y_train, x_test, y_test, chosen_set = ''):\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state = random_state)\n",
    "                  \n",
    "        roc_auc_scores = pd.DataFrame(columns = [str(i) for i in self.base_models])\n",
    "        test_pred = pd.DataFrame(np.zeros((x_test.shape[0], len(self.base_models))), columns=[str(i).split('(')[0].lower() for i in self.base_models])\n",
    "        test_pred.columns = pd.MultiIndex.from_product([[chosen_set], test_pred.columns])\n",
    "        feat_selected = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "        feat_importance = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "        estimators = []         \n",
    "        \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            pipe_lr = make_pipeline(PowerTransformer(method='yeo-johnson',standardize = True),\n",
    "                                    clf)\n",
    "            \n",
    "            search = RandomizedSearchCV(estimator=pipe_lr, param_distributions = self.grids[i], cv = cv, n_jobs=-1, verbose=True, scoring = 'roc_auc', iid = True, refit = True, n_iter = 10)\n",
    "            search = search.fit(x_train, y_train)\n",
    "            \n",
    "            filename = 'model_'+str(chosen_set)+str(clf)+'_saved.sav'\n",
    "            pickle.dump(search.best_estimator_.steps[2][1], open(filename, 'wb'))\n",
    "            \n",
    "            estimators.append([chosen_set, i, search.best_estimator_.steps[2][1]])\n",
    "            \n",
    "            predict_rdf = search.best_estimator_.predict_proba(x_test)[:,1]\n",
    "            test_pred[chosen_set][str(clf).split('(')[0].lower()] = predict_rdf.astype('float64')\n",
    "                  \n",
    "            roc_auc_scores.loc[0,str(clf)] = roc_auc_score(y_test, predict_rdf)\n",
    "            \n",
    "#             feat_est = search.best_estimator_.steps[1][1].k_feature_idx_\n",
    "            \n",
    "#             for j in feat_est:\n",
    "#                 feat_selected.iloc[j,i] = 1\n",
    "                  \n",
    "#             for j in x_train.columns:\n",
    "#                 feat_est = dict(zip(x_train.columns, search.best_estimator_.steps[1][1].k_feature_idx_))\n",
    "#                 feat_selected.loc[str(j), str(clf)] = feat_est[str(j)]\n",
    "                \n",
    "#                 try:\n",
    "#                     importances = dict(zip(x_train.columns, search.best_estimator_.named_steps[str(clf).split('(')[0].lower()].feature_importances_))\n",
    "#                     feat_importance.loc[str(j), str(clf)] = importances[str(j)]\n",
    "#                 except Exception:\n",
    "#                     pass\n",
    "                \n",
    "        return roc_auc_scores, test_pred, estimators\n",
    "    \n",
    "    def joined_scores(self, predict_df):\n",
    "    #         roc_auc_all = pd.concat(self.roc_auc)\n",
    "            predict_df_all = pd.concat(predict_df, axis = 1)\n",
    "            return predict_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Create_classifier(object):\n",
    "#     def __init__(self, n_splits, base_models, grids):\n",
    "#         self.n_splits = n_splits\n",
    "#         self.base_models = base_models\n",
    "#         self.grids = grids\n",
    "\n",
    "#     def predict(self, x_train, y_train, x_test, y_test, chosen_set = ''):\n",
    "        \n",
    "#         cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state = random_state)\n",
    "                  \n",
    "#         roc_auc_scores = pd.DataFrame(columns = [str(i) for i in self.base_models])\n",
    "#         test_pred = pd.DataFrame(np.zeros((x_test.shape[0], len(self.base_models))), columns=[str(i).split('(')[0].lower() for i in self.base_models])\n",
    "#         test_pred.columns = pd.MultiIndex.from_product([[chosen_set], test_pred.columns])\n",
    "#         feat_selected = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "#         feat_importance = pd.DataFrame(np.zeros((len(x_train.columns), len(self.base_models))), index=x_train.columns, columns=[str(i) for i in self.base_models])\n",
    "#         models = []         \n",
    "        \n",
    "#         for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "#             pipe_lr = make_pipeline(PowerTransformer(method='yeo-johnson',standardize = True),\n",
    "#                                     RFECV(estimator = clf, step = 1, cv=cv, scoring = 'roc_auc'),\n",
    "#                                     clf)\n",
    "                  \n",
    "#             search = RandomizedSearchCV(estimator=pipe_lr, param_distributions = self.grids[i], cv = cv, n_jobs=-1, verbose=True, scoring = 'roc_auc')\n",
    "#             search.fit(x_train, y_train)\n",
    "            \n",
    "#             models.append([chosen_set, i, search.best_estimator_])\n",
    "            \n",
    "#             predict_rdf = search.best_estimator_.predict_proba(x_test)[:,1]\n",
    "#             test_pred[chosen_set][str(clf).split('(')[0].lower()] = predict_rdf.astype('float64')\n",
    "                  \n",
    "#             roc_auc_scores.loc[0,str(clf)] = roc_auc_score(y_test, predict_rdf)\n",
    "                  \n",
    "#             for j in x_train.columns:\n",
    "#                 feat_est = dict(zip(x_train.columns, search.best_estimator_.named_steps[\"rfecv\"].ranking_))\n",
    "#                 feat_selected.loc[str(j), str(clf)] = feat_est[str(j)]\n",
    "                \n",
    "#                 try:\n",
    "#                     importances = dict(zip(x_train.columns, search.best_estimator_.named_steps[str(clf).split('(')[0].lower()].feature_importances_))\n",
    "#                     feat_importance.loc[str(j), str(clf)] = importances[str(j)]\n",
    "#                 except Exception:\n",
    "#                     pass\n",
    "                \n",
    "#         return roc_auc_scores, feat_selected, feat_importance, test_pred, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def compute_midrank_weight(x, sample_weight):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    cumulative_weight = np.cumsum(sample_weight[J])\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = cumulative_weight[i:j].mean()\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    T2[J] = T\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Oerating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    p_val = np.log10(2) + norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "    \n",
    "    p_val = math.exp(p_val)\n",
    "    \n",
    "    return p_val\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth, sample_weight=None):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    if sample_weight is None:\n",
    "        ordered_sample_weight = None\n",
    "    else:\n",
    "        ordered_sample_weight = sample_weight[order]\n",
    "\n",
    "    return order, label_1_count, ordered_sample_weight\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "    order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(\n",
    "        ground_truth, sample_weight)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "    order, label_1_count, a = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    return calc_pvalue(aucs, delongcov)\n",
    "\n",
    "def calc_auc_ci(y_true, y_pred, alpha=0.95):\n",
    "    auc, auc_cov = delong_roc_variance(y_true,y_pred)\n",
    "    auc_std = np.sqrt(auc_cov)\n",
    "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "    ci_delong = norm.ppf(\n",
    "        lower_upper_q,\n",
    "        loc=auc,\n",
    "        scale=auc_std)\n",
    "\n",
    "    ci_delong[ci_delong > 1] = 1\n",
    "    \n",
    "    return ci_delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "\n",
    "def score_ci(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    score_fun,\n",
    "    n_bootstraps=2000,\n",
    "    confidence_level=0.95,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute confidence interval for given score function based on labels and predictions using bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_pred: 1D list or array of predictions corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param confidence_level: Confidence level for computing confidence interval. (default: 0.95)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Score evaluated on labels and predictions, lower confidence interval, upper confidence interval, array of\n",
    "    bootstrapped scores.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(y_true) == len(y_pred)\n",
    "\n",
    "    score = score_fun(y_true, y_pred)\n",
    "    _, ci_lower, ci_upper, scores = score_stat_ci(\n",
    "        y_true=y_true,\n",
    "        y_preds=y_pred,\n",
    "        score_fun=score_fun,\n",
    "        n_bootstraps=n_bootstraps,\n",
    "        confidence_level=confidence_level,\n",
    "        seed=seed,\n",
    "        reject_one_class_samples=reject_one_class_samples,\n",
    "    )\n",
    "\n",
    "    return score, ci_lower, ci_upper, scores\n",
    "\n",
    "\n",
    "def score_stat_ci(\n",
    "    y_true,\n",
    "    y_preds,\n",
    "    score_fun,\n",
    "    stat_fun=np.mean,\n",
    "    n_bootstraps=2000,\n",
    "    confidence_level=0.95,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute confidence interval for given statistic of a score function based on labels and predictions using\n",
    "    bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_preds: A list of lists or 2D array of predictions corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param stat_fun: Statistic for which confidence interval is computed. (e.g. np.mean)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param confidence_level: Confidence level for computing confidence interval. (default: 0.95)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Mean score statistic evaluated on labels and predictions, lower confidence interval, upper confidence\n",
    "    interval, array of bootstrapped scores.\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_preds = np.atleast_2d(y_preds)\n",
    "    assert all(len(y_true) == len(y) for y in y_preds)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    scores = []\n",
    "    for i in range(n_bootstraps):\n",
    "        readers = np.random.randint(0, len(y_preds), len(y_preds))\n",
    "        indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "        if reject_one_class_samples and len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        reader_scores = []\n",
    "        for r in readers:\n",
    "            reader_scores.append(score_fun(y_true[indices], y_preds[r][indices]))\n",
    "        scores.append(stat_fun(reader_scores))\n",
    "\n",
    "    mean_score = np.mean(scores)\n",
    "    sorted_scores = np.array(sorted(scores))\n",
    "    alpha = (1.0 - confidence_level) / 2.0\n",
    "    ci_lower = sorted_scores[int(round(alpha * len(sorted_scores)))]\n",
    "    ci_upper = sorted_scores[int(round((1.0 - alpha) * len(sorted_scores)))]\n",
    "    \n",
    "    ci_boot = np.array([ci_lower,ci_upper])\n",
    "    \n",
    "    return ci_boot\n",
    "\n",
    "\n",
    "def pvalue(\n",
    "    y_true,\n",
    "    y_pred1,\n",
    "    y_pred2,\n",
    "    score_fun,\n",
    "    n_bootstraps=2000,\n",
    "    two_tailed=True,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute p-value for hypothesis that score function for model I predictions is higher than for model II predictions\n",
    "    using bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_pred1: 1D list or array of predictions for model I corresponding to elements in y_true.\n",
    "    :param y_pred2: 1D list or array of predictions for model II corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param two_tailed: Whether to use two-tailed test. (default: True)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Computed p-value, array of bootstrapped differences of scores.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(y_true) == len(y_pred1)\n",
    "    assert len(y_true) == len(y_pred2)\n",
    "\n",
    "    return pvalue_stat(\n",
    "        y_true=y_true,\n",
    "        y_preds1=y_pred1,\n",
    "        y_preds2=y_pred2,\n",
    "        score_fun=score_fun,\n",
    "        n_bootstraps=n_bootstraps,\n",
    "        two_tailed=two_tailed,\n",
    "        seed=seed,\n",
    "        reject_one_class_samples=reject_one_class_samples,\n",
    "    )\n",
    "\n",
    "\n",
    "def pvalue_stat(\n",
    "    y_true,\n",
    "    y_preds1,\n",
    "    y_preds2,\n",
    "    score_fun,\n",
    "    stat_fun=np.mean,\n",
    "    n_bootstraps=1000,\n",
    "    two_tailed=True,\n",
    "    seed=None,\n",
    "    reject_one_class_samples=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute p-value for hypothesis that given statistic of score function for model I predictions is higher than for\n",
    "    model II predictions using bootstrapping.\n",
    "    :param y_true: 1D list or array of labels.\n",
    "    :param y_preds1: A list of lists or 2D array of predictions for model I corresponding to elements in y_true.\n",
    "    :param y_preds2: A list of lists or 2D array of predictions for model II corresponding to elements in y_true.\n",
    "    :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "    :param stat_fun: Statistic for which p-value is computed. (e.g. np.mean)\n",
    "    :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "    :param two_tailed: Whether to use two-tailed test. (default: True)\n",
    "    :param seed: Random seed for reproducibility. (default: None)\n",
    "    :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "    need at least one positive and one negative sample. (default: True)\n",
    "    :return: Computed p-value, array of bootstrapped differences of scores.\n",
    "    \"\"\"\n",
    "\n",
    "#     y_true = np.array(y_true)\n",
    "#     y_preds1 = np.atleast_2d(y_preds1)\n",
    "#     y_preds2 = np.atleast_2d(y_preds2)\n",
    "#     assert all(len(y_true) == len(y) for y in y_preds1)\n",
    "#     assert all(len(y_true) == len(y) for y in y_preds2)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "#     t= []\n",
    "    m = []\n",
    "    sd = []\n",
    "    score1 = []\n",
    "    score2 = []\n",
    "#     for i in range(n_bootstraps):\n",
    "#         readers1 = np.random.randint(0, len(y_preds1), len(y_preds1))\n",
    "#         readers2 = np.random.randint(0, len(y_preds2), len(y_preds2))\n",
    "#         indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "#         if reject_one_class_samples and len(np.unique(y_true[indices])) < 2:\n",
    "#             continue\n",
    "#         reader_scores = []\n",
    "#         for r in readers1:\n",
    "#             reader_scores.append(score_fun(y_true[indices], y_preds1[r][indices]))\n",
    "#         score1.append(reader_scores)\n",
    "#         reader_scores2 = []\n",
    "#         for r in readers2:\n",
    "#             reader_scores.append(score_fun(y_true[indices], y_preds2[r][indices]))\n",
    "#         score2.append(reader_scores2)\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        readers1 = np.random.randint(0, len(y_preds1), len(y_preds1))\n",
    "        readers2 = np.random.randint(0, len(y_preds2), len(y_preds2))\n",
    "        indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "        score1.append(roc_auc_score(y_true[indices], y_preds1[indices]))\n",
    "        score2.append(roc_auc_score(y_true[indices], y_preds2[indices]))\n",
    "                \n",
    "    m.append(stat_fun(score1) - stat_fun(score2))\n",
    "    \n",
    "    s1 = (stdev(score1))\n",
    "    n1 = len(score1)\n",
    "    s2 = (stdev(score2))\n",
    "    n2 = len(score2)\n",
    "    \n",
    "    sd.append(math.sqrt((s1**2)/n1 + (s2**2)/n2 - 2*np.correlate(score1,score2)*(s1/n1)*(s2/n2)))\n",
    "#     sd.append(math.sqrt(s1 + s2)) \n",
    "    Z = m[0]/sd[0]\n",
    "    \n",
    "    p = norm.cdf(Z)\n",
    "        \n",
    "#     value, p = ttest_ind(score1, score2, equal_var=False)\n",
    "    \n",
    "#     if two_tailed:\n",
    "#         p *= 2.0\n",
    "    return p\n",
    "\n",
    "def method(x,y):\n",
    "    roc_auc_score(x,y)\n",
    "\n",
    "def bootstrap_error_estimate(pred, truth, method, method_name=\"\", alpha=0.95, sample_frac=0.5, iterations=2000):\n",
    "    \"\"\"\n",
    "    Generate a bootstrapped estimate of confidence intervals\n",
    "    :param pred: list of predicted values\n",
    "    :param truth: list of experimental values\n",
    "    :param method: method to evaluate performance, e.g. matthews_corrcoef\n",
    "    :param method_name: name of the method for the progress bar\n",
    "    :param alpha: confidence limit (e.g. 0.95 for 95% confidence interval)\n",
    "    :param sample_frac: fraction to resample for bootstrap confidence interval\n",
    "    :param iterations: number of iterations for resampling\n",
    "    :return: lower and upper bounds for confidence intervals\n",
    "    \"\"\"\n",
    "    index_list = range(0, len(pred))\n",
    "    num_samples = int(len(index_list) * sample_frac)\n",
    "    stats = []\n",
    "    for _ in range(0, iterations):\n",
    "        sample_idx = resample(index_list, n_samples=num_samples)\n",
    "        pred_sample = [pred[x] for x in sample_idx]\n",
    "        truth_sample = [truth[x] for x in sample_idx]\n",
    "        stats.append(method(truth_sample, pred_sample))\n",
    "    p = ((1.0 - alpha) / 2.0) * 100\n",
    "    lower = max(0.0, np.percentile(stats, p))\n",
    "    p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "    upper = min(1.0, np.percentile(stats, p))\n",
    "    \n",
    "    ci_boot = np.array([lower,upper])\n",
    "    \n",
    "    return ci_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pvalue_stat(\n",
    "#     y_true,\n",
    "#     y_preds1,\n",
    "#     y_preds2,\n",
    "#     score_fun,\n",
    "#     stat_fun=np.mean,\n",
    "#     n_bootstraps=2000,\n",
    "#     two_tailed=True,\n",
    "#     seed=None,\n",
    "#     reject_one_class_samples=True,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Compute p-value for hypothesis that given statistic of score function for model I predictions is higher than for\n",
    "#     model II predictions using bootstrapping.\n",
    "#     :param y_true: 1D list or array of labels.\n",
    "#     :param y_preds1: A list of lists or 2D array of predictions for model I corresponding to elements in y_true.\n",
    "#     :param y_preds2: A list of lists or 2D array of predictions for model II corresponding to elements in y_true.\n",
    "#     :param score_fun: Score function for which confidence interval is computed. (e.g. sklearn.metrics.accuracy_score)\n",
    "#     :param stat_fun: Statistic for which p-value is computed. (e.g. np.mean)\n",
    "#     :param n_bootstraps: The number of bootstraps. (default: 2000)\n",
    "#     :param two_tailed: Whether to use two-tailed test. (default: True)\n",
    "#     :param seed: Random seed for reproducibility. (default: None)\n",
    "#     :param reject_one_class_samples: Whether to reject bootstrapped samples with only one label. For scores like AUC we\n",
    "#     need at least one positive and one negative sample. (default: True)\n",
    "#     :return: Computed p-value, array of bootstrapped differences of scores.\n",
    "#     \"\"\"\n",
    "\n",
    "#     y_true = np.array(y_true)\n",
    "#     y_preds1 = np.atleast_2d(y_preds1)\n",
    "#     y_preds2 = np.atleast_2d(y_preds2)\n",
    "#     assert all(len(y_true) == len(y) for y in y_preds1)\n",
    "#     assert all(len(y_true) == len(y) for y in y_preds2)\n",
    "\n",
    "#     np.random.seed(seed)\n",
    "#     z = []\n",
    "#     for i in range(n_bootstraps):\n",
    "#         readers1 = np.random.randint(0, len(y_preds1), len(y_preds1))\n",
    "#         readers2 = np.random.randint(0, len(y_preds2), len(y_preds2))\n",
    "#         indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "#         if reject_one_class_samples and len(np.unique(y_true[indices])) < 2:\n",
    "#             continue\n",
    "#         reader_scores = []\n",
    "#         for r in readers1:\n",
    "#             reader_scores.append(score_fun(y_true[indices], y_preds1[r][indices]))\n",
    "#         score1 = stat_fun(reader_scores)\n",
    "#         reader_scores = []\n",
    "#         for r in readers2:\n",
    "#             reader_scores.append(score_fun(y_true[indices], y_preds2[r][indices]))\n",
    "#         score2 = stat_fun(reader_scores)\n",
    "#         z.append(score1 - score2)\n",
    "\n",
    "#     p = percentileofscore(z, 0.0, kind=\"weak\") / 100.0\n",
    "#     if two_tailed:\n",
    "#         p *= 2.0\n",
    "#     return p, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.075678\n",
       "1        0.001485\n",
       "2        0.001420\n",
       "3        0.001504\n",
       "4        0.000188\n",
       "           ...   \n",
       "12875    0.001880\n",
       "12876    0.000164\n",
       "12877    0.000247\n",
       "12878    0.000993\n",
       "12879    0.003833\n",
       "Name: (ALL, gaussiannb), Length: 12880, dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_all[('ALL','gaussiannb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds1 = predict_df_all[('ALL','gaussiannb')]\n",
    "y_preds2 = predict_df_all[('PDE','gaussiannb')]\n",
    "y_true = ytest\n",
    "y_true = np.array(y_true)\n",
    "# y_preds1 = np.atleast_2d(y_preds1)\n",
    "# y_preds2 = np.atleast_2d(y_preds2)\n",
    "# assert all(len(y_true) == len(y) for y in y_preds1)\n",
    "# assert all(len(y_true) == len(y) for y in y_preds2)\n",
    "score1 = []\n",
    "score2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    readers1 = np.random.randint(0, len(y_preds1), len(y_preds1))\n",
    "    readers2 = np.random.randint(0, len(y_preds2), len(y_preds2))\n",
    "    indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "    score1.append(roc_auc_score(y_true[indices], y_preds1[indices]))\n",
    "    score2.append(roc_auc_score(y_true[indices], y_preds2[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_preds1, y_preds2, y_true, score1, score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    readers1 = np.random.randint(0, len(y_preds1), len(y_preds1))\n",
    "    readers2 = np.random.randint(0, len(y_preds2), len(y_preds2))\n",
    "    indices = np.random.randint(0, len(y_true), len(y_true))\n",
    "    score1.append(roc_auc_score(y_true[indices], y_preds1[indices]))\n",
    "    score2.append(roc_auc_score(y_true[indices], y_preds2[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, p = ttest_ind(score1, score2, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165044193720999"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9183600815147852"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.935227430252111,\n",
       " 0.8834184797151268,\n",
       " 0.9157848583512351,\n",
       " 0.9280878479390618,\n",
       " 0.9099754748373121,\n",
       " 0.9103472408043967,\n",
       " 0.8922910798122066,\n",
       " 0.9220652096533067,\n",
       " 0.925406429018976,\n",
       " 0.9069771152807191]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in score1:\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         t.append(score1)\n",
    "m.append(np.mean(score1) - np.mean(score2))\n",
    "s1 = (stdev(score1)**2)/len(score1)\n",
    "s2 = (stdev(score2)**2)/len(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object of too small depth for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-305-0125881465ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcorrelate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pawel\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mcorrelate\u001b[1;34m(a, v, mode)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \"\"\"\n\u001b[0;32m    712\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrelate2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: object of too small depth for desired array"
     ]
    }
   ],
   "source": [
    "2*np.correlate(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.append(sqrt(s1 + s2 - 2*np.correlate(s1,s2)*s1*s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_ftest_5x2cv(estimator1, estimator2, x_train, y_train, scoring=None, random_seed=None):\n",
    "\n",
    "    if isinstance(scoring, str):\n",
    "        scorer = get_scorer(scoring)\n",
    "    else:\n",
    "        scorer = scoring\n",
    "\n",
    "    variances = []\n",
    "    differences = []\n",
    "\n",
    "    def score_diff(X_1, X_2, y_1, y_2):\n",
    "\n",
    "        estimator1.fit(X_1, y_1)\n",
    "        estimator2.fit(X_1, y_1)\n",
    "        est1_score = scorer(estimator1, X_2, y_2)\n",
    "        est2_score = scorer(estimator2, X_2, y_2)\n",
    "        score_diff = est1_score - est2_score\n",
    "        return score_diff\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "        X_1, X_2, y_1, y_2 = train_test_split(x_train, y_train, test_size=0.5, random_state=random_state)\n",
    "\n",
    "        score_diff_1 = score_diff(X_1, X_2, y_1, y_2)\n",
    "        score_diff_2 = score_diff(X_2, X_1, y_2, y_1)\n",
    "        score_mean = (score_diff_1 + score_diff_2) / 2.\n",
    "        score_var = ((score_diff_1 - score_mean)**2 + (score_diff_2 - score_mean)**2)\n",
    "\n",
    "        differences.extend([score_diff_1**2, score_diff_2**2])\n",
    "        variances.append(score_var)\n",
    "\n",
    "    numerator = sum(differences)\n",
    "    denominator = 2*(sum(variances))\n",
    "    f_stat = numerator / denominator\n",
    "\n",
    "    p_value = f.sf(f_stat, 10, 5)\n",
    "\n",
    "    return float(f_stat), float(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ALL', 0, GaussianNB(var_smoothing=1.7782794100389228)]]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=1.7782794100389228)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scoring(object):\n",
    "    def __init__(self, base_models):\n",
    "#         self.roc_auc = roc_auc\n",
    "        self.base_models = base_models\n",
    "\n",
    "#     def joined_scores(self):\n",
    "#         roc_auc_all = pd.concat(self.roc_auc)\n",
    "#         predict_df_all = pd.concat(self.predict_df, axis = 1)\n",
    "#         return predict_df_all\n",
    "\n",
    "    def delong_test(self, predict_df_all, labels):\n",
    "        \n",
    "        Test_df_sets = pd.DataFrame(np.zeros((2, len(self.base_models))), index=['ALL/PDE','ALL/PD'], columns=[str(i).split('(')[0].lower() for i in self.base_models])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['DeLong Test'], Test_df_sets.columns])\n",
    "        \n",
    "        Test_df_all = pd.DataFrame(list(combinations(Test_df_sets['DeLong Test'].columns,2)),columns = ['1st Algorithm', '2nd Algorithm'])\n",
    "        Test_df_all['score'] = 0\n",
    "        Test_df_all.columns = pd.MultiIndex.from_product([['DeLong Test'], Test_df_all.columns])    \n",
    "            \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            Test_df_sets['DeLong Test'].loc['ALL/PDE',str(clf).split('(')[0].lower()] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][str(clf).split('(')[0].lower()], predict_df_all['PDE'][str(clf).split('(')[0].lower()])\n",
    "            Test_df_sets['DeLong Test'].loc['ALL/PD',str(clf).split('(')[0].lower()] = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][str(clf).split('(')[0].lower()], predict_df_all['PD'][str(clf).split('(')[0].lower()])\n",
    "        \n",
    "        for j in range(Test_df_all.shape[0]):\n",
    "            Test_df_all.loc[j, ('DeLong Test', 'score')]  = delong_roc_test(labels.values.ravel(), predict_df_all['ALL'][Test_df_all.loc[j, ('DeLong Test', '1st Algorithm')]], predict_df_all['ALL'][Test_df_all.loc[j, ('DeLong Test', '2nd Algorithm')]])\n",
    "       \n",
    "        return Test_df_sets, Test_df_all\n",
    "    \n",
    "    def bootstrap_test(self, predict_df_all, labels):\n",
    "    \n",
    "        Test_df_sets = pd.DataFrame(np.zeros((2, len(self.base_models))), index=['ALL/PDE','ALL/PD'], columns=[str(i).split('(')[0].lower() for i in self.base_models])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['Bootstrap Test'], Test_df_sets.columns])\n",
    "        \n",
    "        Test_df_all = pd.DataFrame(list(combinations(Test_df_sets['Bootstrap Test'].columns,2)),columns = ['1st Algorithm', '2nd Algorithm'])\n",
    "        Test_df_all['score'] = 0\n",
    "        Test_df_all.columns = pd.MultiIndex.from_product([['Bootstrap Test'], Test_df_all.columns])\n",
    "            \n",
    "        for i, clf in enumerate(self.base_models):\n",
    "        \n",
    "            Test_df_sets['Bootstrap Test'].loc['ALL/PDE',str(clf).split('(')[0].lower()] = pvalue(labels.values.ravel(), predict_df_all['ALL'][str(clf).split('(')[0].lower()], predict_df_all['PDE'][str(clf).split('(')[0].lower()], score_fun=roc_auc_score)\n",
    "            Test_df_sets['Bootstrap Test'].loc['ALL/PD',str(clf).split('(')[0].lower()] = pvalue(labels.values.ravel(), predict_df_all['ALL'][str(clf).split('(')[0].lower()], predict_df_all['PD'][str(clf).split('(')[0].lower()], score_fun=roc_auc_score)\n",
    "            \n",
    "        for j in range(Test_df_all.shape[0]):\n",
    "            Test_df_all.loc[j, ('Bootstrap Test', 'score')]  = pvalue(labels.values.ravel(), predict_df_all['ALL'][Test_df_all.loc[j, ('Bootstrap Test', '1st Algorithm')]], predict_df_all['ALL'][Test_df_all.loc[j, ('Bootstrap Test', '2nd Algorithm')]],score_fun=roc_auc_score)\n",
    "       \n",
    "        return Test_df_sets, Test_df_all\n",
    "    \n",
    "    def likelihood_RT(self, predict_df_all, labels, x_train):\n",
    "    \n",
    "#     Tu powinien być model, który zostanie wyszukany, a nie self.base_models\n",
    "\n",
    "        Test_df_sets = pd.DataFrame((np.zeros((2, 1))), index=['ALL/PDE','ALL/PD'], columns=[str(self.base_models[0])])\n",
    "        Test_df_sets.columns = pd.MultiIndex.from_product([['LRT'], Test_df_sets.columns])\n",
    "\n",
    "        alt_log_likelihood = -log_loss(labels,\n",
    "                                       predict_df_all['ALL'][str(self.base_models[0])],\n",
    "                                       normalize=False)\n",
    "        null_log_likelihood = -log_loss(ytest,\n",
    "                                        predict_df_all['PDE'][str(self.base_models[0])],\n",
    "                                        normalize=False)\n",
    "        G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "        p_log_l = chi2.sf(G, x_train.shape[1])\n",
    "        \n",
    "        alt_log_likelihood = -log_loss(labels,\n",
    "                                       predict_df_all['ALL'][str(self.base_models[0])],\n",
    "                                       normalize=False)\n",
    "        null_log_likelihood = -log_loss(ytest,\n",
    "                                        predict_df_all['PD'][str(self.base_models[0])],\n",
    "                                        normalize=False)\n",
    "        \n",
    "        G = 2 * (alt_log_likelihood - null_log_likelihood)\n",
    "        p_log_2 = chi2.sf(G, x_train.shape[1])\n",
    "        \n",
    "        Test_df_sets['LRT'].loc['ALL/PDE' ,str(self.base_models[0])] = p_log_l\n",
    "        Test_df_sets['LRT'].loc['ALL/PD', str(self.base_models[0])] = p_log_2\n",
    "\n",
    "        return Test_df_sets\n",
    "    \n",
    "    def f_test(self, estimators_list, x_train, y_train, scoring, random_state):\n",
    "    \n",
    "        estimators = []\n",
    "        for i in range(len(self.base_models)):\n",
    "              estimators.append(estimators_list[i][2])\n",
    "#             it should be 2 because of what models' list contains\n",
    "#             estimators.append(estimators_list[i][2])\n",
    "        estimators = list(combinations(estimators,2))\n",
    "        \n",
    "        p_values = []\n",
    "\n",
    "        for i in range(len(estimators)): \n",
    "#           it should be eval becuase of the character of data imputed\n",
    "#             estimator1 = eval(estimators[i][0])\n",
    "#             estimator2 = eval(estimators[i][1])\n",
    "            \n",
    "            global estimator1, estimator2 \n",
    "            estimator1 = estimators[i][0]\n",
    "            estimator2 = estimators[i][1]\n",
    "            \n",
    "            f_stat, p_value = combined_ftest_5x2cv(estimator1, estimator2, x_train, y_train, scoring, random_state)\n",
    "            \n",
    "            p_values.append(p_value)\n",
    "            \n",
    "        f_p_values = pd.DataFrame(columns = ['algorithm1', 'algorithm2', 'score'])    \n",
    "            \n",
    "        for j in range(len(estimators)): \n",
    "            f_p_values.loc[j,'algorithm1'] = estimators[j][0]\n",
    "            f_p_values.loc[j,'algorithm2'] = estimators[j][1]\n",
    "            f_p_values.loc[j,'score'] = p_values[j]\n",
    "        \n",
    "        return(f_p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yeoj_graph(x_train, lbd_list, feature=''):\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    for i in range(len(lbd_list)):\n",
    "        n_lines = len(lbd_list)\n",
    "        c = np.arange(1, n_lines + 1)\n",
    "        norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "        cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Blues)\n",
    "        cmap.set_array([])\n",
    "        a = x_train[feature].values.ravel()\n",
    "        a = np.sort(a)\n",
    "        b = stats.yeojohnson(x_train[feature], lmbda=lbd_list[i])\n",
    "        b = np.sort(b)\n",
    "        plt.plot(a,b, c=cmap.to_rgba(i + 1), label='λ = '+str(lbd_list[i]))\n",
    "    plt.legend(loc=0)\n",
    "    plt.ylabel(\"ψ(λ,x)\", fontsize=15)\n",
    "    plt.xlabel(\"x\", fontsize=15)\n",
    "    plt.savefig('yeo-johnson.png', dpi=1200)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def roc_comparison_all(predict_df, y_test):\n",
    "    \n",
    "    # Plot the figure\n",
    "    # Train the models and record the results\n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "\n",
    "    for i, (j, clf) in enumerate(predict_df):\n",
    "        yproba = predict_df[j][clf]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test.values.ravel(),  yproba)\n",
    "        auc = roc_auc_score(y_test.values.ravel(), yproba)\n",
    "\n",
    "        result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                            'fpr':fpr, \n",
    "                                            'tpr':tpr, \n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "\n",
    "        result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    for k,m in enumerate(result_table.classifier.unique()):\n",
    "\n",
    "    #     n_lines = len(base_models[:2])\n",
    "    #     c = np.arange(1, n_lines + 1)\n",
    "    #     norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "    #     cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Blues)\n",
    "    #     cmap.set_array([])\n",
    "\n",
    "        plt.plot(result_table.loc[result_table.set == 'ALL']['fpr'][k], \n",
    "                 result_table.loc[result_table.set == 'ALL']['tpr'][k],\n",
    "    #              c=cmap.to_rgba(k + 2),\n",
    "                 label=\"{}, AUC={:.3f}\".format(str(m).split('(')[0].lower(), result_table.loc[result_table.set == 'ALL']['auc'][k]))\n",
    "\n",
    "    plt.plot([0,1], [0,1], color='gray', linestyle='--')\n",
    "\n",
    "    plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "    plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "    # plt.title('ROC Curve Logistic Regression Analysis', fontweight='bold', fontsize=15)\n",
    "    plt.legend(prop={'size':13}, loc='lower right')\n",
    "    plt.savefig('ALL.png',  dpi=1200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def roc_comparison_sets(predict_df, y_test):\n",
    "    \n",
    "    # Plot the figure\n",
    "    # Train the models and record the results\n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "    for i, (j, clf) in enumerate(predict_df):\n",
    "        yproba = predict_df[j][clf]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test.values.ravel(),  yproba)\n",
    "        auc = roc_auc_score(y_test.values.ravel(), yproba)\n",
    "\n",
    "        result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                            'fpr':fpr, \n",
    "                                            'tpr':tpr, \n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "\n",
    "        result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "        for k,m in enumerate(result_table.set.unique()):\n",
    "\n",
    "            plt.plot(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['fpr'].values[0], \n",
    "                     result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['tpr'].values[0],\n",
    "                     label=\"{}, AUC={:.3f}\".format(str(m), result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['auc'].values[0]))\n",
    "\n",
    "            plt.plot([0,1], [0,1], color='gray', linestyle='--')\n",
    "\n",
    "            plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "            plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "            plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "            plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "            plt.legend(prop={'size':13}, loc='lower right')\n",
    "            \n",
    "        plt.savefig(str(clf)+str(m)+'.png',  dpi=1200)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_ci_alternative(predict_df, base_models):\n",
    "    \n",
    "        \n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'delong','bootstrap'])\n",
    "    for i, (j, clf) in enumerate(predict_df):\n",
    "        yproba = predict_df[j][clf]\n",
    "\n",
    "        delong = calc_auc_ci(ytest.values.ravel(),  yproba, alpha=0.95) \n",
    "        bootstrap = score_stat_ci(ytest.values.ravel(), yproba,  roc_auc_score)\n",
    "\n",
    "        result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                            'delong':delong, \n",
    "                                            'bootstrap':bootstrap}, ignore_index=True)\n",
    "\n",
    "        result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "\n",
    "    for k,m in enumerate(result_table.set.unique()):\n",
    "    \n",
    "        plt.figure(figsize=(8,6))\n",
    "\n",
    "        SMALL_SIZE = 10\n",
    "        MEDIUM_SIZE = 12\n",
    "        BIGGER_SIZE = 14\n",
    "\n",
    "        plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "        plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "        plt.rc('xtick', labelsize=MEDIUM_SIZE)   # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "        plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "        x_ticks = [str(i).split('(')[0].lower() for i in base_models]\n",
    "\n",
    "        for n,l in enumerate(result_table.classifier.unique()):\n",
    "\n",
    "            eb_1 = plt.errorbar(x=n+1, \n",
    "                             y=(result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['bootstrap'].values[0][1] + result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['bootstrap'].values[0][0])/2, \n",
    "                             yerr=[(result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['bootstrap'].values[0][1] - result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['bootstrap'].values[0][0])/2],\n",
    "                             fmt='ok',\n",
    "                             capsize = 10)\n",
    "\n",
    "            eb_2 = plt.errorbar(x=n+1.1, \n",
    "                             y=(result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['delong'].values[0][1] + result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['delong'].values[0][0])/2, \n",
    "                             yerr=[(result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['delong'].values[0][1] - result_table.loc[(result_table.classifier == str(l)) & (result_table.set == str(m))]['delong'].values[0][0])/2],\n",
    "                             fmt='ok',\n",
    "                             capsize = 10)\n",
    "            eb_2[-1][0].set_linestyle('--')\n",
    "            \n",
    "            # I need to manipulate 3rd parameter in arange, so the graph looks nice & I also need to do the same in errorbar(x)\n",
    "\n",
    "            plt.xticks(np.arange(1.05,len(x_ticks)+0.5,1), x_ticks, rotation=90)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plt.ylabel(\"ROC AUC Przedział Ufności\", fontsize=15)\n",
    "            plt.tight_layout()\n",
    "\n",
    "        plt.savefig('plot'+str(m)+'ci.png', dpi=1200)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_ci(predict_df, base_models):\n",
    "    \n",
    "        \n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'delong','bootstrap'])\n",
    "    for i, (j, clf) in enumerate(predict_df):\n",
    "        yproba = predict_df[j][clf]\n",
    "\n",
    "        delong = calc_auc_ci(ytest.values.ravel(),  yproba, alpha=0.95) \n",
    "        bootstrap = bootstrap_error_estimate(yproba, ytest.values.ravel(), roc_auc_score)\n",
    "\n",
    "        result_table = result_table.append({'classifiers': [j,clf],\n",
    "                                            'delong':delong, \n",
    "                                            'bootstrap':bootstrap}, ignore_index=True)\n",
    "\n",
    "        result_table[['set', 'classifier']] = pd.DataFrame(result_table['classifiers'].tolist(), index=result_table.index)\n",
    "        \n",
    "        plt.figure(figsize=(8,6))\n",
    "\n",
    "        for k,(m,n) in enumerate(result_table.classifiers):\n",
    "\n",
    "            SMALL_SIZE = 10\n",
    "            MEDIUM_SIZE = 12\n",
    "            BIGGER_SIZE = 14\n",
    "\n",
    "            plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "            plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "            plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "            plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "            plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "            x_ticks = ('Wszystkie Zmienne', 'Bez PD', 'Tylko PD')\n",
    "            \n",
    "            def m_value(x):\n",
    "                if x == 'ALL':\n",
    "                    x_1 = 1\n",
    "                    x_2 = x_1 + 0.1\n",
    "                elif x == 'NOPD':\n",
    "                    x_1 = 2\n",
    "                    x_2 = x_1 + 0.1\n",
    "                elif x == 'PD':\n",
    "                    x_1 = 3\n",
    "                    x_2 = x_1 + 0.1\n",
    "                return list([x_1,x_2])\n",
    "\n",
    "            eb_1 = plt.errorbar(x=m_value(str(m))[0], \n",
    "                             y=(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][1] + result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][0])/2, \n",
    "                             yerr=[(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][1] - result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['bootstrap'].values[0][0])/2],\n",
    "                             fmt='ok',\n",
    "                             capsize = 10)\n",
    "\n",
    "            eb_2 = plt.errorbar(x=m_value(str(m))[1], \n",
    "                             y=(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][1] + result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][0])/2, \n",
    "                             yerr=[(result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][1] - result_table.loc[(result_table.classifier == str(clf)) & (result_table.set == str(m))]['delong'].values[0][0])/2],\n",
    "                             fmt='ok',\n",
    "                             capsize = 10)\n",
    "            eb_2[-1][0].set_linestyle('--')\n",
    "\n",
    "            plt.xticks([1.05,2.05,3.05], x_ticks, rotation=90)\n",
    "            plt.tight_layout()\n",
    "\n",
    "\n",
    "            plt.ylabel(\"ROC AUC Przedział Ufności\", fontsize=15)\n",
    "            plt.tight_layout()\n",
    "\n",
    "        plt.savefig('plot'+str(clf)+'ci.png', dpi=1200)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to refer to 5x2 CV test below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_score = Scoring(base_models = base_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = lgb_score.delong_test(predict_df_all, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,d = lgb_score.bootstrap_test(predict_df_all, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Bootstrap Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>gaussiannb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL/PDE</th>\n",
       "      <td>3.177230e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALL/PD</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bootstrap Test\n",
       "            gaussiannb\n",
       "ALL/PDE   3.177230e-45\n",
       "ALL/PD    1.000000e+00"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaussianNB()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GaussianNB()\n",
       "0     0.904118"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Bootstrap Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>gaussiannb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL/PDE</th>\n",
       "      <td>3.177230e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALL/PD</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bootstrap Test\n",
       "            gaussiannb\n",
       "ALL/PDE   3.177230e-45\n",
       "ALL/PD    1.000000e+00"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Bootstrap Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1st Algorithm</th>\n",
       "      <th>2nd Algorithm</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(Bootstrap Test, 1st Algorithm), (Bootstrap Test, 2nd Algorithm), (Bootstrap Test, score)]\n",
       "Index: []"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_p_values = lgb_score.f_test(models, xtrain, ytrain, scoring = 'roc_auc', random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ci_alternative(test_pred, base_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = graph_ci_alternative(predict_df_all, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = graph_ci_alternative(predict_df_all, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_stack = Create_classifier(n_splits = n_splits, base_models = base_models, grids = grids)        \n",
    "# roc_auc_scores, feat_selected, test_pred, models = lgb_stack.predict(xtrain, ytrain, xtest, ytest, chosen_set = chosen_set[0])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
